{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:13:09.206724Z",
     "iopub.status.busy": "2025-05-19T00:13:09.206284Z",
     "iopub.status.idle": "2025-05-19T00:13:10.634776Z",
     "shell.execute_reply": "2025-05-19T00:13:10.634028Z",
     "shell.execute_reply.started": "2025-05-19T00:13:09.206691Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the .pt file\n",
    "file_path = 'data/Combined/total_processed_rna_data.pt'\n",
    "loaded_data = torch.load(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:13:12.989316Z",
     "iopub.status.busy": "2025-05-19T00:13:12.988992Z",
     "iopub.status.idle": "2025-05-19T00:13:15.465570Z",
     "shell.execute_reply": "2025-05-19T00:13:15.465025Z",
     "shell.execute_reply.started": "2025-05-19T00:13:12.989292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.manifold import MDS\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import fm\n",
    "from sklearn.manifold import MDS\n",
    "import dgl\n",
    "import sys\n",
    "sys.path.append(\"/workspace/app\")\n",
    "import se3_transformer\n",
    "from dgl import DGLGraph\n",
    "from typing import Dict, Tuple, List, Set\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CONFIG & SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:13:33.242732Z",
     "iopub.status.busy": "2025-05-19T00:13:33.242043Z",
     "iopub.status.idle": "2025-05-19T00:13:33.252916Z",
     "shell.execute_reply": "2025-05-19T00:13:33.252491Z",
     "shell.execute_reply.started": "2025-05-19T00:13:33.242706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 1024,\n",
    "    \"batch_size\": 1,\n",
    "    \"model_config_path\": \"ribonanzanet2d-final/configs/pairwise.yaml\",\n",
    "    \"max_len_filter\": 128, #1024 originally\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    \"train_sequences_path\": \"data/Competition/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"data/Competition/train_labels.csv\",\n",
    "    \"test_data_path\": \"data/Competition/test_sequences.csv\",\n",
    "    \"combined_train_data_path\": \"data/Combined/total_processed_rna_data.pt\",\n",
    "    \"final_pretrained_weights_path\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "    \"nonfinal_pretrained_weights_path\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_name\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_final\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "    \"rna_fm_weights\": \"weights/RNA-FM_pretrained.pth\",\n",
    "    \"path_to_GCNFold_weights\": \"weights/model_unet_99.pth\",\n",
    "    \"rna_fm_embedding_dim\": 640 # default 640; DO NOT CHANGE\n",
    "}\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])\n",
    "\n",
    "# import shutil\n",
    "# shutil.copy(\"/root/.cache/torch/hub/checkpoints/RNA-FM_pretrained.pth\", config[\"rna_fm_weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:13:40.945816Z",
     "iopub.status.busy": "2025-05-19T00:13:40.945374Z",
     "iopub.status.idle": "2025-05-19T00:13:41.264831Z",
     "shell.execute_reply": "2025-05-19T00:13:41.264305Z",
     "shell.execute_reply.started": "2025-05-19T00:13:40.945789Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load CSVs\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "\n",
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "# Create a pdb_id field\n",
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(\n",
    "    lambda x: x.split(\"_\")[0] + \"_\" + x.split(\"_\")[1]\n",
    ")\n",
    "\n",
    "# # Collect xyz data for each sequence\n",
    "# all_xyz = []\n",
    "# for pdb_id in tqdm(train_sequences[\"target_id\"], desc=\"Collecting XYZ data\"):\n",
    "#     df = train_labels[train_labels[\"pdb_id\"] == pdb_id]\n",
    "#     xyz = df[[\"x_1\", \"y_1\", \"z_1\"]].to_numpy().astype(\"float32\")\n",
    "#     xyz[xyz < -1e17] = float(\"nan\")\n",
    "#     all_xyz.append(xyz)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 SECONDARY DATA (BPPMs, initial 3D structs, initial sequence embeddings, etc.) GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:13:45.683634Z",
     "iopub.status.busy": "2025-05-19T00:13:45.682938Z",
     "iopub.status.idle": "2025-05-19T00:13:53.483287Z",
     "shell.execute_reply": "2025-05-19T00:13:53.482552Z",
     "shell.execute_reply.started": "2025-05-19T00:13:45.683634Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 9 ConvTransformerEncoderLayers\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"ribonanzanet2d-final\")\n",
    "\n",
    "from Network import *\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries=entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return Config(**config)\n",
    "\n",
    "class finetuned_RibonanzaNet(RibonanzaNet):\n",
    "    def __init__(self, config):\n",
    "        config.dropout=0.2\n",
    "        super(finetuned_RibonanzaNet, self).__init__(config)\n",
    "        self.use_gradient_checkpoint = False\n",
    "        self.ct_predictor=nn.Linear(64,1)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        \n",
    "    def forward(self,src):\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        _, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n",
    "\n",
    "        pairwise_features=pairwise_features+pairwise_features.permute(0,2,1,3) #symmetrize\n",
    "\n",
    "        output=self.ct_predictor(self.dropout(pairwise_features)) #predict\n",
    "\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "ribonet=finetuned_RibonanzaNet(load_config_from_yaml(\"ribonanzanet2d-final/configs/pairwise.yaml\")).cuda()\n",
    "ribonet.load_state_dict(torch.load(\"weights/RibonanzaNet-SS.pt\",map_location='cpu'))\n",
    "\n",
    "rna_fmodel, alphabet = fm.pretrained.rna_fm_t12(config[\"rna_fm_weights\"])\n",
    "rnafm_batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# After you build each model (≈ lines 190–200)\n",
    "ribonet.eval()\n",
    "for p in ribonet.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "rna_fmodel.eval()\n",
    "for p in rna_fmodel.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "\n",
    "reverse_map = {nt: i for i, nt in enumerate(\"GUAC\")}\n",
    "\n",
    "def tokens_to_str(tokens):\n",
    "    tokens = tokens.tolist()\n",
    "    seq = \"\"\n",
    "    for token in tokens:\n",
    "        seq+=reverse_map[token]\n",
    "    return seq\n",
    "\n",
    "def init_coords_from_sequence(\n",
    "    seq,\n",
    "    bppm,\n",
    "    contact_d=6.0,\n",
    "    noncontact_d=25.0,\n",
    "    mds_kwargs=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq: RNA sequence str of len L\n",
    "        bppm: pair prob matrix of (L, L)\n",
    "        contact_d: target distance (Å) for predicted base pairs\n",
    "        noncontact_d: target distance (Å) for non-paired nucleotides\n",
    "        mds_kwargs: extra args for sklearn.manifold.MDS\n",
    "\n",
    "    Returns:\n",
    "        coords: tensor of shape (L,3)\n",
    "    \"\"\"\n",
    "\n",
    "    P = bppm\n",
    "    \n",
    "    L = P.shape[0]\n",
    "    \n",
    "    # 2. Build graph & run MWM\n",
    "    G = nx.Graph()\n",
    "    for i in range(L):\n",
    "        for j in range(i+4, L):  # enforce minimum loop length\n",
    "            p = P[i, j]\n",
    "            if p > 0.01:  # skip ultra-low probs\n",
    "                w = torch.log(p / (1 - p + 1e-9))\n",
    "                if w > 0:\n",
    "                    G.add_edge(i, j, weight=w)\n",
    "    match = nx.algorithms.matching.max_weight_matching(\n",
    "        G, maxcardinality=False\n",
    "    )  # O(L³) but usually <0.05 s for L≈400\n",
    "\n",
    "    # 3. Build a target distance matrix\n",
    "    D = np.full((L, L), noncontact_d, dtype=float)\n",
    "    for i, j in match:\n",
    "        D[i, j] = D[j, i] = contact_d\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "\n",
    "    # 4. Run classical MDS to embed into ℝ³\n",
    "    mds_kwargs = mds_kwargs or {}\n",
    "    mds = MDS(\n",
    "        n_components=3,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        n_init=4,\n",
    "        max_iter=300,\n",
    "        **mds_kwargs\n",
    "    )\n",
    "    coords = mds.fit_transform(D)  # (L,3), preserves the “contact” proximities\n",
    "    return torch.from_numpy(coords).float().cuda()\n",
    "\n",
    "vocab = {\"A\":0, \"C\":1, \"G\":2, \"U\":3}\n",
    "def get_ribonet_bpp(sequence): # returns tensor of shape (1, L, L)\n",
    "    src = sequence.unsqueeze(0)\n",
    "    return ribonet(src).sigmoid().detach().cpu()\n",
    "    \n",
    "def get_rnaf_seq_encoding(sequence): \n",
    "    # sequence = tokens_to_str(sequence[0]) # CURRENTLY ONLY SUPPORTS BATCH SIZE 1 ### FIX ###\n",
    "    \n",
    "    # Prepare data\n",
    "    data = [\n",
    "        (\"Sequence\", sequence)\n",
    "    ]\n",
    "    _, _, batch_tokens = rnafm_batch_converter(data) # [(id, seq),...] -> batch label, seq, tokens\n",
    "\n",
    "    # Extract embeddings (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = rna_fmodel(batch_tokens, repr_layers=[rna_fmodel.num_layers])\n",
    "    # print(results[\"representations\"])\n",
    "    token_embeddings = results[\"representations\"][rna_fmodel.num_layers].cuda()\n",
    "    token_embeddings = token_embeddings[:, 1:-1, :]\n",
    "    return token_embeddings # (1, seqlen, 640)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T01:35:21.629615Z",
     "iopub.status.busy": "2025-05-19T01:35:21.629202Z",
     "iopub.status.idle": "2025-05-19T01:35:21.923170Z",
     "shell.execute_reply": "2025-05-19T01:35:21.922743Z",
     "shell.execute_reply.started": "2025-05-19T01:35:21.629555Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "454it [00:00, 4524.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 4, 1, 2, 3, 3, 1, 1, 3, 2, 2, 3, 4, 4, 2, 3, 2, 1, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1504it [00:00, 5320.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped: 16\n",
      "{'rna_id': '17RA', 'sequence': tensor([1, 1, 4, 1, 2, 3, 3, 1, 1, 3, 2, 2, 3, 4, 4, 2, 3, 2, 1, 4, 4]), 'label': tensor([[ 35.8570,  30.2300,  23.9680,  19.2960,  16.3620,  15.6360,  16.9700,\n",
      "          20.3910,  24.3700,  26.3420,  23.9180,  24.9380,  25.5880,  28.3330,\n",
      "          28.9490,  26.7490,  24.1190,  22.7710,  22.3300,  25.3730,  29.9620],\n",
      "        [-10.7690, -12.0750, -11.3560,  -9.8740,  -6.0470,  -1.5490,   2.8930,\n",
      "           6.8620,   9.6300,  12.3650,  16.0230,  15.5650,  10.0950,   7.8040,\n",
      "           4.8360,   1.3900,  -2.8210,  -7.6650, -13.6260, -17.3560, -19.0250],\n",
      "        [ -7.5480,  -8.6140,  -7.6900,  -4.7780,  -0.7060,   2.4630,   4.6260,\n",
      "           5.5490,   3.3480,  -0.5940,  -5.4180, -11.2430, -10.0040,  -6.2550,\n",
      "          -0.7560,   3.2870,   6.0260,   5.3550,   3.1070,  -0.2930,  -3.3090]])}\n",
      "1504\n",
      "1488\n",
      "1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_seq = [] #list of shape (S, L)\n",
    "new_xyz = [] #list of numpys of shape (S, L, 3)\n",
    "\n",
    "# Loaded data mapping: GUAC -> 1234\n",
    "# New map -> guac -> 0123\n",
    "# Local data mapping: ACGU -> 0123\n",
    "skipped = 0\n",
    "for idx, datapoint in tqdm(enumerate(loaded_data)):\n",
    "    # data.seq is a string of shape (L)\n",
    "    # data.xyz is an array of shape (L, 3)\n",
    "    # loaded_data is a list of dicts of shape {sequence: tensor(L), label: tensor(3,L)} (transposing label gives tensor(L,3)\n",
    "\n",
    "    real_seq = []\n",
    "\n",
    "    if idx==0: print(datapoint['sequence'])\n",
    "    for n in datapoint['sequence']:\n",
    "        if n.item()-1 >= 0:\n",
    "            real_seq.append(n.item()-1)\n",
    "        else:\n",
    "            real_seq.append(99)\n",
    "            continue\n",
    "\n",
    "    if not 99 in real_seq:\n",
    "        new_seq.append(real_seq)\n",
    "        xyzs = datapoint['label'].t()\n",
    "        xyzs = xyzs.numpy().astype(\"float32\")\n",
    "        xyzs[xyzs < -1e17] = float(\"nan\")\n",
    "        new_xyz.append(xyzs)\n",
    "    else:\n",
    "        skipped+=1\n",
    "print(f\"Skipped: {skipped}\")\n",
    "print(loaded_data[0])\n",
    "print(len(loaded_data))\n",
    "print(len(new_seq))\n",
    "print(len(new_xyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:00.440929Z",
     "iopub.status.busy": "2025-05-19T00:14:00.440490Z",
     "iopub.status.idle": "2025-05-19T00:14:00.461914Z",
     "shell.execute_reply": "2025-05-19T00:14:00.461221Z",
     "shell.execute_reply.started": "2025-05-19T00:14:00.440895Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 6218\n",
      "incl/total ratio: 0.7972074468085106\n"
     ]
    }
   ],
   "source": [
    "valid_indices = []\n",
    "max_len_seen = 0\n",
    "for i, xyz in enumerate(new_xyz):\n",
    "    # Track the maximum length\n",
    "    if len(xyz) > max_len_seen:\n",
    "        max_len_seen = len(xyz)\n",
    "\n",
    "    nan_ratio = np.isnan(xyz).mean()\n",
    "    seq_len = len(xyz)\n",
    "    # Keep sequence if it meets criteria\n",
    "    if (nan_ratio <= 0.5) and (config[\"min_len_filter\"] < seq_len <= config[\"max_len_filter\"]):\n",
    "        valid_indices.append(i)\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len_seen}\")\n",
    "print(f\"incl/total ratio: {len(valid_indices)/len(new_xyz)}\")\n",
    "# Filter sequences & xyz based on valid_indices\n",
    "# train_sequences = train_sequences.loc[valid_indices].reset_index(drop=True)\n",
    "# try:\n",
    "new_seq = [new_seq[i] for i in valid_indices]\n",
    "# except:\n",
    "    # print(f\"Err on index {i} of new_seq\")\n",
    "\n",
    "# try:\n",
    "new_xyz = [new_xyz[i] for i in valid_indices]\n",
    "# except:\n",
    "    # print(f\"Err on index {i} of new_xyz\")\n",
    "# init_seq_embeddings = [init_seq_embeddings[i] for i in valid_indices]\n",
    "# initial_3ds = [initial_3ds[i] for i in valid_indices]\n",
    "# bppms = [bppms[i] for i in valid_indices]\n",
    "\n",
    "# Prepare final data dictionary\n",
    "\n",
    "data = {\n",
    "    \"sequence\": new_seq,\n",
    "    \"temporal_cutoff\": train_sequences[\"temporal_cutoff\"].tolist(),\n",
    "    \"description\": train_sequences[\"description\"].tolist(),\n",
    "    \"all_sequences\": train_sequences[\"all_sequences\"].tolist(),\n",
    "    \"xyz\": new_xyz\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TRAIN / VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:09.443315Z",
     "iopub.status.busy": "2025-05-19T00:14:09.442995Z",
     "iopub.status.idle": "2025-05-19T00:14:09.449059Z",
     "shell.execute_reply": "2025-05-19T00:14:09.448397Z",
     "shell.execute_reply.started": "2025-05-19T00:14:09.443288Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cutoff_date = pd.Timestamp(config[\"cutoff_date\"])\n",
    "test_cutoff_date = pd.Timestamp(config[\"test_cutoff_date\"])\n",
    "\n",
    "train_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if pd.Timestamp(date_str) <= cutoff_date]\n",
    "test_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if cutoff_date < pd.Timestamp(date_str) <= test_cutoff_date]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "all_indices = list(range(len(data[\"sequence\"])))\n",
    "train_indices, test_indices = train_test_split(all_indices, test_size=0.15, random_state=config[\"seed\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:14.718082Z",
     "iopub.status.busy": "2025-05-19T00:14:14.717770Z",
     "iopub.status.idle": "2025-05-19T00:14:14.721934Z",
     "shell.execute_reply": "2025-05-19T00:14:14.721077Z",
     "shell.execute_reply.started": "2025-05-19T00:14:14.718058Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199\n"
     ]
    }
   ],
   "source": [
    "print(len(data['sequence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:19.005094Z",
     "iopub.status.busy": "2025-05-19T00:14:19.004671Z",
     "iopub.status.idle": "2025-05-19T00:14:19.017714Z",
     "shell.execute_reply": "2025-05-19T00:14:19.016874Z",
     "shell.execute_reply.started": "2025-05-19T00:14:19.005058Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, a ratio of 1.0 remains\n",
      "After cleaning, a ratio of 1.0 remains\n"
     ]
    }
   ],
   "source": [
    "def rna_collate_fn(batch):\n",
    "    sequences = [item[\"sequence\"] for item in batch]\n",
    "    xyzs = [item[\"xyz\"] for item in batch]\n",
    "\n",
    "    # Create masks before padding\n",
    "    masks = [torch.ones(len(seq), dtype=torch.bool) for seq in sequences]\n",
    "\n",
    "    # Pad sequences and coordinates\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=4)  # 4 = <PAD> token index\n",
    "    padded_xyzs = pad_sequence(xyzs, batch_first=True, padding_value=0.0)\n",
    "    padded_masks = pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        \"sequence\": padded_sequences,\n",
    "        \"xyz\": padded_xyzs,\n",
    "        \"mask\": padded_masks\n",
    "    }\n",
    "\n",
    "\n",
    "class RNA3D_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for 3D RNA structures.\n",
    "    \"\"\"\n",
    "    def __init__(self, indices, data_dict, max_len=1024):\n",
    "        self.indices = indices\n",
    "        self.data = data_dict\n",
    "        self.max_len = max_len\n",
    "        self.nt_to_idx = {nt: i for i, nt in enumerate(\"GUAC\")}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "   \n",
    "    def clean_sequences(self):\n",
    "        clean_seqs = []\n",
    "        clean_xyz = []\n",
    "        clean_indices = []\n",
    "        \n",
    "        # DATA SHAPE:\n",
    "        # sequence: list of shape (S, L) with GUAC maps\n",
    "        # xyz: list of numpys of shape (S, L, 3)\n",
    "\n",
    "        \n",
    "        for seq, coords in zip(self.data[\"sequence\"], self.data[\"xyz\"]):\n",
    "            if len(seq) != len(coords) or len(seq) > self.max_len:\n",
    "                continue\n",
    "            clean_seqs.append(seq)\n",
    "            clean_xyz.append(coords)\n",
    "        print(f\"After cleaning, a ratio of {len(clean_seqs)/len(self.data['sequence'])} remains\")\n",
    "        self.data[\"sequence\"] = clean_seqs\n",
    "        self.data[\"xyz\"] = clean_xyz\n",
    "        self.indices = list(range(len(clean_seqs)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_idx = self.indices[idx]\n",
    "        # Convert nucleotides to integer tokens\n",
    "        sequence = []\n",
    "        sequence = self.data[\"sequence\"][data_idx]\n",
    "        # sequence = [self.nt_to_idx[nt] for nt in self.data[\"sequence\"][data_idx]]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        # Convert xyz to torch tensor\n",
    "        xyz = torch.tensor(self.data[\"xyz\"][data_idx], dtype=torch.float32)\n",
    "\n",
    "\n",
    "        return {\"sequence\": sequence, \"xyz\": xyz}\n",
    "\n",
    "train_dataset = RNA3D_Dataset(train_indices, data, max_len=config[\"max_len\"])\n",
    "train_dataset.clean_sequences()\n",
    "val_dataset = RNA3D_Dataset(test_indices, data, max_len=config[\"max_len\"])\n",
    "val_dataset.clean_sequences()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:24.477476Z",
     "iopub.status.busy": "2025-05-19T00:14:24.477170Z",
     "iopub.status.idle": "2025-05-19T00:14:24.481897Z",
     "shell.execute_reply": "2025-05-19T00:14:24.480872Z",
     "shell.execute_reply.started": "2025-05-19T00:14:24.477453Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=6,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=rna_collate_fn\n",
    "    )\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=6, persistent_workers=True, pin_memory=True, \n",
    "                        collate_fn=rna_collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODEL, CONFIG CLASSES & HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:28.172685Z",
     "iopub.status.busy": "2025-05-19T00:14:28.172417Z",
     "iopub.status.idle": "2025-05-19T00:14:28.206861Z",
     "shell.execute_reply": "2025-05-19T00:14:28.206202Z",
     "shell.execute_reply.started": "2025-05-19T00:14:28.172652Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strip_self_loops(src: torch.Tensor,\n",
    "                     dst: torch.Tensor,\n",
    "                     *feats: torch.Tensor):\n",
    "    keep = src != dst\n",
    "    new_feats = [f[keep] for f in feats]\n",
    "    return (src[keep], dst[keep], *new_feats)\n",
    "\n",
    "# NEW helper – drop-in replacement for _extract_mwm_pairs (put under utilities)\n",
    "@torch.jit.script\n",
    "def _nussinov_pairs(P: torch.Tensor,\n",
    "                    min_loop: int = 4,\n",
    "                    min_prob: float = 0.01) -> List[Tuple[int,int]]:\n",
    "    \"\"\"\n",
    "    Batched-friendly Nussinov DP (O(L³)) on GPU.\n",
    "    Returns list[(i,j)] with i<j.\n",
    "    \"\"\"\n",
    "    L = P.size(0)\n",
    "    S = P.new_zeros((L, L))          # DP table\n",
    "    # fill table\n",
    "    for d in range(min_loop+1, L):   # distance between i,j\n",
    "        i = torch.arange(0, L-d, device=P.device)\n",
    "        j = i + d\n",
    "        s0 = S[i+1, j]                       # i unpaired\n",
    "        s1 = S[i, j-1]                       # j unpaired\n",
    "        pair_prob = torch.where(P[i, j] >= min_prob,\n",
    "                                torch.log(P[i, j] / (1-P[i,j]+1e-9)),\n",
    "                                P.new_zeros(i.size()))\n",
    "        s2 = S[i+1, j-1] + pair_prob         # i-j pair\n",
    "        # bifurcation max_k S[i,k] + S[k+1,j]\n",
    "        best_bif = torch.zeros_like(i, dtype=P.dtype)\n",
    "        for k in range(1, d-min_loop):\n",
    "            best_bif = torch.max(best_bif, S[i, i+k] + S[i+k+1, j])\n",
    "        S[i, j] = torch.max(torch.stack([s0, s1, s2, best_bif]), dim=0).values\n",
    "\n",
    "    # traceback\n",
    "    pairs: List[Tuple[int,int]] = []\n",
    "    stack: List[Tuple[int,int]] = [(0, L-1)]\n",
    "    while stack:\n",
    "        i, j = stack.pop()\n",
    "        if i >= j: continue\n",
    "        if S[i, j] == S[i+1, j]:\n",
    "            stack.append((i+1, j))\n",
    "        elif S[i, j] == S[i, j-1]:\n",
    "            stack.append((i, j-1))\n",
    "        elif P[i, j] >= min_prob and S[i, j] == S[i+1, j-1] + torch.log(P[i,j]/(1-P[i,j]+1e-9)):\n",
    "            pairs.append((i, j))\n",
    "            stack.append((i+1, j-1))\n",
    "        else:  # bifurcation – find split k\n",
    "            for k in range(i+1, j):\n",
    "                if S[i, j] == S[i, k] + S[k+1, j]:\n",
    "                    stack.append((i, k))\n",
    "                    stack.append((k+1, j))\n",
    "                    break\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:32.660687Z",
     "iopub.status.busy": "2025-05-19T00:14:32.660424Z",
     "iopub.status.idle": "2025-05-19T00:14:33.465906Z",
     "shell.execute_reply": "2025-05-19T00:14:33.465044Z",
     "shell.execute_reply.started": "2025-05-19T00:14:32.660666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assume the provided files (transformer.py, fiber.py, etc.) are in the python path\n",
    "# Or place them in the same directory\n",
    "from se3_transformer.model.transformer import SE3Transformer\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.runtime.utils import degree_to_dim # Helper if needed\n",
    "\n",
    "# --- Assume these tensors are provided as input to the forward pass ---\n",
    "# sequence_rep: (B, L, 640) float tensor - Per-residue sequence embeddings\n",
    "# pair_rep:     (B, L, L, 128) float tensor - Pairwise embeddings\n",
    "# bppm:         (B, L, L) float tensor - Base Pairing Probability Matrix\n",
    "# initial_coords: (B, L, 3) float tensor - Initial 3D coordinates\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "class CoordinateRefiner(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_embed_dim: int = 640,\n",
    "                 pair_embed_dim: int = 128,\n",
    "                 num_layers: int = 3,      # Simple depth\n",
    "                 num_heads: int = 4,       # Moderate number of heads\n",
    "                 hidden_channels: int = 32,# Moderate hidden channels\n",
    "                 num_degrees: int = 2,      # Use degree 0 and 1 in hidden layers\n",
    "                 knn_k: int = 16, # k for k-NN edges\n",
    "                 sec_struct_threshold: float = 0.5, # Threshold for proxy secondary structure edges\n",
    "                 high_prob_threshold: float = 0.3,\n",
    "                 mwm_min_loop_len: int = 4, # Min loop length for MWM pairing\n",
    "                 mwm_min_prob: float = 0.01, # Min BPPM prob for considering MWM edge\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seq_embed_dim: Dimension of the input sequence embeddings.\n",
    "            pair_embed_dim: Dimension of the input pairwise embeddings.\n",
    "            num_layers: Number of SE3Transformer layers.\n",
    "            num_heads: Number of attention heads.\n",
    "            hidden_channels: Number of channels per degree in hidden layers.\n",
    "            num_degrees: Number of degrees (0 to num_degrees-1) in hidden layers.\n",
    "            knn_k: Number of nearest neighbors for k-NN edges.\n",
    "            sec_struct_threshold: BPPM threshold proxy for secondary structure pairs.\n",
    "            high_prob_threshold: BPPM threshold for additional high-probability pairs.\n",
    "            mwm_min_loop_len: Minimum loop length constraint for MWM graph construction.\n",
    "            mwm_min_prob: Minimum BPPM probability to consider an edge in MWM graph.\n",
    "            high_prob_threshold: BPPM threshold for additional high-probability pairs.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_embed_dim = seq_embed_dim\n",
    "        self.pair_embed_dim = pair_embed_dim\n",
    "        # Edge features combine pairwise embeddings and bppm scalar\n",
    "        self.edge_feature_dim = pair_embed_dim + 1 # Add 1 for bppm\n",
    "        self.knn_k = knn_k\n",
    "        self.sec_struct_threshold = sec_struct_threshold\n",
    "        self.high_prob_threshold = high_prob_threshold\n",
    "        self.mwm_min_loop_len = mwm_min_loop_len\n",
    "        self.mwm_min_prob = mwm_min_prob\n",
    "\n",
    "        # --- Define Fibers ---\n",
    "        # Input Node Fiber: Type 0 for sequence embeddings, Type 1 for coordinates\n",
    "        self.fiber_in = Fiber({\n",
    "            '0': self.seq_embed_dim, # Invariant sequence features\n",
    "            '1': 1                   # Equivariant coordinate features (1 channel of type 1)\n",
    "        })\n",
    "\n",
    "        # Input Edge Fiber: Type 0 for pairwise embeddings + bppm + distance (distance added internally)\n",
    "        # Note: The actual dimension passed to RadialProfile will be self.edge_feature_dim + 1\n",
    "        self.fiber_edge = Fiber({\n",
    "            '0': self.edge_feature_dim # All invariant edge features provided by user\n",
    "        })\n",
    "\n",
    "        # Hidden Fiber: Use degrees 0 to num_degrees-1\n",
    "        self.fiber_hidden = Fiber.create(num_degrees=num_degrees, num_channels=hidden_channels)\n",
    "\n",
    "        # Output Fiber: We only want the refined coordinates (Type 1)\n",
    "        self.fiber_out = Fiber({\n",
    "            '1': 1  # Output 1 channel of type 1 features (coordinate update)\n",
    "        })\n",
    "\n",
    "        # --- Instantiate the SE3 Transformer ---\n",
    "        self.se3_transformer = SE3Transformer(\n",
    "            num_layers=num_layers,\n",
    "            fiber_in=self.fiber_in,\n",
    "            fiber_hidden=self.fiber_hidden,\n",
    "            fiber_out=self.fiber_out,\n",
    "            num_heads=num_heads,\n",
    "            channels_div=2,          # Standard default\n",
    "            fiber_edge=self.fiber_edge, # Pass the user-provided part\n",
    "            return_type=1,           # Return only type 1 features (coordinate update)\n",
    "            pooling=None,            # We need per-node output\n",
    "            norm=True,               # Use normalization\n",
    "            use_layer_norm=True,     # Use layer norm\n",
    "            tensor_cores=torch.cuda.is_available(), # Auto-detect (can be overridden)\n",
    "            low_memory=False,         # Assume standard memory usage for now\n",
    "        )\n",
    "\n",
    "        # Print config only once during init\n",
    "        if not hasattr(CoordinateRefiner, '_config_printed'):\n",
    "            print(\"--- Model Configuration ---\")\n",
    "            print(f\"SE3 Layers: {num_layers}\")\n",
    "            print(f\"Attention Heads: {num_heads}\")\n",
    "            print(f\"Hidden Channels/Degree: {hidden_channels}\")\n",
    "            print(f\"Hidden Degrees: {num_degrees}\")\n",
    "            print(f\"Input Node Fiber: {self.fiber_in}\")\n",
    "            print(f\"Input Edge Fiber (User provided part): {self.fiber_edge}\")\n",
    "            print(f\"Hidden Fiber: {self.fiber_hidden}\")\n",
    "            print(f\"Output Fiber: {self.fiber_out}\")\n",
    "            print(f\"Using Tensor Cores: {self.se3_transformer.tensor_cores}\")\n",
    "            print(f\"Graph Edges: Backbone, SecStruct (MWM >{self.mwm_min_prob}, min_loop={self.mwm_min_loop_len}), kNN (k={self.knn_k}), HighProb (>{self.high_prob_threshold})\")\n",
    "            print(\"------------------\")\n",
    "            CoordinateRefiner._config_printed = True\n",
    "\n",
    "    # --- MWM Helper ---\n",
    "    def _extract_mwm_pairs(self, P: np.ndarray, min_loop_len: int = 4, min_prob: float = 0.01) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Extract secondary structure from BPPM via maximum-weight matching.\"\"\"\n",
    "        L = P.shape[0]\n",
    "        G = nx.Graph()\n",
    "        for i in range(L):\n",
    "            for j in range(i + min_loop_len, L): # Ensure min loop length\n",
    "                p = P[i, j]\n",
    "                if p > min_prob:\n",
    "                    # Use log-odds as weight (higher probability = higher weight)\n",
    "                    log_odds = np.log(p / (1 - p + 1e-9)) # safe denominator\n",
    "                    G.add_edge(i, j, weight=log_odds)\n",
    "\n",
    "        # Compute maximum weight matching\n",
    "        # maxcardinality=False ensures we maximize weight, not necessarily the number of edges\n",
    "        match = nx.algorithms.matching.max_weight_matching(G, maxcardinality=False)\n",
    "        # The result is a set of tuples, convert to list\n",
    "        return list(match)\n",
    "\n",
    "    def _get_backbone_edges(self, L: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generates backbone edges (i, i+1) and (i+1, i).\"\"\"\n",
    "        src = torch.arange(0, L - 1, device=device)\n",
    "        dst = torch.arange(1, L, device=device)\n",
    "        # Add edges in both directions\n",
    "        src_all = torch.cat([src, dst])\n",
    "        dst_all = torch.cat([dst, src])\n",
    "        return src_all, dst_all\n",
    "\n",
    "    def _get_secondary_structure_edges(self, bppm: torch.Tensor, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor, Set[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Generates secondary structure edges based on Maximum Weight Matching on the BPPM.\n",
    "        Returns edges in both directions and a set of unique pairs (i, j) where i < j.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get matched pairs using helper\n",
    "        matched_pairs = _nussinov_pairs(bppm, self.mwm_min_loop_len, self.mwm_min_prob)\n",
    "\n",
    "        if not matched_pairs: # Handle case where no pairs are matched\n",
    "            src_all = torch.tensor([], dtype=torch.long, device=device)\n",
    "            dst_all = torch.tensor([], dtype=torch.long, device=device)\n",
    "            pair_set = set()\n",
    "            return src_all, dst_all, pair_set\n",
    "\n",
    "        # Extract source and destination from matched pairs\n",
    "        src_list = [pair[0] for pair in matched_pairs]\n",
    "        dst_list = [pair[1] for pair in matched_pairs]\n",
    "\n",
    "        # Ensure pairs are stored as (min_idx, max_idx) in the set\n",
    "        pair_set = set((min(s, d), max(s, d)) for s, d in matched_pairs)\n",
    "\n",
    "        # Create tensors and add edges in both directions\n",
    "        src_match = torch.tensor(src_list, dtype=torch.long, device=device)\n",
    "        dst_match = torch.tensor(dst_list, dtype=torch.long, device=device)\n",
    "        src_all = torch.cat([src_match, dst_match])\n",
    "        dst_all = torch.cat([dst_match, src_match])\n",
    "\n",
    "        return src_all, dst_all, pair_set\n",
    "\n",
    "    def _get_knn_edges(self, coords: torch.Tensor, k: int\n",
    "                       ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Pure-Torch k-NN (L ≤ 1 024, k ≈ 16 is cheap).\n",
    "        Returns undirected edges without self-loops.\n",
    "        \"\"\"\n",
    "        L = coords.size(0)\n",
    "        # pairwise ℓ₂ distance matrix\n",
    "        dists = torch.cdist(coords, coords, p=2)           # (L,L)\n",
    "        dists.fill_diagonal_(float('inf'))                 # mask self\n",
    "        _, nn_idx = torch.topk(dists, min(k, L-1), largest=False)    # (L,k)\n",
    "\n",
    "        src = torch.arange(L, device=coords.device).unsqueeze(1).repeat(1, k).flatten()\n",
    "        dst = nn_idx.flatten()\n",
    "        # make edges bidirectional\n",
    "        src_all = torch.cat([src, dst])\n",
    "        dst_all = torch.cat([dst, src])\n",
    "        return src_all, dst_all\n",
    "    \n",
    "    # def _get_knn_edges(self, coords: torch.Tensor, k: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    #     \"\"\"Generates k-NN edges based on 3D coordinates, excluding self-loops.\"\"\"\n",
    "    #     # dgl.knn_graph computes distances and finds neighbors efficiently\n",
    "    #     # Note: By default, it creates edges (neighbor -> node).\n",
    "    #     # We want edges in both directions for message passing.\n",
    "    #     knn_graph = dgl.knn_graph(coords, k)\n",
    "    #     src, dst = knn_graph.edges()\n",
    "    #     # Add reverse edges\n",
    "    #     src_all = torch.cat([src, dst])\n",
    "    #     dst_all = torch.cat([dst, src])\n",
    "    #     return src_all, dst_all\n",
    "\n",
    "    def _get_high_prob_edges(\n",
    "            self,\n",
    "            bppm: torch.Tensor,\n",
    "            threshold: float,\n",
    "            exclude_pairs: Set[Tuple[int, int]]\n",
    "            ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Vectorised: upper-triangle mask + logical operations.\n",
    "        \"\"\"\n",
    "        L = bppm.size(0)\n",
    "        device = bppm.device\n",
    "\n",
    "        # basic masks\n",
    "        mask_upper = torch.triu(torch.ones(L, L, dtype=torch.bool, device=device), diagonal=1)\n",
    "        mask_thresh = bppm >= threshold\n",
    "        mask_adjacent = torch.ones_like(mask_upper)\n",
    "        idx = torch.arange(L-1, device=device)\n",
    "        mask_adjacent[idx, idx+1] = False  # kill (i,i+1)\n",
    "        mask_adjacent[idx+1, idx] = False\n",
    "\n",
    "        # MWM-exclusion mask\n",
    "        mask_excl = torch.ones_like(mask_upper)\n",
    "        if exclude_pairs:\n",
    "            ex_s, ex_d = zip(*exclude_pairs)\n",
    "            mask_excl[list(ex_s), list(ex_d)] = False\n",
    "            mask_excl[list(ex_d), list(ex_s)] = False\n",
    "\n",
    "        final = mask_upper & mask_thresh & mask_adjacent & mask_excl\n",
    "        src, dst = torch.nonzero(final, as_tuple=True)\n",
    "        src_all = torch.cat([src, dst])\n",
    "        dst_all = torch.cat([dst, src])\n",
    "        return src_all, dst_all\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                sequence_rep: torch.Tensor,\n",
    "                pair_rep: torch.Tensor,\n",
    "                bppm: torch.Tensor,\n",
    "                initial_coords: torch.Tensor\n",
    "                ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs one step of 3D coordinate refinement on a batch of structures using sparse graphs (MWM for SS).\n",
    "        Args see original docstring. Returns see original docstring.\n",
    "        \"\"\"\n",
    "        B, L = initial_coords.shape[:2]\n",
    "        device = initial_coords.device\n",
    "\n",
    "        graphs_list = []\n",
    "        total_src_list = []\n",
    "        total_dst_list = []\n",
    "        node_offset = 0\n",
    "\n",
    "        # 1. Build Individual Sparse Graphs for each item in the batch\n",
    "        for i in range(B):\n",
    "            coords_i = initial_coords[i] # (L, 3)\n",
    "            bppm_i = bppm[i]             # (L, L)\n",
    "            pair_i = pair_rep[i]     # (L, L, pair_dim)\n",
    "            # Get edges for this instance\n",
    "            src_bb, dst_bb = self._get_backbone_edges(L, device)\n",
    "            # Use MWM for secondary structure edges\n",
    "            src_ss, dst_ss, ss_pair_set = self._get_secondary_structure_edges(bppm_i, device)\n",
    "            src_knn, dst_knn = self._get_knn_edges(coords_i, self.knn_k)\n",
    "            # High prob edges exclude MWM pairs now\n",
    "            src_hp, dst_hp = self._get_high_prob_edges(bppm_i, self.high_prob_threshold, ss_pair_set)\n",
    "\n",
    "            # Combine all edge types\n",
    "            src_combined = torch.cat([src_bb, src_ss, src_knn, src_hp])\n",
    "            dst_combined = torch.cat([dst_bb, dst_ss, dst_knn, dst_hp])\n",
    "            \n",
    "            # Remove duplicate edges\n",
    "            combined_edges = torch.stack([src_combined, dst_combined], dim=1)\n",
    "            unique_edges = torch.unique(combined_edges, dim=0)\n",
    "            src_unique = unique_edges[:, 0]\n",
    "            dst_unique = unique_edges[:, 1]\n",
    "\n",
    "            edge_pair_feats = pair_i[src_unique, dst_unique]\n",
    "            edge_bppm = bppm_i[src_unique, dst_unique]\n",
    "            src_unique, dst_unique, edge_pair_feats, edge_bppm = strip_self_loops(\n",
    "                src_unique, dst_unique,\n",
    "                edge_pair_feats, edge_bppm\n",
    "            )\n",
    "\n",
    "            # Now build the graph (it’s already self‑loop–free):\n",
    "            g = dgl.graph((src_unique, dst_unique), num_nodes=L).to(device)\n",
    "\n",
    "            # And attach the features you just passed through:\n",
    "            g.edata['pair_feat'] = edge_pair_feats\n",
    "            g.edata['bppm']      = edge_bppm\n",
    "\n",
    "            graphs_list.append(g)\n",
    "\n",
    "            # Store edges with offset for later feature selection\n",
    "            total_src_list.append(src_unique + node_offset)\n",
    "            total_dst_list.append(dst_unique + node_offset)\n",
    "            node_offset += L\n",
    "\n",
    "        # 2. Batch Graphs\n",
    "        if not graphs_list: return initial_coords\n",
    "        batched_graph = dgl.batch(graphs_list)\n",
    "        N_total = batched_graph.num_nodes()\n",
    "\n",
    "        src_total = torch.cat(total_src_list)\n",
    "        dst_total = torch.cat(total_dst_list)\n",
    "        num_total_edges = src_total.shape[0]\n",
    "\n",
    "        if num_total_edges == 0:\n",
    "            print(\"Warning: Batched graph has no edges. Returning initial coordinates.\")\n",
    "            return initial_coords\n",
    "\n",
    "        # 3. Prepare Batched Node Features\n",
    "        node_seq_rep_flat = sequence_rep.reshape(N_total, self.seq_embed_dim)\n",
    "        node_coords_flat = initial_coords.reshape(N_total, 3)\n",
    "        node_feats = {\n",
    "            '0': node_seq_rep_flat.unsqueeze(-1),\n",
    "            '1': node_coords_flat.unsqueeze(1)\n",
    "        }\n",
    "\n",
    "        # 4. Prepare Batched Edge Features\n",
    "        batch_idx_src = src_total // L\n",
    "        node_idx_src = src_total % L\n",
    "        batch_idx_dst = dst_total // L\n",
    "        node_idx_dst = dst_total % L\n",
    "\n",
    "        edge_pair_feats = pair_rep[batch_idx_src, node_idx_src, node_idx_dst]\n",
    "        edge_bppm = bppm[batch_idx_src, node_idx_src, node_idx_dst].unsqueeze(-1)\n",
    "        combined_edge_feats = torch.cat([edge_pair_feats, edge_bppm], dim=1)\n",
    "        edge_feats = {\n",
    "            '0': combined_edge_feats.unsqueeze(-1)\n",
    "        }\n",
    "\n",
    "        # 5. Calculate Relative Positions\n",
    "        rel_pos = node_coords_flat[dst_total] - node_coords_flat[src_total]\n",
    "        batched_graph.edata['rel_pos'] = rel_pos\n",
    "\n",
    "        # 6. Forward Pass\n",
    "        delta_coords_flat = self.se3_transformer(batched_graph, node_feats, edge_feats)\n",
    "\n",
    "        # 7. Apply Coordinate Update\n",
    "        refined_coords_flat = node_coords_flat + delta_coords_flat.squeeze(1)\n",
    "\n",
    "        # 8. Reshape Output\n",
    "        refined_coords = refined_coords_flat.reshape(B, L, 3)\n",
    "\n",
    "        return refined_coords\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:42.343535Z",
     "iopub.status.busy": "2025-05-19T00:14:42.343111Z",
     "iopub.status.idle": "2025-05-19T00:14:42.355864Z",
     "shell.execute_reply": "2025-05-19T00:14:42.354847Z",
     "shell.execute_reply.started": "2025-05-19T00:14:42.343508Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "class PairEmbedding(nn.Module):\n",
    "    def __init__(self, d_seq, d_pair, d_hidden=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1, d_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_hidden, d_pair)\n",
    "        )\n",
    "        self.outer_product_mean = Outer_Product_Mean(in_dim=d_seq, pairwise_dim=d_pair)\n",
    "        self.rel_pos_embed = relpos(dim=d_pair)\n",
    "\n",
    "    def forward(self, seq_rep, bppm):\n",
    "        x = bppm.unsqueeze(-1)                       # (L,L,1) bppm is len 28\n",
    "        pair_embed = self.mlp(x)                        # (L,L,d_pair)\n",
    "        outer_prod_mean = self.outer_product_mean(seq_rep)  # seq_rep is len 30\n",
    "        rel_embeddings = self.rel_pos_embed(seq_rep)\n",
    "        summed_pair_rep = outer_prod_mean + rel_embeddings + pair_embed\n",
    "        return summed_pair_rep\n",
    "\n",
    "class ConvFormerBlocks(nn.Module):\n",
    "    def __init__(self, n_blocks, seq_dim, nhead, pair_dim,\n",
    "                 use_triangular_attention, dropout):\n",
    "        super(ConvFormerBlocks, self).__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ConvTransformerEncoderLayer(\n",
    "                d_model = seq_dim,\n",
    "                nhead = nhead,\n",
    "                dim_feedforward = seq_dim*3, \n",
    "                pairwise_dimension= pair_dim,\n",
    "                use_triangular_attention=use_triangular_attention,\n",
    "                dropout = dropout\n",
    "            )\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, seq_embedding, pair_embedding):\n",
    "        seqrep = seq_embedding\n",
    "        pairrep = pair_embedding\n",
    "        mask = torch.ones(seqrep.size(0), seqrep.size(1), dtype=torch.bool, device=seqrep.device)\n",
    "        for block in self.blocks:\n",
    "            def create_custom_forward(module):\n",
    "                def custom_forward(*inputs):\n",
    "                    return module(*inputs)\n",
    "                return custom_forward\n",
    "\n",
    "            seqrep, pairrep = checkpoint(create_custom_forward(block), seqrep, pairrep, mask)\n",
    "            # seqrep, pairrep = block(seqrep, pairrep, src_mask=mask)\n",
    "        return seqrep, pairrep\n",
    "\n",
    "class CoordinateRefinerBlocks(nn.Module):\n",
    "    def __init__(self, n_blocks, seq_dim, pair_dim, thresh):\n",
    "        super(CoordinateRefinerBlocks, self).__init__()\n",
    "        self.thresh = thresh\n",
    "        self.blocks = nn.ModuleList(CoordinateRefiner(seq_embed_dim=seq_dim,pair_embed_dim=pair_dim) for _ in range(n_blocks))\n",
    "        \n",
    "    def forward(self, sequence_rep, pair_rep, bppm,\n",
    "                initial_coords):\n",
    "        xyz = initial_coords\n",
    "        for refiner in self.blocks:\n",
    "            xyz = refiner(sequence_rep, pair_rep, bppm, xyz)\n",
    "        return xyz\n",
    "    \n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL INSTANTANTIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:47.072221Z",
     "iopub.status.busy": "2025-05-19T00:14:47.071944Z",
     "iopub.status.idle": "2025-05-19T00:14:47.150624Z",
     "shell.execute_reply": "2025-05-19T00:14:47.149998Z",
     "shell.execute_reply.started": "2025-05-19T00:14:47.072198Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing fresh model...\n",
      "--- Model Configuration ---\n",
      "SE3 Layers: 3\n",
      "Attention Heads: 4\n",
      "Hidden Channels/Degree: 32\n",
      "Hidden Degrees: 2\n",
      "Input Node Fiber: [FiberEl(degree=1, channels=1), FiberEl(degree=0, channels=640)]\n",
      "Input Edge Fiber (User provided part): [FiberEl(degree=0, channels=129)]\n",
      "Hidden Fiber: [FiberEl(degree=0, channels=32), FiberEl(degree=1, channels=32)]\n",
      "Output Fiber: [FiberEl(degree=1, channels=1)]\n",
      "Using Tensor Cores: True\n",
      "Graph Edges: Backbone, SecStruct (MWM >0.01, min_loop=4), kNN (k=16), HighProb (>0.3)\n",
      "------------------\n",
      "insted\n"
     ]
    }
   ],
   "source": [
    "class ChocolateNet(nn.Module):\n",
    "    \"\"\"\n",
    "    pretrained_state: either 0, 1, or 2 depending on how weights should be loaded:\n",
    "    - 0: no pretraining\n",
    "    - 1: load non-final pretrained weights\n",
    "    - 2: load final pretrained weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, thresh=0.20, pretrained_state=0, dropout=0.1):\n",
    "\n",
    "        super(ChocolateNet,self).__init__()\n",
    "        if pretrained_state==2:\n",
    "            print(\"loading final pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"final_pretrained_weights_path\"], map_location=\"cpu\"), strict = True\n",
    "            )\n",
    "        elif pretrained_state==1:\n",
    "            print(\"loading nonfinal pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"nonfinal_pretrained_weights_path\"], map_location=\"cpu\"), strict = True\n",
    "            )\n",
    "        elif pretrained_state==0:\n",
    "            print(\"initializing fresh model...\")\n",
    "        else:\n",
    "            raise ValueError(\"Unknown pretrained_state configuration. See class description.\")\n",
    "        \n",
    "        self.config = {\"gradient_accumulation_steps\": 1}\n",
    "        self.thresh = thresh\n",
    "        self.seq_dim = config[\"rna_fm_embedding_dim\"]\n",
    "        self.pair_dim = 128\n",
    "        self.heads = 8\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.pair_embedding = PairEmbedding(self.seq_dim, self.pair_dim)\n",
    "\n",
    "        self.sequence_transformer = ConvFormerBlocks(\n",
    "            n_blocks = 1,\n",
    "            seq_dim = self.seq_dim, \n",
    "            nhead = self.heads, \n",
    "            pair_dim = self.pair_dim,\n",
    "            use_triangular_attention=True,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        \n",
    "        # (3) RBF parameters for edge-length encoding\n",
    "        mu = torch.linspace(0, 20, 30)               # 30 Gaussians\n",
    "        sigma = 0.8 * torch.ones_like(mu)\n",
    "        self.register_buffer(\"rbf_mu\", mu)\n",
    "        self.register_buffer(\"rbf_sigma\", sigma)\n",
    "        \n",
    "        self.coord_refiner = CoordinateRefinerBlocks(\n",
    "            n_blocks = 1, seq_dim=self.seq_dim, pair_dim=self.pair_dim, thresh=self.thresh\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        sequence = sequence[0] # DOES NOT SUPPORT BATCH SIZE > 1, FIX!!\n",
    "        # 1) Get raw RNA-FM embeddings (1, L, d_seq)\n",
    "        fm_emb = get_rnaf_seq_encoding(sequence).cuda()      # → torch.FloatTensor on CPU\n",
    "\n",
    "        # 2) Get BPPM from RiboNet, convert to Tensor\n",
    "        bppm = get_ribonet_bpp(sequence).float().cuda()\n",
    "        # 3) Now build your pair embedding correctly\n",
    "        pair_embedding = self.pair_embedding(fm_emb, bppm)      # both use L\n",
    "        bppm_raw = bppm.squeeze(0)\n",
    "        \n",
    "        # # fm_embedding = get_rnaf_seq_encoding(sequence[0])\n",
    "        # bppm = get_ribonet_bpp(sequence[0])\n",
    "        # bppm_src = torch.from_numpy(bppm).float().cuda()\n",
    "        \n",
    "        \n",
    "        # pair_embedding = self.pair_embedding(fm_embedding, bppm_src)\n",
    "        \n",
    "        xyz_init = init_coords_from_sequence(sequence, bppm_raw).unsqueeze(0)\n",
    "        seq_rep, pair_rep = self.sequence_transformer(fm_emb, pair_embedding)\n",
    "        xyz_pred = self.coord_refiner(seq_rep, pair_rep, bppm, xyz_init)\n",
    "        return xyz_pred\n",
    "        \n",
    "# Instantiate the model\n",
    "model = ChocolateNet().cuda()\n",
    "print(\"insted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:14:53.126164Z",
     "iopub.status.busy": "2025-05-19T00:14:53.125900Z",
     "iopub.status.idle": "2025-05-19T00:14:53.136388Z",
     "shell.execute_reply": "2025-05-19T00:14:53.135462Z",
     "shell.execute_reply.started": "2025-05-19T00:14:53.126142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X, Y, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances between every point in X and every point in Y.\n",
    "    Shape: (len(X), len(Y))\n",
    "    \"\"\"\n",
    "    return ((X[:, None] - Y[None, :])**2 + epsilon).sum(dim=-1).sqrt()\n",
    "\n",
    "def dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=None):\n",
    "    \"\"\"\n",
    "    Distance-based RMSD.\n",
    "    pred_x, pred_y: predicted coordinates (usually the same tensor for X and Y).\n",
    "    gt_x, gt_y: ground truth coordinates.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    if d_clamp is not None:\n",
    "        diff_sq = diff_sq.clamp(max=d_clamp**2)\n",
    "\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def local_dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=30):\n",
    "    \"\"\"\n",
    "    Local distance-based RMSD, ignoring distances above a clamp threshold.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = (~torch.isnan(gt_dm)) & (gt_dm < d_clamp)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def dRMAE(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10):\n",
    "    \"\"\"\n",
    "    Distance-based Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff = torch.abs(pred_dm[mask] - gt_dm[mask])\n",
    "    return diff.mean() / Z\n",
    "\n",
    "def align_svd_mae(input_coords, target_coords, Z=10):\n",
    "    \"\"\"\n",
    "    Align input_coords to target_coords via SVD (Kabsch algorithm) and compute MAE.\n",
    "    \"\"\"\n",
    "    assert input_coords.shape == target_coords.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    # Create mask for valid points\n",
    "    mask = ~torch.isnan(target_coords.sum(dim=-1))\n",
    "    input_coords = input_coords[mask]\n",
    "    target_coords = target_coords[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input_coords.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target_coords.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input_coords - centroid_input\n",
    "    target_centered = target_coords - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (determinant R == 1)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt_adj = Vt.clone()   # Clone to avoid in-place modification issues\n",
    "        Vt_adj[-1, :] = -Vt_adj[-1, :]\n",
    "        R = Vt_adj @ U.T\n",
    "\n",
    "    # Rotate input and compute mean absolute error\n",
    "    aligned_input = (input_centered @ R.T) + centroid_target\n",
    "    return torch.abs(aligned_input - target_coords).mean() / Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:15:29.334611Z",
     "iopub.status.busy": "2025-05-19T00:15:29.334321Z",
     "iopub.status.idle": "2025-05-19T00:15:29.348410Z",
     "shell.execute_reply": "2025-05-19T00:15:29.347406Z",
     "shell.execute_reply.started": "2025-05-19T00:15:29.334583Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPLEMENT TRAIN() FROM SE3TRANSFORMER\n",
    "\n",
    "def train_model(model, train_dl, val_dl, epochs=50, cos_epoch=35, lr=3e-4, clip=1):\n",
    "    \"\"\"Train the model with a CosineAnnealingLR after `cos_epoch` epochs.\"\"\"\n",
    "    \n",
    "    optim_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.AdamW(optim_params, weight_decay=0.0, lr=lr)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(epochs - cos_epoch) * len(train_dl),\n",
    "    )\n",
    "    grad_accum_steps = model.config[\"gradient_accumulation_steps\"]\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_preds = None\n",
    "    use_amp = model.coord_refiner.blocks[0].se3_transformer.tensor_cores and device.type == 'cuda'\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_dl, desc=f\"Training Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Add profiling for the first few batches of the first epoch\n",
    "        profiling_enabled = (epoch == 0)\n",
    "        profile_lim = 15\n",
    "        fw_time = 0\n",
    "        for idx, batch in enumerate(train_pbar):\n",
    "            \n",
    "            sequence = batch[\"sequence\"].cuda()\n",
    "            gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "            #mask = batch[\"mask\"].cuda()\n",
    "            if profiling_enabled and idx < profile_lim:\n",
    "                if idx >= 1: print(f\"Avg fp: {fw_time/idx:.4f}\")\n",
    "                torch.cuda.synchronize()\n",
    "                start_forward = time.time()\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                torch.cuda.synchronize()\n",
    "                forward_time = time.time() - start_forward\n",
    "                torch.cuda.synchronize()\n",
    "                start_loss = time.time()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "                torch.cuda.synchronize()\n",
    "                loss_time = time.time() - start_loss\n",
    "                fw_add = forward_time\n",
    "                fw_time += fw_add\n",
    "                print(f\"Batch {idx}: Forward pass: {fw_add:.4f}s, Loss computation: {loss_time:.4f}s\")\n",
    "            else:\n",
    "                # Normal non-profiling training code (without autocast and scaler)\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "            \n",
    "            loss = loss / grad_accum_steps\n",
    "            loss.backward()\n",
    "            if (idx + 1) % grad_accum_steps == 0 or (idx + 1) == len(train_dl):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if (epoch + 1) > cos_epoch:\n",
    "                    scheduler.step()\n",
    "                            \n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (idx + 1)\n",
    "            train_pbar.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(val_dl):\n",
    "                sequence = batch[\"sequence\"].cuda()\n",
    "                gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "                #mask = batch[\"mask\"].cuda()\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.append((gt_xyz.cpu().numpy(), pred_xyz.cpu().numpy()))\n",
    "\n",
    "            val_loss /= len(val_dl)\n",
    "            print(f\"Validation Loss (Epoch {epoch+1}): {val_loss:.4f}\")\n",
    "\n",
    "            # Check for improvement\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_preds = val_preds\n",
    "                torch.save(model.state_dict(), config[\"save_weights_name\"])\n",
    "                print(f\"  -> New best model saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), config[\"save_weights_final\"])\n",
    "    return best_val_loss, best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. RUN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured batch size: 1\n",
      "Train loader batch size: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Configured batch size: {config['batch_size']}\")\n",
    "print(f\"Train loader batch size: {train_loader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:15:35.718934Z",
     "iopub.status.busy": "2025-05-19T00:15:35.718676Z",
     "iopub.status.idle": "2025-05-19T00:17:31.772048Z",
     "shell.execute_reply": "2025-05-19T00:17:31.771079Z",
     "shell.execute_reply.started": "2025-05-19T00:15:35.718913Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50:   0%|          | 0/1199 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Forward pass: 85.2210s, Loss computation: 1.3467s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.2279:   0%|          | 1/1199 [01:27<29:09:57, 87.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg fp: 85.2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.2623:   0%|          | 2/1199 [01:29<20:32:46, 61.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: Forward pass: 1.3891s, Loss computation: 0.0046s\n",
      "Avg fp: 43.3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.1469:   0%|          | 3/1199 [01:29<14:25:01, 43.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2: Forward pass: 0.3937s, Loss computation: 0.0041s\n",
      "Avg fp: 29.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.7188:   0%|          | 4/1199 [01:30<10:07:52, 30.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3: Forward pass: 0.3998s, Loss computation: 0.0047s\n",
      "Avg fp: 21.8509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.6420:   0%|          | 5/1199 [01:30<7:08:22, 21.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4: Forward pass: 0.4542s, Loss computation: 0.0038s\n",
      "Avg fp: 17.5715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4414:   1%|          | 6/1199 [01:31<5:02:16, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5: Forward pass: 0.3715s, Loss computation: 0.0041s\n",
      "Avg fp: 14.7049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.3841:   1%|          | 7/1199 [01:31<3:33:54, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6: Forward pass: 0.3565s, Loss computation: 0.0036s\n",
      "Avg fp: 12.6551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4284:   1%|          | 8/1199 [01:32<2:35:15,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7: Forward pass: 0.8617s, Loss computation: 0.0033s\n",
      "Avg fp: 11.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4353:   1%|          | 9/1199 [01:33<1:52:19,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8: Forward pass: 0.5525s, Loss computation: 0.0045s\n",
      "Avg fp: 10.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4303:   1%|          | 10/1199 [01:33<1:21:44,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9: Forward pass: 0.4591s, Loss computation: 0.0045s\n",
      "Avg fp: 9.0459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4401:   1%|          | 11/1199 [01:34<1:00:12,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10: Forward pass: 0.4299s, Loss computation: 0.0058s\n",
      "Avg fp: 8.2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4174:   1%|          | 12/1199 [01:35<48:02,  2.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11: Forward pass: 0.9191s, Loss computation: 0.0033s\n",
      "Avg fp: 7.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4096:   1%|          | 13/1199 [01:35<37:38,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12: Forward pass: 0.6149s, Loss computation: 0.0033s\n",
      "Avg fp: 7.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4598:   1%|          | 14/1199 [01:37<37:36,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13: Forward pass: 1.7858s, Loss computation: 0.0033s\n",
      "Avg fp: 6.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.4235:   1%|▏         | 15/1199 [01:38<28:45,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14: Forward pass: 0.3324s, Loss computation: 0.0034s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.2527:   3%|▎         | 39/1199 [01:55<57:25,  2.97s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f1690fe0c9e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     best_loss, best_predictions = train_model(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         train_dl=DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-21f115028774>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, val_dl, epochs, cos_epoch, lr, clip)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# Normal non-profiling training code (without autocast and scaler)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mpred_xyz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdRMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_xyz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malign_svd_mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_xyz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7bee5713f736>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# 2) Get BPPM from RiboNet, convert to Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mbppm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ribonet_bpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;31m# 3) Now build your pair embedding correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mpair_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpair_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfm_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbppm\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# both use L\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c96fff9dfd25>\u001b[0m in \u001b[0;36mget_ribonet_bpp\u001b[0;34m(sequence)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ribonet_bpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# returns tensor of shape (1, L, L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mribonet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_rnaf_seq_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c96fff9dfd25>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairwise_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mpairwise_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairwise_features\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpairwise_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#symmetrize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/beta-fold-main/proj/ribonanzanet2d-final/Network.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, src, src_mask, return_aw)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m#spawn outer product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_loss, best_predictions = train_model(\n",
    "        model=model,\n",
    "        train_dl=DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=rna_collate_fn\n",
    "    ),\n",
    "        val_dl=DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=rna_collate_fn\n",
    "    ),\n",
    "        epochs=50,         # or config[\"epochs\"]\n",
    "        cos_epoch=35,      # or config[\"cos_epoch\"]\n",
    "        lr=3e-4,\n",
    "        clip=1\n",
    "    )\n",
    "    print(f\"Best Validation Loss: {best_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T00:08:33.960551Z",
     "iopub.status.busy": "2025-05-19T00:08:33.960221Z",
     "iopub.status.idle": "2025-05-19T00:08:33.976125Z",
     "shell.execute_reply": "2025-05-19T00:08:33.975425Z",
     "shell.execute_reply.started": "2025-05-19T00:08:33.960520Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1fc2658a3a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdebatchloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msequence_batch_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Keep on CPU for inspection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "debatchloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=0,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=rna_collate_fn\n",
    "    )\n",
    "\n",
    "for idx, batch in enumerate(debatchloader):\n",
    "    if idx == 14:\n",
    "        sequence_batch_cpu = batch[\"sequence\"] # Keep on CPU for inspection\n",
    "        gt_xyz_batch_cpu = batch[\"xyz\"]\n",
    "        mask_batch_cpu = batch[\"mask\"]\n",
    "        print(f\"--- DEBUG: Data for 15th batch ---\")\n",
    "        print(f\"Sequence (shape {sequence_batch_cpu.shape}):\\n{sequence_batch_cpu}\")\n",
    "        print(f\"XYZ (shape {gt_xyz_batch_cpu.shape})\") # XYZ less likely to cause assert\n",
    "        print(f\"Mask (shape {mask_batch_cpu.shape}):\\n{mask_batch_cpu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-17T19:20:35.904522Z",
     "iopub.status.idle": "2025-05-17T19:20:35.904733Z",
     "shell.execute_reply": "2025-05-17T19:20:35.904649Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(config[\"test_data_path\"]) # target_id,sequence,temporal_cutoff,description,all_sequences\n",
    "print(test_df.head(10))\n",
    "test_model = FinetunedRibonanzaNet(model_cfg, pretrained_state=2).cuda()\n",
    "test_model.eval()\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Running inference\"):\n",
    "    seq_id = row[\"target_id\"]\n",
    "    seq = row[\"sequence\"]\n",
    "    \n",
    "    token_map = {'A': 0, 'C': 1, 'U': 2, 'G': 3}\n",
    "    token_ids = torch.tensor([token_map[c] for c in seq], dtype=torch.long).unsqueeze(0).cuda()  # shape (1, L)\n",
    "    mask = torch.ones_like(token_ids).cuda()  # or derive if needed\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5):  # generate 5 predictions\n",
    "            pred_xyz = test_model(token_ids, mask).squeeze(0).cpu().numpy()  # shape (L, 3)\n",
    "            preds.append(pred_xyz)\n",
    "\n",
    "    preds = np.stack(preds, axis=0)  # shape (5, L, 3)\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        resname = seq[i]\n",
    "        resid = i + 1\n",
    "        flat_xyz = preds[:, i, :].flatten()  # (x1,y1,z1,...,x5,y5,z5)\n",
    "        row = [f\"{seq_id}\", resname, resid] + flat_xyz.tolist()\n",
    "        submission_rows.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "columns = [\"ID\", \"resname\", \"resid\"] + [f\"{axis}_{i+1}\" for i in range(5) for axis in [\"x\", \"y\", \"z\"]]\n",
    "submission = pd.DataFrame(submission_rows, columns=columns)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Inference complete! Saved to submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11403143,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 4299272,
     "sourceId": 7639698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459124,
     "sourceId": 8318191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
