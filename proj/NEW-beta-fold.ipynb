{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:33:49.658697Z",
     "iopub.status.busy": "2025-05-04T15:33:49.657776Z",
     "iopub.status.idle": "2025-05-04T15:34:09.834151Z",
     "shell.execute_reply": "2025-05-04T15:34:09.833428Z",
     "shell.execute_reply.started": "2025-05-04T15:33:49.658663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.41.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting rna-fm\n",
      "  Downloading rna_fm-0.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rna-fm) (1.26.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from rna-fm) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from rna-fm) (4.66.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from rna-fm) (1.3.0)\n",
      "Collecting ptflops (from rna-fm)\n",
      "  Downloading ptflops-0.7.4-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rna-fm) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->rna-fm) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->rna-fm) (2023.4)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from ptflops->rna-fm) (2.1.1+cu121)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->rna-fm) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->rna-fm) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->rna-fm) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->rna-fm) (1.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops->rna-fm) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops->rna-fm) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops->rna-fm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops->rna-fm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops->rna-fm) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops->rna-fm) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops->rna-fm) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->ptflops->rna-fm) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0->ptflops->rna-fm) (1.3.0)\n",
      "Downloading rna_fm-0.2.2-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ptflops-0.7.4-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: ptflops, rna-fm\n",
      "Successfully installed ptflops-0.7.4 rna-fm-0.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch_geometric) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2020.6.20)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCompleted pip process\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install einops\n",
    "!pip install bitsandbytes\n",
    "!pip install rna-fm # https://github.com/ml4bio/RNA-FM\n",
    "!pip install torch_geometric\n",
    "!pip install networkx\n",
    "# os.chdir(\"/notebooks/NEW-SE3Transformer\")\n",
    "# !pip install -e .\n",
    "# !pip install -r requirements.txt\n",
    "# # !pip install --pre dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
    "# !pip install dgl\n",
    "# os.chdir(\"/notebooks/proj\")\n",
    "\n",
    "print(\"Completed pip process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:34:16.600399Z",
     "iopub.status.busy": "2025-05-04T15:34:16.600043Z",
     "iopub.status.idle": "2025-05-04T15:34:16.605636Z",
     "shell.execute_reply": "2025-05-04T15:34:16.604551Z",
     "shell.execute_reply.started": "2025-05-04T15:34:16.600373Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/notebooks/NEW-SE3Transformer\")\n",
    "sys.path.append(\"/notebooks/RNAstructure/exe\")\n",
    "# import RNAstructure\n",
    "# sys.path.append(\"/notebooks/GCNfold\")\n",
    "# from GCNfold import models\n",
    "# from nets.gcnfold_net import GCNFoldNet_UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:35:03.867829Z",
     "iopub.status.busy": "2025-05-04T15:35:03.867394Z",
     "iopub.status.idle": "2025-05-04T15:35:03.874039Z",
     "shell.execute_reply": "2025-05-04T15:35:03.872036Z",
     "shell.execute_reply.started": "2025-05-04T15:35:03.867803Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T15:35:24.638267Z",
     "iopub.status.busy": "2025-05-04T15:35:24.638267Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#----- MIGHT HAVE TO  RUN BLOCK TWICE TO RESOLVE TYPERROR && DO NOT CHANGE -----##\n",
    "##################################################################################\n",
    "# !pip install torchdata==0.7.0\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# from se3_transformer.model import *\n",
    "from sklearn.manifold import MDS\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import fm\n",
    "from sklearn.manifold import MDS\n",
    "from torch_geometric.data import Data\n",
    "import dgl\n",
    "import torch_geometric\n",
    "# import RNA\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CONFIG & SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:26:09.965698Z",
     "iopub.status.busy": "2025-05-04T03:26:09.965087Z",
     "iopub.status.idle": "2025-05-04T03:26:09.972137Z",
     "shell.execute_reply": "2025-05-04T03:26:09.971461Z",
     "shell.execute_reply.started": "2025-05-04T03:26:09.965690Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 1024,\n",
    "    \"batch_size\": 1,\n",
    "    \"model_config_path\": \"ribonanzanet2d-final/configs/pairwise.yaml\",\n",
    "    \"max_len_filter\": 1024,\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    \"train_sequences_path\": \"data/Competition/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"data/Competition/train_labels.csv\",\n",
    "    \"test_data_path\": \"data/Competition/test_sequences.csv\",\n",
    "    \"combined_train_data_path\": \"data/Combined/total_processed_rna_data.pt\",\n",
    "    \"final_pretrained_weights_path\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "    \"nonfinal_pretrained_weights_path\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_name\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_final\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "    \"rna_fm_weights\": \"weights/RNA-FM_pretrained.pth\",\n",
    "    \"path_to_GCNFold_weights\": \"weights/model_unet_99.pth\",\n",
    "    \"rna_fm_embedding_dim\": 640 # default 640; DO NOT CHANGE\n",
    "}\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])\n",
    "\n",
    "# import shutil\n",
    "# shutil.copy(\"/root/.cache/torch/hub/checkpoints/RNA-FM_pretrained.pth\", config[\"rna_fm_weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:26:11.620684Z",
     "iopub.status.busy": "2025-05-04T03:26:11.620233Z",
     "iopub.status.idle": "2025-05-04T03:26:17.177001Z",
     "shell.execute_reply": "2025-05-04T03:26:17.176629Z",
     "shell.execute_reply.started": "2025-05-04T03:26:11.620666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting XYZ data: 100%|██████████| 844/844 [00:05<00:00, 159.97it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load CSVs\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "# Create a pdb_id field\n",
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(\n",
    "    lambda x: x.split(\"_\")[0] + \"_\" + x.split(\"_\")[1]\n",
    ")\n",
    "\n",
    "# Collect xyz data for each sequence\n",
    "all_xyz = []\n",
    "for pdb_id in tqdm(train_sequences[\"target_id\"], desc=\"Collecting XYZ data\"):\n",
    "    df = train_labels[train_labels[\"pdb_id\"] == pdb_id]\n",
    "    xyz = df[[\"x_1\", \"y_1\", \"z_1\"]].to_numpy().astype(\"float32\")\n",
    "    xyz[xyz < -1e17] = float(\"nan\")\n",
    "    all_xyz.append(xyz)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 SECONDARY DATA (BPPMs, initial 3D structs, initial sequence embeddings, etc.) GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:26:23.708822Z",
     "iopub.status.busy": "2025-05-04T03:26:23.708409Z",
     "iopub.status.idle": "2025-05-04T03:26:28.537549Z",
     "shell.execute_reply": "2025-05-04T03:26:28.536940Z",
     "shell.execute_reply.started": "2025-05-04T03:26:23.708822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 9 ConvTransformerEncoderLayers\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"ribonanzanet2d-final\")\n",
    "\n",
    "from Network import *\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries=entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return Config(**config)\n",
    "\n",
    "class finetuned_RibonanzaNet(RibonanzaNet):\n",
    "    def __init__(self, config):\n",
    "        config.dropout=0.2\n",
    "        super(finetuned_RibonanzaNet, self).__init__(config)\n",
    "        self.use_gradient_checkpoint = False\n",
    "        self.ct_predictor=nn.Linear(64,1)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        \n",
    "    def forward(self,src):\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        _, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n",
    "\n",
    "        pairwise_features=pairwise_features+pairwise_features.permute(0,2,1,3) #symmetrize\n",
    "\n",
    "        output=self.ct_predictor(self.dropout(pairwise_features)) #predict\n",
    "\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "ribonet=finetuned_RibonanzaNet(load_config_from_yaml(\"ribonanzanet2d-final/configs/pairwise.yaml\")).cuda()\n",
    "ribonet.load_state_dict(torch.load(\"weights/RibonanzaNet-SS.pt\",map_location='cpu'))\n",
    "ribonet.eval()\n",
    "\n",
    "rna_fmodel, alphabet = fm.pretrained.rna_fm_t12(config[\"rna_fm_weights\"])\n",
    "rnafm_batch_converter = alphabet.get_batch_converter()\n",
    "rna_fmodel.eval()\n",
    "\n",
    "reverse_map = {\n",
    "    0: \"A\", 1: \"C\", 2: \"G\", 3: \"U\"\n",
    "}\n",
    "\n",
    "def tokens_to_str(tokens):\n",
    "    tokens = tokens.tolist()\n",
    "    seq = \"\"\n",
    "    for token in tokens:\n",
    "        seq+=reverse_map[token]\n",
    "    return seq\n",
    "\n",
    "def init_coords_from_sequence(\n",
    "    seq,\n",
    "    bppm,\n",
    "    contact_d=6.0,\n",
    "    noncontact_d=25.0,\n",
    "    mds_kwargs=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq: RNA sequence str of len L\n",
    "        bppm: pair prob matrix of (L, L)\n",
    "        contact_d: target distance (Å) for predicted base pairs\n",
    "        noncontact_d: target distance (Å) for non-paired nucleotides\n",
    "        mds_kwargs: extra args for sklearn.manifold.MDS\n",
    "\n",
    "    Returns:\n",
    "        coords: tensor of shape (L,3)\n",
    "    \"\"\"\n",
    "\n",
    "    P = bppm\n",
    "    \n",
    "    L = P.shape[0]\n",
    "    \n",
    "    # 2. Build graph & run MWM\n",
    "    G = nx.Graph()\n",
    "    for i in range(L):\n",
    "        for j in range(i+4, L):  # enforce minimum loop length\n",
    "            p = P[i, j]\n",
    "            if p > 0.01:  # skip ultra-low probs\n",
    "                w = torch.log(p / (1 - p + 1e-9))\n",
    "                if w > 0:\n",
    "                    G.add_edge(i, j, weight=w)\n",
    "    match = nx.algorithms.matching.max_weight_matching(\n",
    "        G, maxcardinality=False\n",
    "    )  # O(L³) but usually <0.05 s for L≈400\n",
    "\n",
    "    # 3. Build a target distance matrix\n",
    "    D = np.full((L, L), noncontact_d, dtype=float)\n",
    "    for i, j in match:\n",
    "        D[i, j] = D[j, i] = contact_d\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "\n",
    "    # 4. Run classical MDS to embed into ℝ³\n",
    "    mds_kwargs = mds_kwargs or {}\n",
    "    mds = MDS(\n",
    "        n_components=3,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        n_init=4,\n",
    "        max_iter=300,\n",
    "        **mds_kwargs\n",
    "    )\n",
    "    coords = mds.fit_transform(D)  # (L,3), preserves the “contact” proximities\n",
    "    return torch.from_numpy(coords).float().cuda()\n",
    "\n",
    "vocab = {\"A\":0, \"C\":1, \"G\":2, \"U\":3}\n",
    "def get_ribonet_bpp(sequence): # tensor of shape (1, L, L)\n",
    "    src = sequence.unsqueeze(0)\n",
    "    return ribonet(src).sigmoid().detach().cpu()\n",
    "    \n",
    "def get_rnaf_seq_encoding(sequence): \n",
    "    # sequence = tokens_to_str(sequence[0]) # CURRENTLY ONLY SUPPORTS BATCH SIZE 1 ### FIX ###\n",
    "     \n",
    "    # Prepare data\n",
    "    data = [\n",
    "        (\"Sequence\", sequence)\n",
    "    ]\n",
    "    _, _, batch_tokens = rnafm_batch_converter(data) # [(id, seq),...] -> batch label, seq, tokens\n",
    "\n",
    "    # Extract embeddings (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = rna_fmodel(batch_tokens, repr_layers=[rna_fmodel.num_layers])\n",
    "    # print(results[\"representations\"])\n",
    "    token_embeddings = results[\"representations\"][rna_fmodel.num_layers].cuda()\n",
    "    token_embeddings = token_embeddings[:, 1:-1, :]\n",
    "    return token_embeddings # (1, seqlen, 640)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:26:32.701744Z",
     "iopub.status.busy": "2025-05-04T03:26:32.701508Z",
     "iopub.status.idle": "2025-05-04T03:26:32.713500Z",
     "shell.execute_reply": "2025-05-04T03:26:32.712907Z",
     "shell.execute_reply.started": "2025-05-04T03:26:32.701727Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 4298\n"
     ]
    }
   ],
   "source": [
    "valid_indices = []\n",
    "max_len_seen = 0\n",
    "\n",
    "for i, xyz in enumerate(all_xyz):\n",
    "    # Track the maximum length\n",
    "    if len(xyz) > max_len_seen:\n",
    "        max_len_seen = len(xyz)\n",
    "\n",
    "    nan_ratio = np.isnan(xyz).mean()\n",
    "    seq_len = len(xyz)\n",
    "    # Keep sequence if it meets criteria\n",
    "    if (nan_ratio <= 0.5) and (config[\"min_len_filter\"] < seq_len <= config[\"max_len_filter\"]):\n",
    "        valid_indices.append(i)\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len_seen}\")\n",
    "\n",
    "# Filter sequences & xyz based on valid_indices\n",
    "train_sequences = train_sequences.loc[valid_indices].reset_index(drop=True)\n",
    "all_xyz = [all_xyz[i] for i in valid_indices]\n",
    "# init_seq_embeddings = [init_seq_embeddings[i] for i in valid_indices]\n",
    "# initial_3ds = [initial_3ds[i] for i in valid_indices]\n",
    "# bppms = [bppms[i] for i in valid_indices]\n",
    "\n",
    "# Prepare final data dictionary\n",
    "data = {\n",
    "    \"sequence\": train_sequences[\"sequence\"].tolist(),\n",
    "    \"temporal_cutoff\": train_sequences[\"temporal_cutoff\"].tolist(),\n",
    "    \"description\": train_sequences[\"description\"].tolist(),\n",
    "    \"all_sequences\": train_sequences[\"all_sequences\"].tolist(),\n",
    "    \"xyz\": all_xyz\n",
    "    # \"base_pair_matrices\": bppms,\n",
    "    # \"3d_inits\": tertiary_inits,\n",
    "    # \"seq_embedding_inits\": seq_emb_inits\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TRAIN / VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:26:34.641202Z",
     "iopub.status.busy": "2025-05-04T03:26:34.640956Z",
     "iopub.status.idle": "2025-05-04T03:26:34.646672Z",
     "shell.execute_reply": "2025-05-04T03:26:34.646139Z",
     "shell.execute_reply.started": "2025-05-04T03:26:34.641185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cutoff_date = pd.Timestamp(config[\"cutoff_date\"])\n",
    "test_cutoff_date = pd.Timestamp(config[\"test_cutoff_date\"])\n",
    "\n",
    "train_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if pd.Timestamp(date_str) <= cutoff_date]\n",
    "test_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if cutoff_date < pd.Timestamp(date_str) <= test_cutoff_date]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "all_indices = list(range(len(data[\"sequence\"])))\n",
    "train_indices, test_indices = train_test_split(all_indices, test_size=0.1, random_state=config[\"seed\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:26:37.181354Z",
     "iopub.status.busy": "2025-05-04T03:26:37.180588Z",
     "iopub.status.idle": "2025-05-04T03:26:37.191114Z",
     "shell.execute_reply": "2025-05-04T03:26:37.190515Z",
     "shell.execute_reply.started": "2025-05-04T03:26:37.181333Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rna_collate_fn(batch):\n",
    "    sequences = [item[\"sequence\"] for item in batch]\n",
    "    xyzs = [item[\"xyz\"] for item in batch]\n",
    "\n",
    "    # Create masks before padding\n",
    "    masks = [torch.ones(len(seq), dtype=torch.bool) for seq in sequences]\n",
    "\n",
    "    # Pad sequences and coordinates\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=4)  # 4 = <PAD> token index\n",
    "    padded_xyzs = pad_sequence(xyzs, batch_first=True, padding_value=0.0)\n",
    "    padded_masks = pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        \"sequence\": padded_sequences,\n",
    "        \"xyz\": padded_xyzs,\n",
    "        \"mask\": padded_masks\n",
    "    }\n",
    "\n",
    "\n",
    "class RNA3D_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for 3D RNA structures.\n",
    "    \"\"\"\n",
    "    def __init__(self, indices, data_dict, max_len=384):\n",
    "        self.indices = indices\n",
    "        self.data = data_dict\n",
    "        self.max_len = max_len\n",
    "        self.nt_to_idx = {nt: i for i, nt in enumerate(\"ACGU\")}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "   \n",
    "    def clean_sequences(self):\n",
    "        clean_seqs = []\n",
    "        clean_xyz = []\n",
    "        clean_indices = []\n",
    "\n",
    "        for seq, coords in zip(self.data[\"sequence\"], self.data[\"xyz\"]):\n",
    "            if 'X' in seq or coords is None or len(seq) != len(coords):\n",
    "                continue\n",
    "            clean_seqs.append(seq)\n",
    "            clean_xyz.append(coords)\n",
    "\n",
    "        self.data[\"sequence\"] = clean_seqs\n",
    "        self.data[\"xyz\"] = clean_xyz\n",
    "        self.indices = list(range(len(clean_seqs)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_idx = self.indices[idx]\n",
    "        # Convert nucleotides to integer tokens\n",
    "        sequence = []\n",
    "\n",
    "        sequence = [self.nt_to_idx[nt] for nt in self.data[\"sequence\"][data_idx]]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        # Convert xyz to torch tensor\n",
    "        xyz = torch.tensor(self.data[\"xyz\"][data_idx], dtype=torch.float32)\n",
    "\n",
    "        # If sequence is longer than max_len, randomly crop\n",
    "        if len(sequence) > self.max_len:\n",
    "            crop_start = np.random.randint(len(sequence) - self.max_len)\n",
    "            crop_end = crop_start + self.max_len\n",
    "            sequence = sequence[crop_start:crop_end]\n",
    "            xyz = xyz[crop_start:crop_end]\n",
    "\n",
    "        return {\"sequence\": sequence, \"xyz\": xyz}\n",
    "\n",
    "train_dataset = RNA3D_Dataset(train_indices, data, max_len=config[\"max_len\"])\n",
    "train_dataset.clean_sequences()\n",
    "val_dataset = RNA3D_Dataset(test_indices, data, max_len=config[\"max_len\"])\n",
    "val_dataset.clean_sequences()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=8,  # Adjust based on CPU cores\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=rna_collate_fn\n",
    "    )\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=8, pin_memory=True, \n",
    "                        collate_fn=rna_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODEL, CONFIG CLASSES & HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:33:38.495007Z",
     "iopub.status.busy": "2025-05-04T03:33:38.494696Z",
     "iopub.status.idle": "2025-05-04T03:33:38.519392Z",
     "shell.execute_reply": "2025-05-04T03:33:38.518846Z",
     "shell.execute_reply.started": "2025-05-04T03:33:38.494983Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "from typing import Dict, Tuple, List, Set\n",
    "\n",
    "# Assume the provided files (transformer.py, fiber.py, etc.) are in the python path\n",
    "# Or place them in the same directory\n",
    "from se3_transformer.model.transformer import SE3Transformer\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.runtime.utils import degree_to_dim # Helper if needed\n",
    "\n",
    "# --- Assume these tensors are provided as input to the forward pass ---\n",
    "# sequence_rep: (B, L, 640) float tensor - Per-residue sequence embeddings\n",
    "# pair_rep:     (B, L, L, 128) float tensor - Pairwise embeddings\n",
    "# bppm:         (B, L, L) float tensor - Base Pairing Probability Matrix\n",
    "# initial_coords: (B, L, 3) float tensor - Initial 3D coordinates\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "class CoordinateRefiner(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_embed_dim: int = 640,\n",
    "                 pair_embed_dim: int = 128,\n",
    "                 num_layers: int = 3,      # Simple depth\n",
    "                 num_heads: int = 4,       # Moderate number of heads\n",
    "                 hidden_channels: int = 32,# Moderate hidden channels\n",
    "                 num_degrees: int = 2,      # Use degree 0 and 1 in hidden layers\n",
    "                 knn_k: int = 16, # k for k-NN edges\n",
    "                 sec_struct_threshold: float = 0.5, # Threshold for proxy secondary structure edges\n",
    "                 high_prob_threshold: float = 0.3,\n",
    "                 mwm_min_loop_len: int = 4, # Min loop length for MWM pairing\n",
    "                 mwm_min_prob: float = 0.01, # Min BPPM prob for considering MWM edge\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seq_embed_dim: Dimension of the input sequence embeddings.\n",
    "            pair_embed_dim: Dimension of the input pairwise embeddings.\n",
    "            num_layers: Number of SE3Transformer layers.\n",
    "            num_heads: Number of attention heads.\n",
    "            hidden_channels: Number of channels per degree in hidden layers.\n",
    "            num_degrees: Number of degrees (0 to num_degrees-1) in hidden layers.\n",
    "            knn_k: Number of nearest neighbors for k-NN edges.\n",
    "            sec_struct_threshold: BPPM threshold proxy for secondary structure pairs.\n",
    "            high_prob_threshold: BPPM threshold for additional high-probability pairs.\n",
    "            mwm_min_loop_len: Minimum loop length constraint for MWM graph construction.\n",
    "            mwm_min_prob: Minimum BPPM probability to consider an edge in MWM graph.\n",
    "            high_prob_threshold: BPPM threshold for additional high-probability pairs.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_embed_dim = seq_embed_dim\n",
    "        self.pair_embed_dim = pair_embed_dim\n",
    "        # Edge features combine pairwise embeddings and bppm scalar\n",
    "        self.edge_feature_dim = pair_embed_dim + 1 # Add 1 for bppm\n",
    "        self.knn_k = knn_k\n",
    "        self.sec_struct_threshold = sec_struct_threshold\n",
    "        self.high_prob_threshold = high_prob_threshold\n",
    "        self.mwm_min_loop_len = mwm_min_loop_len\n",
    "        self.mwm_min_prob = mwm_min_prob\n",
    "\n",
    "        # --- Define Fibers ---\n",
    "        # Input Node Fiber: Type 0 for sequence embeddings, Type 1 for coordinates\n",
    "        self.fiber_in = Fiber({\n",
    "            '0': self.seq_embed_dim, # Invariant sequence features\n",
    "            '1': 1                   # Equivariant coordinate features (1 channel of type 1)\n",
    "        })\n",
    "\n",
    "        # Input Edge Fiber: Type 0 for pairwise embeddings + bppm + distance (distance added internally)\n",
    "        # Note: The actual dimension passed to RadialProfile will be self.edge_feature_dim + 1\n",
    "        self.fiber_edge = Fiber({\n",
    "            '0': self.edge_feature_dim # All invariant edge features provided by user\n",
    "        })\n",
    "\n",
    "        # Hidden Fiber: Use degrees 0 to num_degrees-1\n",
    "        self.fiber_hidden = Fiber.create(num_degrees=num_degrees, num_channels=hidden_channels)\n",
    "\n",
    "        # Output Fiber: We only want the refined coordinates (Type 1)\n",
    "        self.fiber_out = Fiber({\n",
    "            '1': 1  # Output 1 channel of type 1 features (coordinate update)\n",
    "        })\n",
    "\n",
    "        # --- Instantiate the SE3 Transformer ---\n",
    "        self.se3_transformer = SE3Transformer(\n",
    "            num_layers=num_layers,\n",
    "            fiber_in=self.fiber_in,\n",
    "            fiber_hidden=self.fiber_hidden,\n",
    "            fiber_out=self.fiber_out,\n",
    "            num_heads=num_heads,\n",
    "            channels_div=2,          # Standard default\n",
    "            fiber_edge=self.fiber_edge, # Pass the user-provided part\n",
    "            return_type=1,           # Return only type 1 features (coordinate update)\n",
    "            pooling=None,            # We need per-node output\n",
    "            norm=True,               # Use normalization\n",
    "            use_layer_norm=True,     # Use layer norm\n",
    "            tensor_cores=torch.cuda.is_available(), # Auto-detect (can be overridden)\n",
    "            low_memory=False,         # Assume standard memory usage for now\n",
    "        )\n",
    "\n",
    "        # Print config only once during init\n",
    "        if not hasattr(CoordinateRefiner, '_config_printed'):\n",
    "            print(\"--- Model Configuration ---\")\n",
    "            print(f\"SE3 Layers: {num_layers}\")\n",
    "            print(f\"Attention Heads: {num_heads}\")\n",
    "            print(f\"Hidden Channels/Degree: {hidden_channels}\")\n",
    "            print(f\"Hidden Degrees: {num_degrees}\")\n",
    "            print(f\"Input Node Fiber: {self.fiber_in}\")\n",
    "            print(f\"Input Edge Fiber (User provided part): {self.fiber_edge}\")\n",
    "            print(f\"Hidden Fiber: {self.fiber_hidden}\")\n",
    "            print(f\"Output Fiber: {self.fiber_out}\")\n",
    "            print(f\"Using Tensor Cores: {self.se3_transformer.tensor_cores}\")\n",
    "            print(f\"Graph Edges: Backbone, SecStruct (MWM >{self.mwm_min_prob}, min_loop={self.mwm_min_loop_len}), kNN (k={self.knn_k}), HighProb (>{self.high_prob_threshold})\")\n",
    "            print(\"------------------\")\n",
    "            CoordinateRefiner._config_printed = True\n",
    "\n",
    "    # --- MWM Helper ---\n",
    "    def _extract_mwm_pairs(self, P: np.ndarray, min_loop_len: int = 4, min_prob: float = 0.01) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Extract secondary structure from BPPM via maximum-weight matching.\"\"\"\n",
    "        L = P.shape[0]\n",
    "        G = nx.Graph()\n",
    "        for i in range(L):\n",
    "            for j in range(i + min_loop_len, L): # Ensure min loop length\n",
    "                p = P[i, j]\n",
    "                if p > min_prob:\n",
    "                    # Use log-odds as weight (higher probability = higher weight)\n",
    "                    log_odds = np.log(p / (1 - p + 1e-9)) # safe denominator\n",
    "                    G.add_edge(i, j, weight=log_odds)\n",
    "\n",
    "        # Compute maximum weight matching\n",
    "        # maxcardinality=False ensures we maximize weight, not necessarily the number of edges\n",
    "        match = nx.algorithms.matching.max_weight_matching(G, maxcardinality=False)\n",
    "        # The result is a set of tuples, convert to list\n",
    "        return list(match)\n",
    "\n",
    "    def _get_backbone_edges(self, L: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generates backbone edges (i, i+1) and (i+1, i).\"\"\"\n",
    "        src = torch.arange(0, L - 1, device=device)\n",
    "        dst = torch.arange(1, L, device=device)\n",
    "        # Add edges in both directions\n",
    "        src_all = torch.cat([src, dst])\n",
    "        dst_all = torch.cat([dst, src])\n",
    "        return src_all, dst_all\n",
    "\n",
    "    def _get_secondary_structure_edges(self, bppm: torch.Tensor, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor, Set[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Generates secondary structure edges based on Maximum Weight Matching on the BPPM.\n",
    "        Returns edges in both directions and a set of unique pairs (i, j) where i < j.\n",
    "        \"\"\"\n",
    "        # Convert tensor to numpy array for networkx/numpy operations\n",
    "        bppm_np = bppm.cpu().numpy()\n",
    "\n",
    "        # Get matched pairs using MWM helper\n",
    "        matched_pairs = self._extract_mwm_pairs(bppm_np, self.mwm_min_loop_len, self.mwm_min_prob)\n",
    "\n",
    "        if not matched_pairs: # Handle case where no pairs are matched\n",
    "            src_all = torch.tensor([], dtype=torch.long, device=device)\n",
    "            dst_all = torch.tensor([], dtype=torch.long, device=device)\n",
    "            pair_set = set()\n",
    "            return src_all, dst_all, pair_set\n",
    "\n",
    "        # Extract source and destination from matched pairs\n",
    "        src_list = [pair[0] for pair in matched_pairs]\n",
    "        dst_list = [pair[1] for pair in matched_pairs]\n",
    "\n",
    "        # Ensure pairs are stored as (min_idx, max_idx) in the set\n",
    "        pair_set = set((min(s, d), max(s, d)) for s, d in matched_pairs)\n",
    "\n",
    "        # Create tensors and add edges in both directions\n",
    "        src_match = torch.tensor(src_list, dtype=torch.long, device=device)\n",
    "        dst_match = torch.tensor(dst_list, dtype=torch.long, device=device)\n",
    "        src_all = torch.cat([src_match, dst_match])\n",
    "        dst_all = torch.cat([dst_match, src_match])\n",
    "\n",
    "        return src_all, dst_all, pair_set\n",
    "\n",
    "    def _get_knn_edges(self, coords: torch.Tensor, k: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generates k-NN edges based on 3D coordinates, excluding self-loops.\"\"\"\n",
    "        # dgl.knn_graph computes distances and finds neighbors efficiently\n",
    "        # Note: By default, it creates edges (neighbor -> node).\n",
    "        # We want edges in both directions for message passing.\n",
    "        knn_graph = dgl.knn_graph(coords, k, exclude_self=True)\n",
    "        src, dst = knn_graph.edges()\n",
    "        # Add reverse edges\n",
    "        src_all = torch.cat([src, dst])\n",
    "        dst_all = torch.cat([dst, src])\n",
    "        return src_all, dst_all\n",
    "\n",
    "    def _get_high_prob_edges(self, bppm: torch.Tensor, threshold: float,\n",
    "                             exclude_pairs: Set[Tuple[int, int]], device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Generates high-probability edges (BPPM > threshold), excluding backbone and secondary structure pairs.\n",
    "        \"\"\"\n",
    "        L = bppm.shape[0]\n",
    "        # Consider only upper triangle (i < j)\n",
    "        upper_tri_indices = torch.triu_indices(L, L, offset=1, device=device) # offset=1 excludes diagonal\n",
    "        upper_tri_bppm = bppm[upper_tri_indices[0], upper_tri_indices[1]]\n",
    "\n",
    "        # Find pairs above threshold\n",
    "        mask = upper_tri_bppm >= threshold\n",
    "        src_potential = upper_tri_indices[0][mask]\n",
    "        dst_potential = upper_tri_indices[1][mask]\n",
    "\n",
    "        src_filtered_list = []\n",
    "        dst_filtered_list = []\n",
    "        for s, d in zip(src_potential, dst_potential):\n",
    "            s_item, d_item = s.item(), d.item()\n",
    "            # Ensure i < j representation for checking exclusion set\n",
    "            pair = (min(s_item, d_item), max(s_item, d_item))\n",
    "            # Exclude backbone (i, i+1) and secondary structure pairs\n",
    "            if abs(s_item - d_item) > 1 and pair not in exclude_pairs:\n",
    "                src_filtered_list.append(s)\n",
    "                dst_filtered_list.append(d)\n",
    "\n",
    "        if not src_filtered_list: # Handle empty case\n",
    "            src_filtered = torch.tensor([], dtype=torch.long, device=device)\n",
    "            dst_filtered = torch.tensor([], dtype=torch.long, device=device)\n",
    "        else:\n",
    "            src_filtered = torch.stack(src_filtered_list)\n",
    "            dst_filtered = torch.stack(dst_filtered_list)\n",
    "\n",
    "        # Add edges in both directions\n",
    "        src_all = torch.cat([src_filtered, dst_filtered])\n",
    "        dst_all = torch.cat([dst_filtered, src_filtered])\n",
    "\n",
    "        return src_all, dst_all\n",
    "\n",
    "    def forward(self,\n",
    "                sequence_rep: torch.Tensor,\n",
    "                pair_rep: torch.Tensor,\n",
    "                bppm: torch.Tensor,\n",
    "                initial_coords: torch.Tensor\n",
    "                ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs one step of 3D coordinate refinement on a batch of structures using sparse graphs (MWM for SS).\n",
    "        Args see original docstring. Returns see original docstring.\n",
    "        \"\"\"\n",
    "        B, L = initial_coords.shape[:2]\n",
    "        device = initial_coords.device\n",
    "\n",
    "        graphs_list = []\n",
    "        total_src_list = []\n",
    "        total_dst_list = []\n",
    "        node_offset = 0\n",
    "\n",
    "        # 1. Build Individual Sparse Graphs for each item in the batch\n",
    "        for i in range(B):\n",
    "            coords_i = initial_coords[i] # (L, 3)\n",
    "            bppm_i = bppm[i]             # (L, L)\n",
    "\n",
    "            # Get edges for this instance\n",
    "            src_bb, dst_bb = self._get_backbone_edges(L, device)\n",
    "            # Use MWM for secondary structure edges\n",
    "            src_ss, dst_ss, ss_pair_set = self._get_secondary_structure_edges(bppm_i, device)\n",
    "            src_knn, dst_knn = self._get_knn_edges(coords_i, self.knn_k, device)\n",
    "            # High prob edges exclude MWM pairs now\n",
    "            src_hp, dst_hp = self._get_high_prob_edges(bppm_i, self.high_prob_threshold, ss_pair_set, device)\n",
    "\n",
    "            # Combine all edge types\n",
    "            src_combined = torch.cat([src_bb, src_ss, src_knn, src_hp])\n",
    "            dst_combined = torch.cat([dst_bb, dst_ss, dst_knn, dst_hp])\n",
    "\n",
    "            # Remove duplicate edges\n",
    "            combined_edges = torch.stack([src_combined, dst_combined], dim=1)\n",
    "            unique_edges = torch.unique(combined_edges, dim=0)\n",
    "            src_unique = unique_edges[:, 0]\n",
    "            dst_unique = unique_edges[:, 1]\n",
    "\n",
    "            # Create individual graph\n",
    "            g = dgl.graph((src_unique, dst_unique), num_nodes=L).to(device)\n",
    "            graphs_list.append(g)\n",
    "\n",
    "            # Store edges with offset for later feature selection\n",
    "            total_src_list.append(src_unique + node_offset)\n",
    "            total_dst_list.append(dst_unique + node_offset)\n",
    "            node_offset += L\n",
    "\n",
    "        # 2. Batch Graphs\n",
    "        if not graphs_list: return initial_coords\n",
    "        batched_graph = dgl.batch(graphs_list)\n",
    "        N_total = batched_graph.num_nodes()\n",
    "\n",
    "        src_total = torch.cat(total_src_list)\n",
    "        dst_total = torch.cat(total_dst_list)\n",
    "        num_total_edges = src_total.shape[0]\n",
    "\n",
    "        if num_total_edges == 0:\n",
    "            print(\"Warning: Batched graph has no edges. Returning initial coordinates.\")\n",
    "            return initial_coords\n",
    "\n",
    "        # 3. Prepare Batched Node Features\n",
    "        node_seq_rep_flat = sequence_rep.reshape(N_total, self.seq_embed_dim)\n",
    "        node_coords_flat = initial_coords.reshape(N_total, 3)\n",
    "        node_feats = {\n",
    "            '0': node_seq_rep_flat.unsqueeze(-1),\n",
    "            '1': node_coords_flat.unsqueeze(1)\n",
    "        }\n",
    "\n",
    "        # 4. Prepare Batched Edge Features\n",
    "        batch_idx_src = src_total // L\n",
    "        node_idx_src = src_total % L\n",
    "        batch_idx_dst = dst_total // L\n",
    "        node_idx_dst = dst_total % L\n",
    "\n",
    "        edge_pair_feats = pair_rep[batch_idx_src, node_idx_src, node_idx_dst]\n",
    "        edge_bppm = bppm[batch_idx_src, node_idx_src, node_idx_dst].unsqueeze(-1)\n",
    "        combined_edge_feats = torch.cat([edge_pair_feats, edge_bppm], dim=1)\n",
    "        edge_feats = {\n",
    "            '0': combined_edge_feats.unsqueeze(-1)\n",
    "        }\n",
    "\n",
    "        # 5. Calculate Relative Positions\n",
    "        rel_pos = node_coords_flat[dst_total] - node_coords_flat[src_total]\n",
    "        batched_graph.edata['rel_pos'] = rel_pos\n",
    "\n",
    "        # 6. Forward Pass\n",
    "        delta_coords_flat = self.se3_transformer(batched_graph, node_feats, edge_feats)\n",
    "\n",
    "        # 7. Apply Coordinate Update\n",
    "        refined_coords_flat = node_coords_flat + delta_coords_flat.squeeze(1)\n",
    "\n",
    "        # 8. Reshape Output\n",
    "        refined_coords = refined_coords_flat.reshape(B, L, 3)\n",
    "\n",
    "        return refined_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:33:42.126328Z",
     "iopub.status.busy": "2025-05-04T03:33:42.126077Z",
     "iopub.status.idle": "2025-05-04T03:33:42.134344Z",
     "shell.execute_reply": "2025-05-04T03:33:42.133843Z",
     "shell.execute_reply.started": "2025-05-04T03:33:42.126311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "class PairEmbedding(nn.Module):\n",
    "    def __init__(self, d_seq, d_pair, d_hidden=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1, d_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_hidden, d_pair)\n",
    "        )\n",
    "        self.outer_product_mean = Outer_Product_Mean(in_dim=d_seq, pairwise_dim=d_pair)\n",
    "        self.rel_pos_embed = relpos(dim=d_pair)\n",
    "\n",
    "    def forward(self, seq_rep, bppm):\n",
    "        print(f\"embedding seq_rep of shape {seq_rep.shape}, and bppm of shape {bppm.shape}\")\n",
    "        x = bppm.unsqueeze(-1)                       # (L,L,1) bppm is len 28\n",
    "        pair_embed = self.mlp(x)                        # (L,L,d_pair)\n",
    "        outer_prod_mean = self.outer_product_mean(seq_rep)  # seq_rep is len 30\n",
    "        rel_embeddings = self.rel_pos_embed(seq_rep)\n",
    "        print(f\"Pair: {pair_embed.shape}, outer: {outer_prod_mean.shape}, relpos: {rel_embeddings.shape}\")\n",
    "        summed_pair_rep = outer_prod_mean + rel_embeddings + pair_embed\n",
    "        return summed_pair_rep\n",
    "\n",
    "class ConvFormerBlocks(nn.Module):\n",
    "    def __init__(self, n_blocks, seq_dim, nhead, pair_dim,\n",
    "                 use_triangular_attention, dropout):\n",
    "        super(ConvFormerBlocks, self).__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ConvTransformerEncoderLayer(\n",
    "                d_model = seq_dim,\n",
    "                nhead = nhead,\n",
    "                dim_feedforward = seq_dim*3, \n",
    "                pairwise_dimension= pair_dim,\n",
    "                use_triangular_attention=use_triangular_attention,\n",
    "                dropout = dropout\n",
    "            )\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, seq_embedding, pair_embedding):\n",
    "        print(f\"s: {seq_embedding.shape}, p: {pair_embedding.shape}\")\n",
    "        seqrep = seq_embedding\n",
    "        pairrep = pair_embedding\n",
    "        mask = torch.ones(seqrep.size(0), seqrep.size(1), dtype=torch.bool, device=seqrep.device)\n",
    "        for block in self.blocks:\n",
    "            seqrep, pairrep = block(seqrep, pairrep, src_mask=mask)\n",
    "        return seqrep, pairrep\n",
    "\n",
    "class CoordinateRefinerBlocks(nn.Module):\n",
    "    def __init__(self, n_blocks, seq_dim, pair_dim, thresh):\n",
    "        super(CoordinateRefinerBlocks, self).__init__()\n",
    "        self.thresh = thresh\n",
    "        self.blocks = nn.ModuleList(CoordinateRefiner(seq_embed_dim=seq_dim,pair_embed_dim=pair_dim) for _ in range(n_blocks))\n",
    "        \n",
    "    def forward(self, sequence_rep, pair_rep, bppm,\n",
    "                initial_coords):\n",
    "        xyz = initial_coords\n",
    "        for refiner in self.blocks:\n",
    "            xyz = refiner(sequence_rep, pair_rep, bppm, xyz)\n",
    "        return xyz\n",
    "    \n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL INSTANTANTIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:39:23.200428Z",
     "iopub.status.busy": "2025-05-04T03:39:23.199931Z",
     "iopub.status.idle": "2025-05-04T03:39:23.355256Z",
     "shell.execute_reply": "2025-05-04T03:39:23.354778Z",
     "shell.execute_reply.started": "2025-05-04T03:39:23.200406Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing fresh model...\n",
      "insted\n"
     ]
    }
   ],
   "source": [
    "class ChocolateNet(nn.Module):\n",
    "    \"\"\"\n",
    "    pretrained_state: either 0, 1, or 2 depending on how weights should be loaded:\n",
    "    - 0: no pretraining\n",
    "    - 1: load non-final pretrained weights\n",
    "    - 2: load final pretrained weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, thresh=0.20, pretrained_state=0, dropout=0.1):\n",
    "\n",
    "        super(ChocolateNet,self).__init__()\n",
    "        if pretrained_state==2:\n",
    "            print(\"loading final pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"final_pretrained_weights_path\"], map_location=\"cpu\"), strict = True\n",
    "            )\n",
    "        elif pretrained_state==1:\n",
    "            print(\"loading nonfinal pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"nonfinal_pretrained_weights_path\"], map_location=\"cpu\"), strict = True\n",
    "            )\n",
    "        elif pretrained_state==0:\n",
    "            print(\"initializing fresh model...\")\n",
    "        else:\n",
    "            raise ValueError(\"Unknown pretrained_state configuration. See class description.\")\n",
    "        \n",
    "        self.config = {\"gradient_accumulation_steps\": 1}\n",
    "        self.thresh = thresh\n",
    "        self.seq_dim = config[\"rna_fm_embedding_dim\"]\n",
    "        self.pair_dim = 128\n",
    "        self.heads = 8\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.pair_embedding = PairEmbedding(self.seq_dim, self.pair_dim)\n",
    "\n",
    "        self.sequence_transformer = ConvFormerBlocks(\n",
    "            n_blocks = 3,\n",
    "            seq_dim = self.seq_dim, \n",
    "            nhead = self.heads, \n",
    "            pair_dim = self.pair_dim,\n",
    "            use_triangular_attention=True,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        \n",
    "        # (3) RBF parameters for edge-length encoding\n",
    "        mu = torch.linspace(0, 20, 30)               # 30 Gaussians\n",
    "        sigma = 0.8 * torch.ones_like(mu)\n",
    "        self.register_buffer(\"rbf_mu\", mu)\n",
    "        self.register_buffer(\"rbf_sigma\", sigma)\n",
    "        \n",
    "        self.coord_refiner = CoordinateRefinerBlocks(\n",
    "            n_blocks = 1, seq_dim=self.seq_dim, pair_dim=self.pair_dim, thresh=self.thresh\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        sequence = sequence[0] # DOES NOT SUPPORT BATCH SIZE > 1, FIX!!\n",
    "        print(sequence.shape)\n",
    "        # 1) Get raw RNA-FM embeddings (1, L, d_seq)\n",
    "        fm_emb = get_rnaf_seq_encoding(sequence).cuda()      # → torch.FloatTensor on CPU\n",
    "\n",
    "        # 2) Get BPPM from RiboNet, convert to Tensor\n",
    "        bppm = get_ribonet_bpp(sequence).float().cuda()\n",
    "        # 3) Now build your pair embedding correctly\n",
    "        pair_embedding = self.pair_embedding(fm_emb, bppm)      # both use L\n",
    "        bppm_raw = bppm.squeeze(0)\n",
    "        \n",
    "        # # fm_embedding = get_rnaf_seq_encoding(sequence[0])\n",
    "        # bppm = get_ribonet_bpp(sequence[0])\n",
    "        # bppm_src = torch.from_numpy(bppm).float().cuda()\n",
    "        \n",
    "        \n",
    "        # pair_embedding = self.pair_embedding(fm_embedding, bppm_src)\n",
    "        \n",
    "        xyz_init = init_coords_from_sequence(sequence, bppm_raw).unsqueeze(0)\n",
    "        seq_rep, pair_rep = self.sequence_transformer(fm_emb, pair_embedding)\n",
    "        print(f\"Shapes: seqrep : {seq_rep.shape}, pr: {pair_rep.shape}, bppm: {bppm.shape}, xyz: {xyz_init.shape}\")\n",
    "        xyz_pred = self.coord_refiner(seq_rep, pair_rep, bppm, xyz_init)\n",
    "        return xyz_pred\n",
    "        \n",
    "# Instantiate the model\n",
    "model = ChocolateNet().cuda()\n",
    "print(\"insted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:44:00.178657Z",
     "iopub.status.busy": "2025-05-04T03:44:00.178051Z",
     "iopub.status.idle": "2025-05-04T03:44:00.186590Z",
     "shell.execute_reply": "2025-05-04T03:44:00.186133Z",
     "shell.execute_reply.started": "2025-05-04T03:44:00.178632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X, Y, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances between every point in X and every point in Y.\n",
    "    Shape: (len(X), len(Y))\n",
    "    \"\"\"\n",
    "    return ((X[:, None] - Y[None, :])**2 + epsilon).sum(dim=-1).sqrt()\n",
    "\n",
    "def dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=None):\n",
    "    \"\"\"\n",
    "    Distance-based RMSD.\n",
    "    pred_x, pred_y: predicted coordinates (usually the same tensor for X and Y).\n",
    "    gt_x, gt_y: ground truth coordinates.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    if d_clamp is not None:\n",
    "        diff_sq = diff_sq.clamp(max=d_clamp**2)\n",
    "\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def local_dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=30):\n",
    "    \"\"\"\n",
    "    Local distance-based RMSD, ignoring distances above a clamp threshold.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = (~torch.isnan(gt_dm)) & (gt_dm < d_clamp)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def dRMAE(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10):\n",
    "    \"\"\"\n",
    "    Distance-based Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff = torch.abs(pred_dm[mask] - gt_dm[mask])\n",
    "    return diff.mean() / Z\n",
    "\n",
    "def align_svd_mae(input_coords, target_coords, Z=10):\n",
    "    \"\"\"\n",
    "    Align input_coords to target_coords via SVD (Kabsch algorithm) and compute MAE.\n",
    "    \"\"\"\n",
    "    assert input_coords.shape == target_coords.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    # Create mask for valid points\n",
    "    mask = ~torch.isnan(target_coords.sum(dim=-1))\n",
    "    input_coords = input_coords[mask]\n",
    "    target_coords = target_coords[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input_coords.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target_coords.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input_coords - centroid_input\n",
    "    target_centered = target_coords - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (determinant R == 1)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt_adj = Vt.clone()   # Clone to avoid in-place modification issues\n",
    "        Vt_adj[-1, :] = -Vt_adj[-1, :]\n",
    "        R = Vt_adj @ U.T\n",
    "\n",
    "    # Rotate input and compute mean absolute error\n",
    "    aligned_input = (input_centered @ R.T) + centroid_target\n",
    "    return torch.abs(aligned_input - target_coords).mean() / Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:43:49.030898Z",
     "iopub.status.busy": "2025-05-04T03:43:49.030461Z",
     "iopub.status.idle": "2025-05-04T03:43:49.039530Z",
     "shell.execute_reply": "2025-05-04T03:43:49.039075Z",
     "shell.execute_reply.started": "2025-05-04T03:43:49.030878Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPLEMENT TRAIN() FROM SE3TRANSFORMER\n",
    "\n",
    "def train_model(model, train_dl, val_dl, epochs=50, cos_epoch=35, lr=3e-4, clip=1):\n",
    "    \"\"\"Train the model with a CosineAnnealingLR after `cos_epoch` epochs.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.0, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(epochs - cos_epoch) * len(train_dl),\n",
    "    )\n",
    "    grad_accum_steps = model.config[\"gradient_accumulation_steps\"]\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_preds = None\n",
    "    use_amp = model.coord_refiner.blocks[0].se3_transformer.tensor_cores and device.type == 'cuda'\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_dl, desc=f\"Training Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Add profiling for the first few batches of the first epoch\n",
    "        profiling_enabled = (epoch == 0)\n",
    "\n",
    "        for idx, batch in enumerate(train_pbar):\n",
    "\n",
    "            sequence = batch[\"sequence\"].cuda()\n",
    "            \n",
    "            gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "            #mask = batch[\"mask\"].cuda()\n",
    "            if profiling_enabled and idx < 5:\n",
    "                torch.cuda.synchronize()\n",
    "                start_forward = time.time()\n",
    "                with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                    pred_xyz = model(sequence).squeeze()\n",
    "                torch.cuda.synchronize()\n",
    "                forward_time = time.time() - start_forward\n",
    "                torch.cuda.synchronize()\n",
    "                start_loss = time.time()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "                torch.cuda.synchronize()\n",
    "                loss_time = time.time() - start_loss\n",
    "                print(f\"Batch {idx}: Forward pass: {forward_time:.4f}s, Loss computation: {loss_time:.4f}s\")\n",
    "            else:\n",
    "                # Normal non-profiling training code (without autocast and scaler)\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "            \n",
    "            loss = loss / grad_accum_steps\n",
    "            loss.backward()\n",
    "            if (idx + 1) % grad_accum_steps == 0 or (idx + 1) == len(train_dl):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if (epoch + 1) > cos_epoch:\n",
    "                    scheduler.step()\n",
    "                            \n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (idx + 1)\n",
    "            train_pbar.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(val_dl):\n",
    "                sequence = batch[\"sequence\"].cuda()\n",
    "                gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "                #mask = batch[\"mask\"].cuda()\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.append((gt_xyz.cpu().numpy(), pred_xyz.cpu().numpy()))\n",
    "\n",
    "            val_loss /= len(val_dl)\n",
    "            print(f\"Validation Loss (Epoch {epoch+1}): {val_loss:.4f}\")\n",
    "\n",
    "            # Check for improvement\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_preds = val_preds\n",
    "                torch.save(model.state_dict(), config[\"save_weights_name\"])\n",
    "                print(f\"  -> New best model saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), config[\"save_weights_final\"])\n",
    "    return best_val_loss, best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. RUN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:43:51.152805Z",
     "iopub.status.busy": "2025-05-04T03:43:51.152577Z",
     "iopub.status.idle": "2025-05-04T03:43:51.156120Z",
     "shell.execute_reply": "2025-05-04T03:43:51.155384Z",
     "shell.execute_reply.started": "2025-05-04T03:43:51.152789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured batch size: 1\n",
      "Train loader batch size: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Configured batch size: {config['batch_size']}\")\n",
    "print(f\"Train loader batch size: {train_loader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T03:45:05.661526Z",
     "iopub.status.busy": "2025-05-04T03:45:05.661269Z",
     "iopub.status.idle": "2025-05-04T03:45:08.372504Z",
     "shell.execute_reply": "2025-05-04T03:45:08.371771Z",
     "shell.execute_reply.started": "2025-05-04T03:45:05.661507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50:   0%|          | 0/731 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([86])\n",
      "embedding seq_rep of shape torch.Size([1, 86, 640]), and bppm of shape torch.Size([1, 86, 86])\n",
      "Pair: torch.Size([1, 86, 86, 128]), outer: torch.Size([1, 86, 86, 128]), relpos: torch.Size([1, 86, 86, 128])\n",
      "s: torch.Size([1, 86, 640]), p: torch.Size([1, 86, 86, 128])\n",
      "Shapes: seqrep : torch.Size([1, 86, 640]), pr: torch.Size([1, 86, 86, 128]), bppm: torch.Size([1, 86, 86]), xyz: torch.Size([1, 86, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn14cublasSaxpy_v2EP13cublasContextiPKfS3_iPfi, version libcudnn_ops_infer.so.8\n",
      "Training Epoch 1/50:   0%|          | 0/731 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Forward pass: 2.0528s, Loss computation: 0.0019s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "FIND was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     best_loss, best_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# or config[\"epochs\"]\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcos_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# or config[\"cos_epoch\"]\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 47\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, val_dl, epochs, cos_epoch, lr, clip)\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) \u001b[38;5;241m+\u001b[39m align_svd_mae(pred_xyz, gt_xyz)\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m grad_accum_steps\n\u001b[0;32m---> 47\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m grad_accum_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl):\n\u001b[1;32m     49\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: FIND was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_loss, best_predictions = train_model(\n",
    "        model=model,\n",
    "        train_dl=train_loader,\n",
    "        val_dl=val_loader,\n",
    "        epochs=50,         # or config[\"epochs\"]\n",
    "        cos_epoch=35,      # or config[\"cos_epoch\"]\n",
    "        lr=3e-4,\n",
    "        clip=1\n",
    "    )\n",
    "    print(f\"Best Validation Loss: {best_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-01T02:54:57.633739Z",
     "iopub.status.idle": "2025-05-01T02:54:57.634017Z",
     "shell.execute_reply": "2025-05-01T02:54:57.633937Z",
     "shell.execute_reply.started": "2025-05-01T02:54:57.633926Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -y dgl\n",
    "# !pip install --pre dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-01T02:54:57.634631Z",
     "iopub.status.idle": "2025-05-01T02:54:57.634964Z",
     "shell.execute_reply": "2025-05-01T02:54:57.634863Z",
     "shell.execute_reply.started": "2025-05-01T02:54:57.634851Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(config[\"test_data_path\"]) # target_id,sequence,temporal_cutoff,description,all_sequences\n",
    "print(test_df.head(10))\n",
    "test_model = FinetunedRibonanzaNet(model_cfg, pretrained_state=2).cuda()\n",
    "test_model.eval()\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Running inference\"):\n",
    "    seq_id = row[\"target_id\"]\n",
    "    seq = row[\"sequence\"]\n",
    "    \n",
    "    token_map = {'A': 0, 'C': 1, 'U': 2, 'G': 3}\n",
    "    token_ids = torch.tensor([token_map[c] for c in seq], dtype=torch.long).unsqueeze(0).cuda()  # shape (1, L)\n",
    "    mask = torch.ones_like(token_ids).cuda()  # or derive if needed\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5):  # generate 5 predictions\n",
    "            pred_xyz = test_model(token_ids, mask).squeeze(0).cpu().numpy()  # shape (L, 3)\n",
    "            preds.append(pred_xyz)\n",
    "\n",
    "    preds = np.stack(preds, axis=0)  # shape (5, L, 3)\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        resname = seq[i]\n",
    "        resid = i + 1\n",
    "        flat_xyz = preds[:, i, :].flatten()  # (x1,y1,z1,...,x5,y5,z5)\n",
    "        row = [f\"{seq_id}\", resname, resid] + flat_xyz.tolist()\n",
    "        submission_rows.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "columns = [\"ID\", \"resname\", \"resid\"] + [f\"{axis}_{i+1}\" for i in range(5) for axis in [\"x\", \"y\", \"z\"]]\n",
    "submission = pd.DataFrame(submission_rows, columns=columns)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Inference complete! Saved to submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11403143,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 4299272,
     "sourceId": 7639698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459124,
     "sourceId": 8318191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
