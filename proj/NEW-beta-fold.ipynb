{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:08.380702Z",
     "iopub.status.busy": "2025-05-08T16:11:08.379944Z",
     "iopub.status.idle": "2025-05-08T16:11:08.386750Z",
     "shell.execute_reply": "2025-05-08T16:11:08.386157Z",
     "shell.execute_reply.started": "2025-05-08T16:11:08.380659Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.manifold import MDS\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import fm\n",
    "from sklearn.manifold import MDS\n",
    "import dgl\n",
    "import sys\n",
    "sys.path.append(\"/workspace/app\")\n",
    "import se3_transformer\n",
    "sys.path.append(\"/notebooks/RNAstructure/exe\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CONFIG & SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:08.394499Z",
     "iopub.status.busy": "2025-05-08T16:11:08.394336Z",
     "iopub.status.idle": "2025-05-08T16:11:08.399151Z",
     "shell.execute_reply": "2025-05-08T16:11:08.398597Z",
     "shell.execute_reply.started": "2025-05-08T16:11:08.394483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 1024,\n",
    "    \"batch_size\": 1,\n",
    "    \"model_config_path\": \"ribonanzanet2d-final/configs/pairwise.yaml\",\n",
    "    \"max_len_filter\": 1024,\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    \"train_sequences_path\": \"data/Competition/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"data/Competition/train_labels.csv\",\n",
    "    \"test_data_path\": \"data/Competition/test_sequences.csv\",\n",
    "    \"combined_train_data_path\": \"data/Combined/total_processed_rna_data.pt\",\n",
    "    \"final_pretrained_weights_path\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "    \"nonfinal_pretrained_weights_path\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_name\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_final\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "    \"rna_fm_weights\": \"weights/RNA-FM_pretrained.pth\",\n",
    "    \"path_to_GCNFold_weights\": \"weights/model_unet_99.pth\",\n",
    "    \"rna_fm_embedding_dim\": 640 # default 640; DO NOT CHANGE\n",
    "}\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])\n",
    "\n",
    "# import shutil\n",
    "# shutil.copy(\"/root/.cache/torch/hub/checkpoints/RNA-FM_pretrained.pth\", config[\"rna_fm_weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:08.399984Z",
     "iopub.status.busy": "2025-05-08T16:11:08.399824Z",
     "iopub.status.idle": "2025-05-08T16:11:13.446042Z",
     "shell.execute_reply": "2025-05-08T16:11:13.445422Z",
     "shell.execute_reply.started": "2025-05-08T16:11:08.399969Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting XYZ data: 100%|██████████| 844/844 [00:04<00:00, 177.83it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load CSVs\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "# Create a pdb_id field\n",
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(\n",
    "    lambda x: x.split(\"_\")[0] + \"_\" + x.split(\"_\")[1]\n",
    ")\n",
    "\n",
    "# Collect xyz data for each sequence\n",
    "all_xyz = []\n",
    "for pdb_id in tqdm(train_sequences[\"target_id\"], desc=\"Collecting XYZ data\"):\n",
    "    df = train_labels[train_labels[\"pdb_id\"] == pdb_id]\n",
    "    xyz = df[[\"x_1\", \"y_1\", \"z_1\"]].to_numpy().astype(\"float32\")\n",
    "    xyz[xyz < -1e17] = float(\"nan\")\n",
    "    all_xyz.append(xyz)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 SECONDARY DATA (BPPMs, initial 3D structs, initial sequence embeddings, etc.) GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:13.447136Z",
     "iopub.status.busy": "2025-05-08T16:11:13.446833Z",
     "iopub.status.idle": "2025-05-08T16:11:20.391300Z",
     "shell.execute_reply": "2025-05-08T16:11:20.390855Z",
     "shell.execute_reply.started": "2025-05-08T16:11:13.447091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 9 ConvTransformerEncoderLayers\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"ribonanzanet2d-final\")\n",
    "\n",
    "from Network import *\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries=entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return Config(**config)\n",
    "\n",
    "class finetuned_RibonanzaNet(RibonanzaNet):\n",
    "    def __init__(self, config):\n",
    "        config.dropout=0.2\n",
    "        super(finetuned_RibonanzaNet, self).__init__(config)\n",
    "        self.use_gradient_checkpoint = False\n",
    "        self.ct_predictor=nn.Linear(64,1)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        \n",
    "    def forward(self,src):\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        _, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n",
    "\n",
    "        pairwise_features=pairwise_features+pairwise_features.permute(0,2,1,3) #symmetrize\n",
    "\n",
    "        output=self.ct_predictor(self.dropout(pairwise_features)) #predict\n",
    "\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "ribonet=finetuned_RibonanzaNet(load_config_from_yaml(\"ribonanzanet2d-final/configs/pairwise.yaml\")).cuda()\n",
    "ribonet.load_state_dict(torch.load(\"weights/RibonanzaNet-SS.pt\",map_location='cpu'))\n",
    "ribonet.eval()\n",
    "\n",
    "rna_fmodel, alphabet = fm.pretrained.rna_fm_t12(config[\"rna_fm_weights\"])\n",
    "rnafm_batch_converter = alphabet.get_batch_converter()\n",
    "rna_fmodel.eval()\n",
    "\n",
    "reverse_map = {\n",
    "    0: \"A\", 1: \"C\", 2: \"G\", 3: \"U\"\n",
    "}\n",
    "\n",
    "def tokens_to_str(tokens):\n",
    "    tokens = tokens.tolist()\n",
    "    seq = \"\"\n",
    "    for token in tokens:\n",
    "        seq+=reverse_map[token]\n",
    "    return seq\n",
    "\n",
    "def init_coords_from_sequence(\n",
    "    seq,\n",
    "    bppm,\n",
    "    contact_d=6.0,\n",
    "    noncontact_d=25.0,\n",
    "    mds_kwargs=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq: RNA sequence str of len L\n",
    "        bppm: pair prob matrix of (L, L)\n",
    "        contact_d: target distance (Å) for predicted base pairs\n",
    "        noncontact_d: target distance (Å) for non-paired nucleotides\n",
    "        mds_kwargs: extra args for sklearn.manifold.MDS\n",
    "\n",
    "    Returns:\n",
    "        coords: tensor of shape (L,3)\n",
    "    \"\"\"\n",
    "\n",
    "    P = bppm\n",
    "    \n",
    "    L = P.shape[0]\n",
    "    \n",
    "    # 2. Build graph & run MWM\n",
    "    G = nx.Graph()\n",
    "    for i in range(L):\n",
    "        for j in range(i+4, L):  # enforce minimum loop length\n",
    "            p = P[i, j]\n",
    "            if p > 0.01:  # skip ultra-low probs\n",
    "                w = torch.log(p / (1 - p + 1e-9))\n",
    "                if w > 0:\n",
    "                    G.add_edge(i, j, weight=w)\n",
    "    match = nx.algorithms.matching.max_weight_matching(\n",
    "        G, maxcardinality=False\n",
    "    )  # O(L³) but usually <0.05 s for L≈400\n",
    "\n",
    "    # 3. Build a target distance matrix\n",
    "    D = np.full((L, L), noncontact_d, dtype=float)\n",
    "    for i, j in match:\n",
    "        D[i, j] = D[j, i] = contact_d\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "\n",
    "    # 4. Run classical MDS to embed into ℝ³\n",
    "    mds_kwargs = mds_kwargs or {}\n",
    "    mds = MDS(\n",
    "        n_components=3,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        n_init=4,\n",
    "        max_iter=300,\n",
    "        **mds_kwargs\n",
    "    )\n",
    "    coords = mds.fit_transform(D)  # (L,3), preserves the “contact” proximities\n",
    "    return torch.from_numpy(coords).float().cuda()\n",
    "\n",
    "vocab = {\"A\":0, \"C\":1, \"G\":2, \"U\":3}\n",
    "def get_ribonet_bpp(sequence): # tensor of shape (1, L, L)\n",
    "    src = sequence.unsqueeze(0)\n",
    "    return ribonet(src).sigmoid().detach().cpu()\n",
    "    \n",
    "def get_rnaf_seq_encoding(sequence): \n",
    "    # sequence = tokens_to_str(sequence[0]) # CURRENTLY ONLY SUPPORTS BATCH SIZE 1 ### FIX ###\n",
    "     \n",
    "    # Prepare data\n",
    "    data = [\n",
    "        (\"Sequence\", sequence)\n",
    "    ]\n",
    "    _, _, batch_tokens = rnafm_batch_converter(data) # [(id, seq),...] -> batch label, seq, tokens\n",
    "\n",
    "    # Extract embeddings (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = rna_fmodel(batch_tokens, repr_layers=[rna_fmodel.num_layers])\n",
    "    # print(results[\"representations\"])\n",
    "    token_embeddings = results[\"representations\"][rna_fmodel.num_layers].cuda()\n",
    "    token_embeddings = token_embeddings[:, 1:-1, :]\n",
    "    return token_embeddings # (1, seqlen, 640)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:20.392153Z",
     "iopub.status.busy": "2025-05-08T16:11:20.391913Z",
     "iopub.status.idle": "2025-05-08T16:11:20.403596Z",
     "shell.execute_reply": "2025-05-08T16:11:20.403218Z",
     "shell.execute_reply.started": "2025-05-08T16:11:20.392134Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 4298\n"
     ]
    }
   ],
   "source": [
    "valid_indices = []\n",
    "max_len_seen = 0\n",
    "\n",
    "for i, xyz in enumerate(all_xyz):\n",
    "    # Track the maximum length\n",
    "    if len(xyz) > max_len_seen:\n",
    "        max_len_seen = len(xyz)\n",
    "\n",
    "    nan_ratio = np.isnan(xyz).mean()\n",
    "    seq_len = len(xyz)\n",
    "    # Keep sequence if it meets criteria\n",
    "    if (nan_ratio <= 0.5) and (config[\"min_len_filter\"] < seq_len <= config[\"max_len_filter\"]):\n",
    "        valid_indices.append(i)\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len_seen}\")\n",
    "\n",
    "# Filter sequences & xyz based on valid_indices\n",
    "train_sequences = train_sequences.loc[valid_indices].reset_index(drop=True)\n",
    "all_xyz = [all_xyz[i] for i in valid_indices]\n",
    "# init_seq_embeddings = [init_seq_embeddings[i] for i in valid_indices]\n",
    "# initial_3ds = [initial_3ds[i] for i in valid_indices]\n",
    "# bppms = [bppms[i] for i in valid_indices]\n",
    "\n",
    "# Prepare final data dictionary\n",
    "data = {\n",
    "    \"sequence\": train_sequences[\"sequence\"].tolist(),\n",
    "    \"temporal_cutoff\": train_sequences[\"temporal_cutoff\"].tolist(),\n",
    "    \"description\": train_sequences[\"description\"].tolist(),\n",
    "    \"all_sequences\": train_sequences[\"all_sequences\"].tolist(),\n",
    "    \"xyz\": all_xyz\n",
    "    # \"base_pair_matrices\": bppms,\n",
    "    # \"3d_inits\": tertiary_inits,\n",
    "    # \"seq_embedding_inits\": seq_emb_inits\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TRAIN / VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:20.404369Z",
     "iopub.status.busy": "2025-05-08T16:11:20.404140Z",
     "iopub.status.idle": "2025-05-08T16:11:20.407488Z",
     "shell.execute_reply": "2025-05-08T16:11:20.407120Z",
     "shell.execute_reply.started": "2025-05-08T16:11:20.404351Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cutoff_date = pd.Timestamp(config[\"cutoff_date\"])\n",
    "test_cutoff_date = pd.Timestamp(config[\"test_cutoff_date\"])\n",
    "\n",
    "train_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if pd.Timestamp(date_str) <= cutoff_date]\n",
    "test_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if cutoff_date < pd.Timestamp(date_str) <= test_cutoff_date]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "all_indices = list(range(len(data[\"sequence\"])))\n",
    "train_indices, test_indices = train_test_split(all_indices, test_size=0.1, random_state=config[\"seed\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:20.408665Z",
     "iopub.status.busy": "2025-05-08T16:11:20.408303Z",
     "iopub.status.idle": "2025-05-08T16:11:20.417377Z",
     "shell.execute_reply": "2025-05-08T16:11:20.416979Z",
     "shell.execute_reply.started": "2025-05-08T16:11:20.408645Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rna_collate_fn(batch):\n",
    "    sequences = [item[\"sequence\"] for item in batch]\n",
    "    xyzs = [item[\"xyz\"] for item in batch]\n",
    "\n",
    "    # Create masks before padding\n",
    "    masks = [torch.ones(len(seq), dtype=torch.bool) for seq in sequences]\n",
    "\n",
    "    # Pad sequences and coordinates\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=4)  # 4 = <PAD> token index\n",
    "    padded_xyzs = pad_sequence(xyzs, batch_first=True, padding_value=0.0)\n",
    "    padded_masks = pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        \"sequence\": padded_sequences,\n",
    "        \"xyz\": padded_xyzs,\n",
    "        \"mask\": padded_masks\n",
    "    }\n",
    "\n",
    "\n",
    "class RNA3D_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for 3D RNA structures.\n",
    "    \"\"\"\n",
    "    def __init__(self, indices, data_dict, max_len=384):\n",
    "        self.indices = indices\n",
    "        self.data = data_dict\n",
    "        self.max_len = max_len\n",
    "        self.nt_to_idx = {nt: i for i, nt in enumerate(\"ACGU\")}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "   \n",
    "    def clean_sequences(self):\n",
    "        clean_seqs = []\n",
    "        clean_xyz = []\n",
    "        clean_indices = []\n",
    "\n",
    "        for seq, coords in zip(self.data[\"sequence\"], self.data[\"xyz\"]):\n",
    "            if 'X' in seq or coords is None or len(seq) != len(coords):\n",
    "                continue\n",
    "            clean_seqs.append(seq)\n",
    "            clean_xyz.append(coords)\n",
    "\n",
    "        self.data[\"sequence\"] = clean_seqs\n",
    "        self.data[\"xyz\"] = clean_xyz\n",
    "        self.indices = list(range(len(clean_seqs)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_idx = self.indices[idx]\n",
    "        # Convert nucleotides to integer tokens\n",
    "        sequence = []\n",
    "\n",
    "        sequence = [self.nt_to_idx[nt] for nt in self.data[\"sequence\"][data_idx]]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        # Convert xyz to torch tensor\n",
    "        xyz = torch.tensor(self.data[\"xyz\"][data_idx], dtype=torch.float32)\n",
    "\n",
    "        # If sequence is longer than max_len, randomly crop\n",
    "        if len(sequence) > self.max_len:\n",
    "            crop_start = np.random.randint(len(sequence) - self.max_len)\n",
    "            crop_end = crop_start + self.max_len\n",
    "            sequence = sequence[crop_start:crop_end]\n",
    "            xyz = xyz[crop_start:crop_end]\n",
    "\n",
    "        return {\"sequence\": sequence, \"xyz\": xyz}\n",
    "\n",
    "train_dataset = RNA3D_Dataset(train_indices, data, max_len=config[\"max_len\"])\n",
    "train_dataset.clean_sequences()\n",
    "val_dataset = RNA3D_Dataset(test_indices, data, max_len=config[\"max_len\"])\n",
    "val_dataset.clean_sequences()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=8,  # Adjust based on CPU cores\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=rna_collate_fn\n",
    "    )\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=8, pin_memory=True, \n",
    "                        collate_fn=rna_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODEL, CONFIG CLASSES & HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:20.418409Z",
     "iopub.status.busy": "2025-05-08T16:11:20.418159Z",
     "iopub.status.idle": "2025-05-08T16:11:20.888650Z",
     "shell.execute_reply": "2025-05-08T16:11:20.888260Z",
     "shell.execute_reply.started": "2025-05-08T16:11:20.418391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "from typing import Dict, Tuple, List, Set\n",
    "\n",
    "# Assume the provided files (transformer.py, fiber.py, etc.) are in the python path\n",
    "# Or place them in the same directory\n",
    "from se3_transformer.model.transformer import SE3Transformer\n",
    "from se3_transformer.model.fiber import Fiber\n",
    "from se3_transformer.runtime.utils import degree_to_dim # Helper if needed\n",
    "\n",
    "# --- Assume these tensors are provided as input to the forward pass ---\n",
    "# sequence_rep: (B, L, 640) float tensor - Per-residue sequence embeddings\n",
    "# pair_rep:     (B, L, L, 128) float tensor - Pairwise embeddings\n",
    "# bppm:         (B, L, L) float tensor - Base Pairing Probability Matrix\n",
    "# initial_coords: (B, L, 3) float tensor - Initial 3D coordinates\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "class CoordinateRefiner(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_embed_dim: int = 640,\n",
    "                 pair_embed_dim: int = 128,\n",
    "                 num_layers: int = 3,      # Simple depth\n",
    "                 num_heads: int = 4,       # Moderate number of heads\n",
    "                 hidden_channels: int = 32,# Moderate hidden channels\n",
    "                 num_degrees: int = 2,      # Use degree 0 and 1 in hidden layers\n",
    "                 knn_k: int = 16, # k for k-NN edges\n",
    "                 sec_struct_threshold: float = 0.5, # Threshold for proxy secondary structure edges\n",
    "                 high_prob_threshold: float = 0.3,\n",
    "                 mwm_min_loop_len: int = 4, # Min loop length for MWM pairing\n",
    "                 mwm_min_prob: float = 0.01, # Min BPPM prob for considering MWM edge\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seq_embed_dim: Dimension of the input sequence embeddings.\n",
    "            pair_embed_dim: Dimension of the input pairwise embeddings.\n",
    "            num_layers: Number of SE3Transformer layers.\n",
    "            num_heads: Number of attention heads.\n",
    "            hidden_channels: Number of channels per degree in hidden layers.\n",
    "            num_degrees: Number of degrees (0 to num_degrees-1) in hidden layers.\n",
    "            knn_k: Number of nearest neighbors for k-NN edges.\n",
    "            sec_struct_threshold: BPPM threshold proxy for secondary structure pairs.\n",
    "            high_prob_threshold: BPPM threshold for additional high-probability pairs.\n",
    "            mwm_min_loop_len: Minimum loop length constraint for MWM graph construction.\n",
    "            mwm_min_prob: Minimum BPPM probability to consider an edge in MWM graph.\n",
    "            high_prob_threshold: BPPM threshold for additional high-probability pairs.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_embed_dim = seq_embed_dim\n",
    "        self.pair_embed_dim = pair_embed_dim\n",
    "        # Edge features combine pairwise embeddings and bppm scalar\n",
    "        self.edge_feature_dim = pair_embed_dim + 1 # Add 1 for bppm\n",
    "        self.knn_k = knn_k\n",
    "        self.sec_struct_threshold = sec_struct_threshold\n",
    "        self.high_prob_threshold = high_prob_threshold\n",
    "        self.mwm_min_loop_len = mwm_min_loop_len\n",
    "        self.mwm_min_prob = mwm_min_prob\n",
    "\n",
    "        # --- Define Fibers ---\n",
    "        # Input Node Fiber: Type 0 for sequence embeddings, Type 1 for coordinates\n",
    "        self.fiber_in = Fiber({\n",
    "            '0': self.seq_embed_dim, # Invariant sequence features\n",
    "            '1': 1                   # Equivariant coordinate features (1 channel of type 1)\n",
    "        })\n",
    "\n",
    "        # Input Edge Fiber: Type 0 for pairwise embeddings + bppm + distance (distance added internally)\n",
    "        # Note: The actual dimension passed to RadialProfile will be self.edge_feature_dim + 1\n",
    "        self.fiber_edge = Fiber({\n",
    "            '0': self.edge_feature_dim # All invariant edge features provided by user\n",
    "        })\n",
    "\n",
    "        # Hidden Fiber: Use degrees 0 to num_degrees-1\n",
    "        self.fiber_hidden = Fiber.create(num_degrees=num_degrees, num_channels=hidden_channels)\n",
    "\n",
    "        # Output Fiber: We only want the refined coordinates (Type 1)\n",
    "        self.fiber_out = Fiber({\n",
    "            '1': 1  # Output 1 channel of type 1 features (coordinate update)\n",
    "        })\n",
    "\n",
    "        # --- Instantiate the SE3 Transformer ---\n",
    "        self.se3_transformer = SE3Transformer(\n",
    "            num_layers=num_layers,\n",
    "            fiber_in=self.fiber_in,\n",
    "            fiber_hidden=self.fiber_hidden,\n",
    "            fiber_out=self.fiber_out,\n",
    "            num_heads=num_heads,\n",
    "            channels_div=2,          # Standard default\n",
    "            fiber_edge=self.fiber_edge, # Pass the user-provided part\n",
    "            return_type=1,           # Return only type 1 features (coordinate update)\n",
    "            pooling=None,            # We need per-node output\n",
    "            norm=True,               # Use normalization\n",
    "            use_layer_norm=True,     # Use layer norm\n",
    "            tensor_cores=torch.cuda.is_available(), # Auto-detect (can be overridden)\n",
    "            low_memory=False,         # Assume standard memory usage for now\n",
    "        )\n",
    "\n",
    "        # Print config only once during init\n",
    "        if not hasattr(CoordinateRefiner, '_config_printed'):\n",
    "            print(\"--- Model Configuration ---\")\n",
    "            print(f\"SE3 Layers: {num_layers}\")\n",
    "            print(f\"Attention Heads: {num_heads}\")\n",
    "            print(f\"Hidden Channels/Degree: {hidden_channels}\")\n",
    "            print(f\"Hidden Degrees: {num_degrees}\")\n",
    "            print(f\"Input Node Fiber: {self.fiber_in}\")\n",
    "            print(f\"Input Edge Fiber (User provided part): {self.fiber_edge}\")\n",
    "            print(f\"Hidden Fiber: {self.fiber_hidden}\")\n",
    "            print(f\"Output Fiber: {self.fiber_out}\")\n",
    "            print(f\"Using Tensor Cores: {self.se3_transformer.tensor_cores}\")\n",
    "            print(f\"Graph Edges: Backbone, SecStruct (MWM >{self.mwm_min_prob}, min_loop={self.mwm_min_loop_len}), kNN (k={self.knn_k}), HighProb (>{self.high_prob_threshold})\")\n",
    "            print(\"------------------\")\n",
    "            CoordinateRefiner._config_printed = True\n",
    "\n",
    "    # --- MWM Helper ---\n",
    "    def _extract_mwm_pairs(self, P: np.ndarray, min_loop_len: int = 4, min_prob: float = 0.01) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Extract secondary structure from BPPM via maximum-weight matching.\"\"\"\n",
    "        L = P.shape[0]\n",
    "        G = nx.Graph()\n",
    "        for i in range(L):\n",
    "            for j in range(i + min_loop_len, L): # Ensure min loop length\n",
    "                p = P[i, j]\n",
    "                if p > min_prob:\n",
    "                    # Use log-odds as weight (higher probability = higher weight)\n",
    "                    log_odds = np.log(p / (1 - p + 1e-9)) # safe denominator\n",
    "                    G.add_edge(i, j, weight=log_odds)\n",
    "\n",
    "        # Compute maximum weight matching\n",
    "        # maxcardinality=False ensures we maximize weight, not necessarily the number of edges\n",
    "        match = nx.algorithms.matching.max_weight_matching(G, maxcardinality=False)\n",
    "        # The result is a set of tuples, convert to list\n",
    "        return list(match)\n",
    "\n",
    "    def _get_backbone_edges(self, L: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generates backbone edges (i, i+1) and (i+1, i).\"\"\"\n",
    "        src = torch.arange(0, L - 1, device=device)\n",
    "        dst = torch.arange(1, L, device=device)\n",
    "        # Add edges in both directions\n",
    "        src_all = torch.cat([src, dst])\n",
    "        dst_all = torch.cat([dst, src])\n",
    "        return src_all, dst_all\n",
    "\n",
    "    def _get_secondary_structure_edges(self, bppm: torch.Tensor, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor, Set[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Generates secondary structure edges based on Maximum Weight Matching on the BPPM.\n",
    "        Returns edges in both directions and a set of unique pairs (i, j) where i < j.\n",
    "        \"\"\"\n",
    "        # Convert tensor to numpy array for networkx/numpy operations\n",
    "        bppm_np = bppm.cpu().numpy()\n",
    "\n",
    "        # Get matched pairs using MWM helper\n",
    "        matched_pairs = self._extract_mwm_pairs(bppm_np, self.mwm_min_loop_len, self.mwm_min_prob)\n",
    "\n",
    "        if not matched_pairs: # Handle case where no pairs are matched\n",
    "            src_all = torch.tensor([], dtype=torch.long, device=device)\n",
    "            dst_all = torch.tensor([], dtype=torch.long, device=device)\n",
    "            pair_set = set()\n",
    "            return src_all, dst_all, pair_set\n",
    "\n",
    "        # Extract source and destination from matched pairs\n",
    "        src_list = [pair[0] for pair in matched_pairs]\n",
    "        dst_list = [pair[1] for pair in matched_pairs]\n",
    "\n",
    "        # Ensure pairs are stored as (min_idx, max_idx) in the set\n",
    "        pair_set = set((min(s, d), max(s, d)) for s, d in matched_pairs)\n",
    "\n",
    "        # Create tensors and add edges in both directions\n",
    "        src_match = torch.tensor(src_list, dtype=torch.long, device=device)\n",
    "        dst_match = torch.tensor(dst_list, dtype=torch.long, device=device)\n",
    "        src_all = torch.cat([src_match, dst_match])\n",
    "        dst_all = torch.cat([dst_match, src_match])\n",
    "\n",
    "        return src_all, dst_all, pair_set\n",
    "\n",
    "    def _get_knn_edges(self, coords: torch.Tensor, k: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generates k-NN edges based on 3D coordinates, excluding self-loops.\"\"\"\n",
    "        # dgl.knn_graph computes distances and finds neighbors efficiently\n",
    "        # Note: By default, it creates edges (neighbor -> node).\n",
    "        # We want edges in both directions for message passing.\n",
    "        knn_graph = dgl.knn_graph(coords, k)\n",
    "        src, dst = knn_graph.edges()\n",
    "        # Add reverse edges\n",
    "        src_all = torch.cat([src, dst])\n",
    "        dst_all = torch.cat([dst, src])\n",
    "        return src_all, dst_all\n",
    "\n",
    "    def _get_high_prob_edges(self, bppm: torch.Tensor, threshold: float,\n",
    "                             exclude_pairs: Set[Tuple[int, int]], device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Generates high-probability edges (BPPM > threshold), excluding backbone and secondary structure pairs.\n",
    "        \"\"\"\n",
    "        L = bppm.shape[0]\n",
    "        # Consider only upper triangle (i < j)\n",
    "        upper_tri_indices = torch.triu_indices(L, L, offset=1, device=device) # offset=1 excludes diagonal\n",
    "        upper_tri_bppm = bppm[upper_tri_indices[0], upper_tri_indices[1]]\n",
    "\n",
    "        # Find pairs above threshold\n",
    "        mask = upper_tri_bppm >= threshold\n",
    "        src_potential = upper_tri_indices[0][mask]\n",
    "        dst_potential = upper_tri_indices[1][mask]\n",
    "\n",
    "        src_filtered_list = []\n",
    "        dst_filtered_list = []\n",
    "        for s, d in zip(src_potential, dst_potential):\n",
    "            s_item, d_item = s.item(), d.item()\n",
    "            # Ensure i < j representation for checking exclusion set\n",
    "            pair = (min(s_item, d_item), max(s_item, d_item))\n",
    "            # Exclude backbone (i, i+1) and secondary structure pairs\n",
    "            if abs(s_item - d_item) > 1 and pair not in exclude_pairs:\n",
    "                src_filtered_list.append(s)\n",
    "                dst_filtered_list.append(d)\n",
    "\n",
    "        if not src_filtered_list: # Handle empty case\n",
    "            src_filtered = torch.tensor([], dtype=torch.long, device=device)\n",
    "            dst_filtered = torch.tensor([], dtype=torch.long, device=device)\n",
    "        else:\n",
    "            src_filtered = torch.stack(src_filtered_list)\n",
    "            dst_filtered = torch.stack(dst_filtered_list)\n",
    "\n",
    "        # Add edges in both directions\n",
    "        src_all = torch.cat([src_filtered, dst_filtered])\n",
    "        dst_all = torch.cat([dst_filtered, src_filtered])\n",
    "\n",
    "        return src_all, dst_all\n",
    "\n",
    "    def forward(self,\n",
    "                sequence_rep: torch.Tensor,\n",
    "                pair_rep: torch.Tensor,\n",
    "                bppm: torch.Tensor,\n",
    "                initial_coords: torch.Tensor\n",
    "                ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs one step of 3D coordinate refinement on a batch of structures using sparse graphs (MWM for SS).\n",
    "        Args see original docstring. Returns see original docstring.\n",
    "        \"\"\"\n",
    "        B, L = initial_coords.shape[:2]\n",
    "        device = initial_coords.device\n",
    "\n",
    "        graphs_list = []\n",
    "        total_src_list = []\n",
    "        total_dst_list = []\n",
    "        node_offset = 0\n",
    "\n",
    "        # 1. Build Individual Sparse Graphs for each item in the batch\n",
    "        for i in range(B):\n",
    "            coords_i = initial_coords[i] # (L, 3)\n",
    "            bppm_i = bppm[i]             # (L, L)\n",
    "\n",
    "            # Get edges for this instance\n",
    "            src_bb, dst_bb = self._get_backbone_edges(L, device)\n",
    "            # Use MWM for secondary structure edges\n",
    "            src_ss, dst_ss, ss_pair_set = self._get_secondary_structure_edges(bppm_i, device)\n",
    "            src_knn, dst_knn = self._get_knn_edges(coords_i, self.knn_k, device)\n",
    "            # High prob edges exclude MWM pairs now\n",
    "            src_hp, dst_hp = self._get_high_prob_edges(bppm_i, self.high_prob_threshold, ss_pair_set, device)\n",
    "\n",
    "            # Combine all edge types\n",
    "            src_combined = torch.cat([src_bb, src_ss, src_knn, src_hp])\n",
    "            dst_combined = torch.cat([dst_bb, dst_ss, dst_knn, dst_hp])\n",
    "\n",
    "            # Remove duplicate edges\n",
    "            combined_edges = torch.stack([src_combined, dst_combined], dim=1)\n",
    "            unique_edges = torch.unique(combined_edges, dim=0)\n",
    "            src_unique = unique_edges[:, 0]\n",
    "            dst_unique = unique_edges[:, 1]\n",
    "\n",
    "            # Create individual graph\n",
    "            g = dgl.graph((src_unique, dst_unique), num_nodes=L).to(device)\n",
    "            graphs_list.append(g)\n",
    "\n",
    "            # Store edges with offset for later feature selection\n",
    "            total_src_list.append(src_unique + node_offset)\n",
    "            total_dst_list.append(dst_unique + node_offset)\n",
    "            node_offset += L\n",
    "\n",
    "        # 2. Batch Graphs\n",
    "        if not graphs_list: return initial_coords\n",
    "        batched_graph = dgl.batch(graphs_list)\n",
    "        N_total = batched_graph.num_nodes()\n",
    "\n",
    "        src_total = torch.cat(total_src_list)\n",
    "        dst_total = torch.cat(total_dst_list)\n",
    "        num_total_edges = src_total.shape[0]\n",
    "\n",
    "        if num_total_edges == 0:\n",
    "            print(\"Warning: Batched graph has no edges. Returning initial coordinates.\")\n",
    "            return initial_coords\n",
    "\n",
    "        # 3. Prepare Batched Node Features\n",
    "        node_seq_rep_flat = sequence_rep.reshape(N_total, self.seq_embed_dim)\n",
    "        node_coords_flat = initial_coords.reshape(N_total, 3)\n",
    "        node_feats = {\n",
    "            '0': node_seq_rep_flat.unsqueeze(-1),\n",
    "            '1': node_coords_flat.unsqueeze(1)\n",
    "        }\n",
    "\n",
    "        # 4. Prepare Batched Edge Features\n",
    "        batch_idx_src = src_total // L\n",
    "        node_idx_src = src_total % L\n",
    "        batch_idx_dst = dst_total // L\n",
    "        node_idx_dst = dst_total % L\n",
    "\n",
    "        edge_pair_feats = pair_rep[batch_idx_src, node_idx_src, node_idx_dst]\n",
    "        edge_bppm = bppm[batch_idx_src, node_idx_src, node_idx_dst].unsqueeze(-1)\n",
    "        combined_edge_feats = torch.cat([edge_pair_feats, edge_bppm], dim=1)\n",
    "        edge_feats = {\n",
    "            '0': combined_edge_feats.unsqueeze(-1)\n",
    "        }\n",
    "\n",
    "        # 5. Calculate Relative Positions\n",
    "        rel_pos = node_coords_flat[dst_total] - node_coords_flat[src_total]\n",
    "        batched_graph.edata['rel_pos'] = rel_pos\n",
    "\n",
    "        # 6. Forward Pass\n",
    "        delta_coords_flat = self.se3_transformer(batched_graph, node_feats, edge_feats)\n",
    "\n",
    "        # 7. Apply Coordinate Update\n",
    "        refined_coords_flat = node_coords_flat + delta_coords_flat.squeeze(1)\n",
    "\n",
    "        # 8. Reshape Output\n",
    "        refined_coords = refined_coords_flat.reshape(B, L, 3)\n",
    "\n",
    "        return refined_coords\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:20.889747Z",
     "iopub.status.busy": "2025-05-08T16:11:20.889314Z",
     "iopub.status.idle": "2025-05-08T16:11:20.896458Z",
     "shell.execute_reply": "2025-05-08T16:11:20.896061Z",
     "shell.execute_reply.started": "2025-05-08T16:11:20.889726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "class PairEmbedding(nn.Module):\n",
    "    def __init__(self, d_seq, d_pair, d_hidden=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1, d_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_hidden, d_pair)\n",
    "        )\n",
    "        self.outer_product_mean = Outer_Product_Mean(in_dim=d_seq, pairwise_dim=d_pair)\n",
    "        self.rel_pos_embed = relpos(dim=d_pair)\n",
    "\n",
    "    def forward(self, seq_rep, bppm):\n",
    "        x = bppm.unsqueeze(-1)                       # (L,L,1) bppm is len 28\n",
    "        pair_embed = self.mlp(x)                        # (L,L,d_pair)\n",
    "        outer_prod_mean = self.outer_product_mean(seq_rep)  # seq_rep is len 30\n",
    "        rel_embeddings = self.rel_pos_embed(seq_rep)\n",
    "        summed_pair_rep = outer_prod_mean + rel_embeddings + pair_embed\n",
    "        return summed_pair_rep\n",
    "\n",
    "class ConvFormerBlocks(nn.Module):\n",
    "    def __init__(self, n_blocks, seq_dim, nhead, pair_dim,\n",
    "                 use_triangular_attention, dropout):\n",
    "        super(ConvFormerBlocks, self).__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ConvTransformerEncoderLayer(\n",
    "                d_model = seq_dim,\n",
    "                nhead = nhead,\n",
    "                dim_feedforward = seq_dim*3, \n",
    "                pairwise_dimension= pair_dim,\n",
    "                use_triangular_attention=use_triangular_attention,\n",
    "                dropout = dropout\n",
    "            )\n",
    "            for _ in range(n_blocks)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, seq_embedding, pair_embedding):\n",
    "        seqrep = seq_embedding\n",
    "        pairrep = pair_embedding\n",
    "        mask = torch.ones(seqrep.size(0), seqrep.size(1), dtype=torch.bool, device=seqrep.device)\n",
    "        for block in self.blocks:\n",
    "            seqrep, pairrep = block(seqrep, pairrep, src_mask=mask)\n",
    "        return seqrep, pairrep\n",
    "\n",
    "class CoordinateRefinerBlocks(nn.Module):\n",
    "    def __init__(self, n_blocks, seq_dim, pair_dim, thresh):\n",
    "        super(CoordinateRefinerBlocks, self).__init__()\n",
    "        self.thresh = thresh\n",
    "        self.blocks = nn.ModuleList(CoordinateRefiner(seq_embed_dim=seq_dim,pair_embed_dim=pair_dim) for _ in range(n_blocks))\n",
    "        \n",
    "    def forward(self, sequence_rep, pair_rep, bppm,\n",
    "                initial_coords):\n",
    "        xyz = initial_coords\n",
    "        for refiner in self.blocks:\n",
    "            xyz = refiner(sequence_rep, pair_rep, bppm, xyz)\n",
    "        return xyz\n",
    "    \n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL INSTANTANTIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:20.897347Z",
     "iopub.status.busy": "2025-05-08T16:11:20.897079Z",
     "iopub.status.idle": "2025-05-08T16:11:21.028361Z",
     "shell.execute_reply": "2025-05-08T16:11:21.027955Z",
     "shell.execute_reply.started": "2025-05-08T16:11:20.897320Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing fresh model...\n",
      "--- Model Configuration ---\n",
      "SE3 Layers: 3\n",
      "Attention Heads: 4\n",
      "Hidden Channels/Degree: 32\n",
      "Hidden Degrees: 2\n",
      "Input Node Fiber: [FiberEl(degree=1, channels=1), FiberEl(degree=0, channels=640)]\n",
      "Input Edge Fiber (User provided part): [FiberEl(degree=0, channels=129)]\n",
      "Hidden Fiber: [FiberEl(degree=0, channels=32), FiberEl(degree=1, channels=32)]\n",
      "Output Fiber: [FiberEl(degree=1, channels=1)]\n",
      "Using Tensor Cores: True\n",
      "Graph Edges: Backbone, SecStruct (MWM >0.01, min_loop=4), kNN (k=16), HighProb (>0.3)\n",
      "------------------\n",
      "insted\n"
     ]
    }
   ],
   "source": [
    "class ChocolateNet(nn.Module):\n",
    "    \"\"\"\n",
    "    pretrained_state: either 0, 1, or 2 depending on how weights should be loaded:\n",
    "    - 0: no pretraining\n",
    "    - 1: load non-final pretrained weights\n",
    "    - 2: load final pretrained weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, thresh=0.20, pretrained_state=0, dropout=0.1):\n",
    "\n",
    "        super(ChocolateNet,self).__init__()\n",
    "        if pretrained_state==2:\n",
    "            print(\"loading final pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"final_pretrained_weights_path\"], map_location=\"cpu\"), strict = True\n",
    "            )\n",
    "        elif pretrained_state==1:\n",
    "            print(\"loading nonfinal pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"nonfinal_pretrained_weights_path\"], map_location=\"cpu\"), strict = True\n",
    "            )\n",
    "        elif pretrained_state==0:\n",
    "            print(\"initializing fresh model...\")\n",
    "        else:\n",
    "            raise ValueError(\"Unknown pretrained_state configuration. See class description.\")\n",
    "        \n",
    "        self.config = {\"gradient_accumulation_steps\": 1}\n",
    "        self.thresh = thresh\n",
    "        self.seq_dim = config[\"rna_fm_embedding_dim\"]\n",
    "        self.pair_dim = 128\n",
    "        self.heads = 8\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.pair_embedding = PairEmbedding(self.seq_dim, self.pair_dim)\n",
    "\n",
    "        self.sequence_transformer = ConvFormerBlocks(\n",
    "            n_blocks = 3,\n",
    "            seq_dim = self.seq_dim, \n",
    "            nhead = self.heads, \n",
    "            pair_dim = self.pair_dim,\n",
    "            use_triangular_attention=True,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        \n",
    "        # (3) RBF parameters for edge-length encoding\n",
    "        mu = torch.linspace(0, 20, 30)               # 30 Gaussians\n",
    "        sigma = 0.8 * torch.ones_like(mu)\n",
    "        self.register_buffer(\"rbf_mu\", mu)\n",
    "        self.register_buffer(\"rbf_sigma\", sigma)\n",
    "        \n",
    "        self.coord_refiner = CoordinateRefinerBlocks(\n",
    "            n_blocks = 1, seq_dim=self.seq_dim, pair_dim=self.pair_dim, thresh=self.thresh\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        sequence = sequence[0] # DOES NOT SUPPORT BATCH SIZE > 1, FIX!!\n",
    "        # 1) Get raw RNA-FM embeddings (1, L, d_seq)\n",
    "        fm_emb = get_rnaf_seq_encoding(sequence).cuda()      # → torch.FloatTensor on CPU\n",
    "\n",
    "        # 2) Get BPPM from RiboNet, convert to Tensor\n",
    "        bppm = get_ribonet_bpp(sequence).float().cuda()\n",
    "        # 3) Now build your pair embedding correctly\n",
    "        pair_embedding = self.pair_embedding(fm_emb, bppm)      # both use L\n",
    "        bppm_raw = bppm.squeeze(0)\n",
    "        \n",
    "        # # fm_embedding = get_rnaf_seq_encoding(sequence[0])\n",
    "        # bppm = get_ribonet_bpp(sequence[0])\n",
    "        # bppm_src = torch.from_numpy(bppm).float().cuda()\n",
    "        \n",
    "        \n",
    "        # pair_embedding = self.pair_embedding(fm_embedding, bppm_src)\n",
    "        \n",
    "        xyz_init = init_coords_from_sequence(sequence, bppm_raw).unsqueeze(0)\n",
    "        seq_rep, pair_rep = self.sequence_transformer(fm_emb, pair_embedding)\n",
    "        xyz_pred = self.coord_refiner(seq_rep, pair_rep, bppm, xyz_init)\n",
    "        return xyz_pred\n",
    "        \n",
    "# Instantiate the model\n",
    "model = ChocolateNet().cuda()\n",
    "print(\"insted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:21.029255Z",
     "iopub.status.busy": "2025-05-08T16:11:21.029000Z",
     "iopub.status.idle": "2025-05-08T16:11:21.036984Z",
     "shell.execute_reply": "2025-05-08T16:11:21.036601Z",
     "shell.execute_reply.started": "2025-05-08T16:11:21.029236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X, Y, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances between every point in X and every point in Y.\n",
    "    Shape: (len(X), len(Y))\n",
    "    \"\"\"\n",
    "    return ((X[:, None] - Y[None, :])**2 + epsilon).sum(dim=-1).sqrt()\n",
    "\n",
    "def dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=None):\n",
    "    \"\"\"\n",
    "    Distance-based RMSD.\n",
    "    pred_x, pred_y: predicted coordinates (usually the same tensor for X and Y).\n",
    "    gt_x, gt_y: ground truth coordinates.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    if d_clamp is not None:\n",
    "        diff_sq = diff_sq.clamp(max=d_clamp**2)\n",
    "\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def local_dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=30):\n",
    "    \"\"\"\n",
    "    Local distance-based RMSD, ignoring distances above a clamp threshold.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = (~torch.isnan(gt_dm)) & (gt_dm < d_clamp)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def dRMAE(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10):\n",
    "    \"\"\"\n",
    "    Distance-based Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff = torch.abs(pred_dm[mask] - gt_dm[mask])\n",
    "    return diff.mean() / Z\n",
    "\n",
    "def align_svd_mae(input_coords, target_coords, Z=10):\n",
    "    \"\"\"\n",
    "    Align input_coords to target_coords via SVD (Kabsch algorithm) and compute MAE.\n",
    "    \"\"\"\n",
    "    assert input_coords.shape == target_coords.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    # Create mask for valid points\n",
    "    mask = ~torch.isnan(target_coords.sum(dim=-1))\n",
    "    input_coords = input_coords[mask]\n",
    "    target_coords = target_coords[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input_coords.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target_coords.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input_coords - centroid_input\n",
    "    target_centered = target_coords - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (determinant R == 1)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt_adj = Vt.clone()   # Clone to avoid in-place modification issues\n",
    "        Vt_adj[-1, :] = -Vt_adj[-1, :]\n",
    "        R = Vt_adj @ U.T\n",
    "\n",
    "    # Rotate input and compute mean absolute error\n",
    "    aligned_input = (input_centered @ R.T) + centroid_target\n",
    "    return torch.abs(aligned_input - target_coords).mean() / Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:21.037805Z",
     "iopub.status.busy": "2025-05-08T16:11:21.037541Z",
     "iopub.status.idle": "2025-05-08T16:11:21.046446Z",
     "shell.execute_reply": "2025-05-08T16:11:21.046054Z",
     "shell.execute_reply.started": "2025-05-08T16:11:21.037785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPLEMENT TRAIN() FROM SE3TRANSFORMER\n",
    "\n",
    "def train_model(model, train_dl, val_dl, epochs=50, cos_epoch=35, lr=3e-4, clip=1):\n",
    "    \"\"\"Train the model with a CosineAnnealingLR after `cos_epoch` epochs.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.0, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(epochs - cos_epoch) * len(train_dl),\n",
    "    )\n",
    "    grad_accum_steps = model.config[\"gradient_accumulation_steps\"]\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_preds = None\n",
    "    use_amp = model.coord_refiner.blocks[0].se3_transformer.tensor_cores and device.type == 'cuda'\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_dl, desc=f\"Training Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Add profiling for the first few batches of the first epoch\n",
    "        profiling_enabled = (epoch == 0)\n",
    "\n",
    "        for idx, batch in enumerate(train_pbar):\n",
    "\n",
    "            sequence = batch[\"sequence\"].cuda()\n",
    "            \n",
    "            gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "            #mask = batch[\"mask\"].cuda()\n",
    "            if profiling_enabled and idx < 5:\n",
    "                torch.cuda.synchronize()\n",
    "                start_forward = time.time()\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                torch.cuda.synchronize()\n",
    "                forward_time = time.time() - start_forward\n",
    "                torch.cuda.synchronize()\n",
    "                start_loss = time.time()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "                torch.cuda.synchronize()\n",
    "                loss_time = time.time() - start_loss\n",
    "                print(f\"Batch {idx}: Forward pass: {forward_time:.4f}s, Loss computation: {loss_time:.4f}s\")\n",
    "            else:\n",
    "                # Normal non-profiling training code (without autocast and scaler)\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "            \n",
    "            loss = loss / grad_accum_steps\n",
    "            loss.backward()\n",
    "            if (idx + 1) % grad_accum_steps == 0 or (idx + 1) == len(train_dl):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if (epoch + 1) > cos_epoch:\n",
    "                    scheduler.step()\n",
    "                            \n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (idx + 1)\n",
    "            train_pbar.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(val_dl):\n",
    "                sequence = batch[\"sequence\"].cuda()\n",
    "                gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "                #mask = batch[\"mask\"].cuda()\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.append((gt_xyz.cpu().numpy(), pred_xyz.cpu().numpy()))\n",
    "\n",
    "            val_loss /= len(val_dl)\n",
    "            print(f\"Validation Loss (Epoch {epoch+1}): {val_loss:.4f}\")\n",
    "\n",
    "            # Check for improvement\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_preds = val_preds\n",
    "                torch.save(model.state_dict(), config[\"save_weights_name\"])\n",
    "                print(f\"  -> New best model saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), config[\"save_weights_final\"])\n",
    "    return best_val_loss, best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. RUN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:21.047304Z",
     "iopub.status.busy": "2025-05-08T16:11:21.047023Z",
     "iopub.status.idle": "2025-05-08T16:11:21.049800Z",
     "shell.execute_reply": "2025-05-08T16:11:21.049450Z",
     "shell.execute_reply.started": "2025-05-08T16:11:21.047284Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured batch size: 1\n",
      "Train loader batch size: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Configured batch size: {config['batch_size']}\")\n",
    "print(f\"Train loader batch size: {train_loader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:11:21.050616Z",
     "iopub.status.busy": "2025-05-08T16:11:21.050367Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50:   0%|          | 0/731 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_loss, best_predictions = train_model(\n",
    "        model=model,\n",
    "        train_dl=train_loader,\n",
    "        val_dl=val_loader,\n",
    "        epochs=50,         # or config[\"epochs\"]\n",
    "        cos_epoch=35,      # or config[\"cos_epoch\"]\n",
    "        lr=3e-4,\n",
    "        clip=1\n",
    "    )\n",
    "    print(f\"Best Validation Loss: {best_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y dgl\n",
    "# !pip install --pre dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(config[\"test_data_path\"]) # target_id,sequence,temporal_cutoff,description,all_sequences\n",
    "print(test_df.head(10))\n",
    "test_model = FinetunedRibonanzaNet(model_cfg, pretrained_state=2).cuda()\n",
    "test_model.eval()\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Running inference\"):\n",
    "    seq_id = row[\"target_id\"]\n",
    "    seq = row[\"sequence\"]\n",
    "    \n",
    "    token_map = {'A': 0, 'C': 1, 'U': 2, 'G': 3}\n",
    "    token_ids = torch.tensor([token_map[c] for c in seq], dtype=torch.long).unsqueeze(0).cuda()  # shape (1, L)\n",
    "    mask = torch.ones_like(token_ids).cuda()  # or derive if needed\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5):  # generate 5 predictions\n",
    "            pred_xyz = test_model(token_ids, mask).squeeze(0).cpu().numpy()  # shape (L, 3)\n",
    "            preds.append(pred_xyz)\n",
    "\n",
    "    preds = np.stack(preds, axis=0)  # shape (5, L, 3)\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        resname = seq[i]\n",
    "        resid = i + 1\n",
    "        flat_xyz = preds[:, i, :].flatten()  # (x1,y1,z1,...,x5,y5,z5)\n",
    "        row = [f\"{seq_id}\", resname, resid] + flat_xyz.tolist()\n",
    "        submission_rows.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "columns = [\"ID\", \"resname\", \"resid\"] + [f\"{axis}_{i+1}\" for i in range(5) for axis in [\"x\", \"y\", \"z\"]]\n",
    "submission = pd.DataFrame(submission_rows, columns=columns)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Inference complete! Saved to submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11403143,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 4299272,
     "sourceId": 7639698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459124,
     "sourceId": 8318191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
