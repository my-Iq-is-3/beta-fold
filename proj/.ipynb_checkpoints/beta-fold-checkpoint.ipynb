{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:26.864507Z",
     "iopub.status.busy": "2025-04-06T03:23:26.863953Z",
     "iopub.status.idle": "2025-04-06T03:23:31.674649Z",
     "shell.execute_reply": "2025-04-06T03:23:31.674164Z",
     "shell.execute_reply.started": "2025-04-06T03:23:26.864485Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.41.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:31.675968Z",
     "iopub.status.busy": "2025-04-06T03:23:31.675786Z",
     "iopub.status.idle": "2025-04-06T03:23:37.890104Z",
     "shell.execute_reply": "2025-04-06T03:23:37.889644Z",
     "shell.execute_reply.started": "2025-04-06T03:23:31.675968Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from bitsandbytes.optim import Adam8bit\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CONFIG & SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:37.891319Z",
     "iopub.status.busy": "2025-04-06T03:23:37.890695Z",
     "iopub.status.idle": "2025-04-06T03:23:37.895769Z",
     "shell.execute_reply": "2025-04-06T03:23:37.895402Z",
     "shell.execute_reply.started": "2025-04-06T03:23:37.891299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 384,\n",
    "    \"batch_size\": 1,\n",
    "    \"model_config_path\": \"ribonanzanet2d-final/configs/pairwise.yaml\",\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    \"train_sequences_path\": \"data/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"data/train_labels.csv\",\n",
    "    \"test_data_path\": \"data/test_sequences.csv\",\n",
    "    \"final_pretrained_weights_path\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "    \"nonfinal_pretrained_weights_path\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_name\": \"weights/RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_final\": \"weights/RibonanzaNet-3D-final.pt\",\n",
    "}\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:37.896739Z",
     "iopub.status.busy": "2025-04-06T03:23:37.896281Z",
     "iopub.status.idle": "2025-04-06T03:23:43.537269Z",
     "shell.execute_reply": "2025-04-06T03:23:43.536609Z",
     "shell.execute_reply.started": "2025-04-06T03:23:37.896723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting XYZ data: 100%|██████████| 844/844 [00:05<00:00, 156.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "# Create a pdb_id field\n",
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(\n",
    "    lambda x: x.split(\"_\")[0] + \"_\" + x.split(\"_\")[1]\n",
    ")\n",
    "\n",
    "# Collect xyz data for each sequence\n",
    "all_xyz = []\n",
    "for pdb_id in tqdm(train_sequences[\"target_id\"], desc=\"Collecting XYZ data\"):\n",
    "    df = train_labels[train_labels[\"pdb_id\"] == pdb_id]\n",
    "    xyz = df[[\"x_1\", \"y_1\", \"z_1\"]].to_numpy().astype(\"float32\")\n",
    "    xyz[xyz < -1e17] = float(\"nan\")\n",
    "    all_xyz.append(xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:43.539754Z",
     "iopub.status.busy": "2025-04-06T03:23:43.539310Z",
     "iopub.status.idle": "2025-04-06T03:23:43.552871Z",
     "shell.execute_reply": "2025-04-06T03:23:43.552440Z",
     "shell.execute_reply.started": "2025-04-06T03:23:43.539738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 4298\n"
     ]
    }
   ],
   "source": [
    "valid_indices = []\n",
    "max_len_seen = 0\n",
    "\n",
    "for i, xyz in enumerate(all_xyz):\n",
    "    # Track the maximum length\n",
    "    if len(xyz) > max_len_seen:\n",
    "        max_len_seen = len(xyz)\n",
    "\n",
    "    nan_ratio = np.isnan(xyz).mean()\n",
    "    seq_len = len(xyz)\n",
    "    # Keep sequence if it meets criteria\n",
    "    if (nan_ratio <= 0.5) and (config[\"min_len_filter\"] < seq_len < config[\"max_len_filter\"]):\n",
    "        valid_indices.append(i)\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len_seen}\")\n",
    "\n",
    "# Filter sequences & xyz based on valid_indices\n",
    "train_sequences = train_sequences.loc[valid_indices].reset_index(drop=True)\n",
    "all_xyz = [all_xyz[i] for i in valid_indices]\n",
    "\n",
    "# Prepare final data dictionary\n",
    "data = {\n",
    "    \"sequence\": train_sequences[\"sequence\"].tolist(),\n",
    "    \"temporal_cutoff\": train_sequences[\"temporal_cutoff\"].tolist(),\n",
    "    \"description\": train_sequences[\"description\"].tolist(),\n",
    "    \"all_sequences\": train_sequences[\"all_sequences\"].tolist(),\n",
    "    \"xyz\": all_xyz,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TRAIN / VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:43.553526Z",
     "iopub.status.busy": "2025-04-06T03:23:43.553377Z",
     "iopub.status.idle": "2025-04-06T03:23:43.560427Z",
     "shell.execute_reply": "2025-04-06T03:23:43.559946Z",
     "shell.execute_reply.started": "2025-04-06T03:23:43.553512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cutoff_date = pd.Timestamp(config[\"cutoff_date\"])\n",
    "test_cutoff_date = pd.Timestamp(config[\"test_cutoff_date\"])\n",
    "\n",
    "train_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if pd.Timestamp(date_str) <= cutoff_date]\n",
    "test_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if cutoff_date < pd.Timestamp(date_str) <= test_cutoff_date]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "all_indices = list(range(len(data[\"sequence\"])))\n",
    "train_indices, test_indices = train_test_split(all_indices, test_size=0.1, random_state=config[\"seed\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:43.561228Z",
     "iopub.status.busy": "2025-04-06T03:23:43.561087Z",
     "iopub.status.idle": "2025-04-06T03:23:43.570196Z",
     "shell.execute_reply": "2025-04-06T03:23:43.569681Z",
     "shell.execute_reply.started": "2025-04-06T03:23:43.561215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rna_collate_fn(batch):\n",
    "    sequences = [item[\"sequence\"] for item in batch]\n",
    "    xyzs = [item[\"xyz\"] for item in batch]\n",
    "\n",
    "    # Create masks before padding\n",
    "    masks = [torch.ones(len(seq), dtype=torch.bool) for seq in sequences]\n",
    "\n",
    "    # Pad sequences and coordinates\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=4)  # 4 = <PAD> token index\n",
    "    padded_xyzs = pad_sequence(xyzs, batch_first=True, padding_value=0.0)\n",
    "    padded_masks = pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        \"sequence\": padded_sequences,\n",
    "        \"xyz\": padded_xyzs,\n",
    "        \"mask\": padded_masks\n",
    "    }\n",
    "\n",
    "\n",
    "class RNA3D_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for 3D RNA structures.\n",
    "    \"\"\"\n",
    "    def __init__(self, indices, data_dict, max_len=384):\n",
    "        self.indices = indices\n",
    "        self.data = data_dict\n",
    "        self.max_len = max_len\n",
    "        self.nt_to_idx = {nt: i for i, nt in enumerate(\"ACGU\")}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "   \n",
    "    def clean_sequences(self):\n",
    "        clean_seqs = []\n",
    "        clean_xyz = []\n",
    "        clean_indices = []\n",
    "\n",
    "        for seq, coords in zip(self.data[\"sequence\"], self.data[\"xyz\"]):\n",
    "            if 'X' in seq or coords is None or len(seq) != len(coords):\n",
    "                continue\n",
    "            clean_seqs.append(seq)\n",
    "            clean_xyz.append(coords)\n",
    "\n",
    "        self.data[\"sequence\"] = clean_seqs\n",
    "        self.data[\"xyz\"] = clean_xyz\n",
    "        self.indices = list(range(len(clean_seqs)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_idx = self.indices[idx]\n",
    "        # Convert nucleotides to integer tokens\n",
    "        sequence = []\n",
    "\n",
    "        sequence = [self.nt_to_idx[nt] for nt in self.data[\"sequence\"][data_idx]]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        # Convert xyz to torch tensor\n",
    "        xyz = torch.tensor(self.data[\"xyz\"][data_idx], dtype=torch.float32)\n",
    "\n",
    "        # If sequence is longer than max_len, randomly crop\n",
    "        if len(sequence) > self.max_len:\n",
    "            crop_start = np.random.randint(len(sequence) - self.max_len)\n",
    "            crop_end = crop_start + self.max_len\n",
    "            sequence = sequence[crop_start:crop_end]\n",
    "            xyz = xyz[crop_start:crop_end]\n",
    "\n",
    "        return {\"sequence\": sequence, \"xyz\": xyz}\n",
    "\n",
    "train_dataset = RNA3D_Dataset(train_indices, data, max_len=config[\"max_len\"])\n",
    "train_dataset.clean_sequences()\n",
    "val_dataset = RNA3D_Dataset(test_indices, data, max_len=config[\"max_len\"])\n",
    "val_dataset.clean_sequences()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=8,  # Adjust based on CPU cores\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    collate_fn=rna_collate_fn\n",
    "    )\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=8, pin_memory=True, \n",
    "                        collate_fn=rna_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODEL, CONFIG CLASSES & HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:43.570944Z",
     "iopub.status.busy": "2025-04-06T03:23:43.570806Z",
     "iopub.status.idle": "2025-04-06T03:23:44.988027Z",
     "shell.execute_reply": "2025-04-06T03:23:44.987566Z",
     "shell.execute_reply.started": "2025-04-06T03:23:43.570931Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 6 ConvTransformerEncoderLayers\n",
      "loading final pretrained weights...\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"ribonanzanet2d-final\")\n",
    "\n",
    "from Network import RibonanzaNet\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Simple Config class that can load from a dict or YAML.\"\"\"\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries = entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "    return Config(**cfg)\n",
    "\n",
    "\n",
    "class FinetunedRibonanzaNet(RibonanzaNet):\n",
    "    \"\"\"\n",
    "    A finetuned version of RibonanzaNet adapted for predicting 3D coordinates.\n",
    "    \n",
    "    pretrained_state: either 0, 1, or 2 depending on how weights should be loaded:\n",
    "    - 0: no pretraining\n",
    "    - 1: load non-final pretrained weights\n",
    "    - 2: load final pretrained weights\n",
    "    \"\"\"\n",
    "    def __init__(self, config_obj, pretrained_state=2, dropout=0.1):\n",
    "        # Modify config dropout before super init, if needed\n",
    "        config_obj.dropout = dropout\n",
    "        super(FinetunedRibonanzaNet, self).__init__(config_obj)\n",
    "\n",
    "        # Load pretrained weights if requested\n",
    "        if pretrained_state==2:\n",
    "            print(\"loading final pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"final_pretrained_weights_path\"], map_location=\"cpu\"), strict = False\n",
    "            )\n",
    "        elif pretrained_state==1:\n",
    "            print(\"loading nonfinal pretrained weights...\")\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"nonfinal_pretrained_weights_path\"], map_location=\"cpu\"), strict = False\n",
    "            )\n",
    "        elif pretrained_state==0:\n",
    "            print(\"initializing fresh model...\")\n",
    "        else:\n",
    "            raise ValueError(\"Unknown pretrained_state configuration. See class description.\")\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.xyz_predictor = nn.Linear(256, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        sequence_features, _ = self.get_embeddings(\n",
    "            src, torch.ones_like(src).long().to(src.device)\n",
    "        )\n",
    "        xyz_pred = self.xyz_predictor(sequence_features)\n",
    "        return xyz_pred\n",
    "\n",
    "# Instantiate the model\n",
    "model_cfg = load_config_from_yaml(config[\"model_config_path\"])\n",
    "model = FinetunedRibonanzaNet(model_cfg, pretrained_state=2).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:44.989390Z",
     "iopub.status.busy": "2025-04-06T03:23:44.988775Z",
     "iopub.status.idle": "2025-04-06T03:23:44.996977Z",
     "shell.execute_reply": "2025-04-06T03:23:44.996641Z",
     "shell.execute_reply.started": "2025-04-06T03:23:44.989369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X, Y, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances between every point in X and every point in Y.\n",
    "    Shape: (len(X), len(Y))\n",
    "    \"\"\"\n",
    "    return ((X[:, None] - Y[None, :])**2 + epsilon).sum(dim=-1).sqrt()\n",
    "\n",
    "def dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=None):\n",
    "    \"\"\"\n",
    "    Distance-based RMSD.\n",
    "    pred_x, pred_y: predicted coordinates (usually the same tensor for X and Y).\n",
    "    gt_x, gt_y: ground truth coordinates.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    if d_clamp is not None:\n",
    "        diff_sq = diff_sq.clamp(max=d_clamp**2)\n",
    "\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def local_dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=30):\n",
    "    \"\"\"\n",
    "    Local distance-based RMSD, ignoring distances above a clamp threshold.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = (~torch.isnan(gt_dm)) & (gt_dm < d_clamp)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def dRMAE(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10):\n",
    "    \"\"\"\n",
    "    Distance-based Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff = torch.abs(pred_dm[mask] - gt_dm[mask])\n",
    "    return diff.mean() / Z\n",
    "\n",
    "def align_svd_mae(input_coords, target_coords, Z=10):\n",
    "    \"\"\"\n",
    "    Align input_coords to target_coords via SVD (Kabsch algorithm) and compute MAE.\n",
    "    \"\"\"\n",
    "    assert input_coords.shape == target_coords.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    # Create mask for valid points\n",
    "    mask = ~torch.isnan(target_coords.sum(dim=-1))\n",
    "    input_coords = input_coords[mask]\n",
    "    target_coords = target_coords[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input_coords.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target_coords.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input_coords - centroid_input\n",
    "    target_centered = target_coords - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (determinant R == 1)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt_adj = Vt.clone()   # Clone to avoid in-place modification issues\n",
    "        Vt_adj[-1, :] = -Vt_adj[-1, :]\n",
    "        R = Vt_adj @ U.T\n",
    "\n",
    "    # Rotate input and compute mean absolute error\n",
    "    aligned_input = (input_centered @ R.T) + centroid_target\n",
    "    return torch.abs(aligned_input - target_coords).mean() / Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:44.998004Z",
     "iopub.status.busy": "2025-04-06T03:23:44.997549Z",
     "iopub.status.idle": "2025-04-06T03:23:45.005694Z",
     "shell.execute_reply": "2025-04-06T03:23:45.005380Z",
     "shell.execute_reply.started": "2025-04-06T03:23:44.997989Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, val_dl, epochs=50, cos_epoch=35, lr=3e-4, clip=1):\n",
    "    \"\"\"Train the model with a CosineAnnealingLR after `cos_epoch` epochs.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.0, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(epochs - cos_epoch) * len(train_dl),\n",
    "    )\n",
    "    grad_accum_steps = model.config.gradient_accumulation_steps\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_preds = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_dl, desc=f\"Training Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Add profiling for the first few batches of the first epoch\n",
    "        profiling_enabled = (epoch == 0)\n",
    "\n",
    "        for idx, batch in enumerate(train_pbar):\n",
    "\n",
    "            sequence = batch[\"sequence\"].cuda()\n",
    "            gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "            #mask = batch[\"mask\"].cuda()\n",
    "            # Only profile the first 5 batches of the first epoch\n",
    "            if profiling_enabled and idx < 10:\n",
    "                torch.cuda.synchronize()\n",
    "                start_forward = time.time()\n",
    "                \n",
    "                # Remove autocast\n",
    "                pred_xyz = model(sequence, src_mask=None).squeeze()\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                forward_time = time.time() - start_forward\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                start_loss = time.time()\n",
    "                \n",
    "                # Remove autocast\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                loss_time = time.time() - start_loss\n",
    "                \n",
    "                print(f\"Batch {idx}: Forward pass: {forward_time:.4f}s, Loss computation: {loss_time:.4f}s\")\n",
    "                \n",
    "                # Continue with normal training flow (without scaler)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                # Normal non-profiling training code (without autocast and scaler)\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "            \n",
    "            loss = loss / grad_accum_steps\n",
    "            loss.backward()\n",
    "            if (idx + 1) % grad_accum_steps == 0 or (idx + 1) == len(train_dl):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if (epoch + 1) > cos_epoch:\n",
    "                    scheduler.step()\n",
    "                            \n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (idx + 1)\n",
    "            train_pbar.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(val_dl):\n",
    "                sequence = batch[\"sequence\"].cuda()\n",
    "                gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "                #mask = batch[\"mask\"].cuda()\n",
    "                pred_xyz = model(sequence, src_mask=None).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.append((gt_xyz.cpu().numpy(), pred_xyz.cpu().numpy()))\n",
    "\n",
    "            val_loss /= len(val_dl)\n",
    "            print(f\"Validation Loss (Epoch {epoch+1}): {val_loss:.4f}\")\n",
    "\n",
    "            # Check for improvement\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_preds = val_preds\n",
    "                torch.save(model.state_dict(), config[\"save_weights_name\"])\n",
    "                print(f\"  -> New best model saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), config[\"save_weights_final\"])\n",
    "    return best_val_loss, best_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. RUN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:45.006748Z",
     "iopub.status.busy": "2025-04-06T03:23:45.006238Z",
     "iopub.status.idle": "2025-04-06T03:23:45.009313Z",
     "shell.execute_reply": "2025-04-06T03:23:45.008933Z",
     "shell.execute_reply.started": "2025-04-06T03:23:45.006732Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured batch size: 1\n",
      "Train loader batch size: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Configured batch size: {config['batch_size']}\")\n",
    "print(f\"Train loader batch size: {train_loader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:23:45.010336Z",
     "iopub.status.busy": "2025-04-06T03:23:45.009838Z",
     "iopub.status.idle": "2025-04-06T03:23:50.269862Z",
     "shell.execute_reply": "2025-04-06T03:23:50.267655Z",
     "shell.execute_reply.started": "2025-04-06T03:23:45.010322Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50:   0%|          | 0/764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Forward pass: 0.8557s, Loss computation: 1.0249s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.6346:   0%|          | 3/764 [00:02<08:21,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: Forward pass: 0.0450s, Loss computation: 0.0021s\n",
      "Batch 2: Forward pass: 0.0464s, Loss computation: 0.0021s\n",
      "Batch 3: Forward pass: 0.0476s, Loss computation: 0.0022s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.5652:   1%|          | 5/764 [00:03<04:31,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4: Forward pass: 0.0407s, Loss computation: 0.0021s\n",
      "Batch 5: Forward pass: 0.0398s, Loss computation: 0.0020s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.6175:   1%|          | 7/764 [00:03<02:55,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6: Forward pass: 0.0573s, Loss computation: 0.0022s\n",
      "Batch 7: Forward pass: 0.0641s, Loss computation: 0.0025s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.6392:   1%|▏         | 10/764 [00:03<02:03,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8: Forward pass: 0.0596s, Loss computation: 0.0024s\n",
      "Batch 9: Forward pass: 0.0519s, Loss computation: 0.0021s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.7314:   2%|▏         | 13/764 [00:04<04:46,  2.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     best_loss, best_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# or config[\"epochs\"]\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcos_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# or config[\"cos_epoch\"]\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 56\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, val_dl, epochs, cos_epoch, lr, clip)\u001b[0m\n\u001b[1;32m     53\u001b[0m     loss \u001b[38;5;241m=\u001b[39m dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) \u001b[38;5;241m+\u001b[39m align_svd_mae(pred_xyz, gt_xyz)\n\u001b[1;32m     55\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m grad_accum_steps\n\u001b[0;32m---> 56\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m grad_accum_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl):\n\u001b[1;32m     58\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_loss, best_predictions = train_model(\n",
    "        model=model,\n",
    "        train_dl=train_loader,\n",
    "        val_dl=val_loader,\n",
    "        epochs=50,         # or config[\"epochs\"]\n",
    "        cos_epoch=35,      # or config[\"cos_epoch\"]\n",
    "        lr=3e-4,\n",
    "        clip=1\n",
    "    )\n",
    "    print(f\"Best Validation Loss: {best_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T03:30:12.580578Z",
     "iopub.status.busy": "2025-04-06T03:30:12.580339Z",
     "iopub.status.idle": "2025-04-06T03:30:17.043837Z",
     "shell.execute_reply": "2025-04-06T03:30:17.043343Z",
     "shell.execute_reply.started": "2025-04-06T03:30:12.580560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  target_id                                           sequence  \\\n",
      "0     R1107  GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...   \n",
      "1     R1108  GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUU...   \n",
      "2     R1116  CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGG...   \n",
      "3   R1117v2                     UUGGGUUCCCUCACCCCAAUCAUAAAAAGG   \n",
      "4     R1126  GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUU...   \n",
      "5     R1128  GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAU...   \n",
      "6     R1136  GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACA...   \n",
      "7     R1138  GGGAGAGUACUAUUCAGAUGCAGACCGCAAGUUCAGAGCGGUUUGC...   \n",
      "8     R1149  GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCG...   \n",
      "9     R1156  GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCG...   \n",
      "\n",
      "  temporal_cutoff                                        description  \\\n",
      "0      2022-05-28  CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...   \n",
      "1      2022-05-27  CPEB3 ribozyme\\nChimpanzee\\nChimpanzee CPEB3 H...   \n",
      "2      2022-06-04  Cloverleaf RNA\\nPoliovirus\\nCrystal Structure ...   \n",
      "3      2022-06-03  PreQ1 class I type III riboswitch\\nK. pneumoni...   \n",
      "4      2022-06-11  Traptamer\\nSynthetic\\nAdditional Information: ...   \n",
      "5      2022-06-10  6WJ\\nSingle-stranded Paranemic Crossover RNA T...   \n",
      "6      2022-06-18  Apta-FRET\\nAdditional Information:        Info...   \n",
      "7      2022-06-24  6HBC-Young\\nAdditional Information:        Thi...   \n",
      "8      2022-07-02  SARS-CoV-2 SL5\\nAdditional Information:       ...   \n",
      "9      2022-07-07  BtCoV-HKU5 SL5\\nBtCoV-HKU5 5 proximal stem-loo...   \n",
      "\n",
      "                                       all_sequences  \n",
      "0  >7QR4_1|Chain A|U1 small nuclear ribonucleopro...  \n",
      "1  >7QR3_1|Chains A, B|U1 small nuclear ribonucle...  \n",
      "2  >8S95_1|Chain A[auth C]|Lysine tRNA scaffold,P...  \n",
      "3  >8FZA_1|Chains A, B|PreQ1 Riboswitch (30-MER)|...  \n",
      "4  >8TVZ_1|Chain A[auth C]|RNA (363-MER)|syntheti...  \n",
      "5  >8BTZ_1|Chain A|RNA Paranemic croosover triang...  \n",
      "6  >7ZJ4_1|Chain A[auth E]|brocolli-pepper aptame...  \n",
      "7  >7PTK_1|Chain A[auth B]|RNA|synthetic construc...  \n",
      "8  >8UYS_1|Chain A|SARS-CoV-2 RNA SL5 domain.|Sev...  \n",
      "9  >8UYE_1|Chain A|BtCoV-HKU5 5' proximal stem-lo...  \n",
      "constructing 6 ConvTransformerEncoderLayers\n",
      "loading final pretrained weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference: 100%|██████████| 12/12 [00:04<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete! Saved to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(config[\"test_data_path\"]) # target_id,sequence,temporal_cutoff,description,all_sequences\n",
    "print(test_df.head(10))\n",
    "test_model = FinetunedRibonanzaNet(model_cfg, pretrained_state=2).cuda()\n",
    "test_model.eval()\n",
    "\n",
    "submission_rows = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Running inference\"):\n",
    "    seq_id = row[\"target_id\"]\n",
    "    seq = row[\"sequence\"]\n",
    "    \n",
    "    token_map = {'A': 0, 'C': 1, 'U': 2, 'G': 3}\n",
    "    token_ids = torch.tensor([token_map[c] for c in seq], dtype=torch.long).unsqueeze(0).cuda()  # shape (1, L)\n",
    "    mask = torch.ones_like(token_ids).cuda()  # or derive if needed\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(5):  # generate 5 predictions\n",
    "            pred_xyz = test_model(token_ids, mask).squeeze(0).cpu().numpy()  # shape (L, 3)\n",
    "            preds.append(pred_xyz)\n",
    "\n",
    "    preds = np.stack(preds, axis=0)  # shape (5, L, 3)\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        resname = seq[i]\n",
    "        resid = i + 1\n",
    "        flat_xyz = preds[:, i, :].flatten()  # (x1,y1,z1,...,x5,y5,z5)\n",
    "        row = [f\"{seq_id}\", resname, resid] + flat_xyz.tolist()\n",
    "        submission_rows.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "columns = [\"ID\", \"resname\", \"resid\"] + [f\"{axis}_{i+1}\" for i in range(5) for axis in [\"x\", \"y\", \"z\"]]\n",
    "submission = pd.DataFrame(submission_rows, columns=columns)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Inference complete! Saved to submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11403143,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 4299272,
     "sourceId": 7639698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459124,
     "sourceId": 8318191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
