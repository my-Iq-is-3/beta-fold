{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:49.092782Z",
     "iopub.status.busy": "2025-04-03T04:30:49.092129Z",
     "iopub.status.idle": "2025-04-03T04:30:51.645502Z",
     "shell.execute_reply": "2025-04-03T04:30:51.644682Z",
     "shell.execute_reply.started": "2025-04-03T04:30:49.092756Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:51.647669Z",
     "iopub.status.busy": "2025-04-03T04:30:51.647249Z",
     "iopub.status.idle": "2025-04-03T04:30:51.655545Z",
     "shell.execute_reply": "2025-04-03T04:30:51.654687Z",
     "shell.execute_reply.started": "2025-04-03T04:30:51.647644Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CONFIG & SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:51.657834Z",
     "iopub.status.busy": "2025-04-03T04:30:51.656380Z",
     "iopub.status.idle": "2025-04-03T04:30:51.664524Z",
     "shell.execute_reply": "2025-04-03T04:30:51.663982Z",
     "shell.execute_reply.started": "2025-04-03T04:30:51.657816Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Set a random seed for Python, NumPy, PyTorch (CPU & GPU) to ensure reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Example configuration (you can load this from a YAML, JSON, etc.)\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 384,\n",
    "    \"batch_size\": 1,\n",
    "    \"model_config_path\": \"ribonanzanet2d-final/configs/pairwise.yaml\",\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"min_len_filter\": 10,\n",
    "    \n",
    "    \"train_sequences_path\": \"data/train_sequences.csv\",\n",
    "    \"train_labels_path\": \"data/train_labels.csv\",\n",
    "    \"pretrained_weights_path\": \"ribonanzanet2d-final/RibonanzaNet-SS.pt\",\n",
    "    \"save_weights_name\": \"RibonanzaNet-3D.pt\",\n",
    "    \"save_weights_final\": \"RibonanzaNet-3D-final.pt\",\n",
    "}\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "set_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:51.665544Z",
     "iopub.status.busy": "2025-04-03T04:30:51.665124Z",
     "iopub.status.idle": "2025-04-03T04:30:58.553020Z",
     "shell.execute_reply": "2025-04-03T04:30:58.552545Z",
     "shell.execute_reply.started": "2025-04-03T04:30:51.665526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting XYZ data: 100%|██████████| 844/844 [00:06<00:00, 127.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs\n",
    "train_sequences = pd.read_csv(config[\"train_sequences_path\"])\n",
    "train_labels = pd.read_csv(config[\"train_labels_path\"])\n",
    "\n",
    "# Create a pdb_id field\n",
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(\n",
    "    lambda x: x.split(\"_\")[0] + \"_\" + x.split(\"_\")[1]\n",
    ")\n",
    "\n",
    "# Collect xyz data for each sequence\n",
    "all_xyz = []\n",
    "for pdb_id in tqdm(train_sequences[\"target_id\"], desc=\"Collecting XYZ data\"):\n",
    "    df = train_labels[train_labels[\"pdb_id\"] == pdb_id]\n",
    "    xyz = df[[\"x_1\", \"y_1\", \"z_1\"]].to_numpy().astype(\"float32\")\n",
    "    xyz[xyz < -1e17] = float(\"nan\")\n",
    "    all_xyz.append(xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:58.554921Z",
     "iopub.status.busy": "2025-04-03T04:30:58.554435Z",
     "iopub.status.idle": "2025-04-03T04:30:58.567791Z",
     "shell.execute_reply": "2025-04-03T04:30:58.567259Z",
     "shell.execute_reply.started": "2025-04-03T04:30:58.554898Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 4298\n"
     ]
    }
   ],
   "source": [
    "valid_indices = []\n",
    "max_len_seen = 0\n",
    "\n",
    "for i, xyz in enumerate(all_xyz):\n",
    "    # Track the maximum length\n",
    "    if len(xyz) > max_len_seen:\n",
    "        max_len_seen = len(xyz)\n",
    "\n",
    "    nan_ratio = np.isnan(xyz).mean()\n",
    "    seq_len = len(xyz)\n",
    "    # Keep sequence if it meets criteria\n",
    "    if (nan_ratio <= 0.5) and (config[\"min_len_filter\"] < seq_len < config[\"max_len_filter\"]):\n",
    "        valid_indices.append(i)\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len_seen}\")\n",
    "\n",
    "# Filter sequences & xyz based on valid_indices\n",
    "train_sequences = train_sequences.loc[valid_indices].reset_index(drop=True)\n",
    "all_xyz = [all_xyz[i] for i in valid_indices]\n",
    "\n",
    "# Prepare final data dictionary\n",
    "data = {\n",
    "    \"sequence\": train_sequences[\"sequence\"].tolist(),\n",
    "    \"temporal_cutoff\": train_sequences[\"temporal_cutoff\"].tolist(),\n",
    "    \"description\": train_sequences[\"description\"].tolist(),\n",
    "    \"all_sequences\": train_sequences[\"all_sequences\"].tolist(),\n",
    "    \"xyz\": all_xyz,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TRAIN / VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:58.569085Z",
     "iopub.status.busy": "2025-04-03T04:30:58.568480Z",
     "iopub.status.idle": "2025-04-03T04:30:58.574276Z",
     "shell.execute_reply": "2025-04-03T04:30:58.573679Z",
     "shell.execute_reply.started": "2025-04-03T04:30:58.569065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff_date = pd.Timestamp(config[\"cutoff_date\"])\n",
    "test_cutoff_date = pd.Timestamp(config[\"test_cutoff_date\"])\n",
    "\n",
    "train_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if pd.Timestamp(date_str) <= cutoff_date]\n",
    "test_indices = [i for i, date_str in enumerate(data[\"temporal_cutoff\"]) if cutoff_date < pd.Timestamp(date_str) <= test_cutoff_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DATASET & DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:58.575707Z",
     "iopub.status.busy": "2025-04-03T04:30:58.575153Z",
     "iopub.status.idle": "2025-04-03T04:30:58.584925Z",
     "shell.execute_reply": "2025-04-03T04:30:58.584153Z",
     "shell.execute_reply.started": "2025-04-03T04:30:58.575686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNA3D_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for 3D RNA structures.\n",
    "    \"\"\"\n",
    "    def __init__(self, indices, data_dict, max_len=384):\n",
    "        self.indices = indices\n",
    "        self.data = data_dict\n",
    "        self.max_len = max_len\n",
    "        self.nt_to_idx = {nt: i for i, nt in enumerate(\"ACGU\")}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_idx = self.indices[idx]\n",
    "        # Convert nucleotides to integer tokens\n",
    "        sequence = [self.nt_to_idx[nt] for nt in self.data[\"sequence\"][data_idx]]\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long)\n",
    "        # Convert xyz to torch tensor\n",
    "        xyz = torch.tensor(self.data[\"xyz\"][data_idx], dtype=torch.float32)\n",
    "\n",
    "        # If sequence is longer than max_len, randomly crop\n",
    "        if len(sequence) > self.max_len:\n",
    "            crop_start = np.random.randint(len(sequence) - self.max_len)\n",
    "            crop_end = crop_start + self.max_len\n",
    "            sequence = sequence[crop_start:crop_end]\n",
    "            xyz = xyz[crop_start:crop_end]\n",
    "\n",
    "        return {\"sequence\": sequence, \"xyz\": xyz}\n",
    "\n",
    "train_dataset = RNA3D_Dataset(train_indices, data, max_len=config[\"max_len\"])\n",
    "val_dataset = RNA3D_Dataset(test_indices, data, max_len=config[\"max_len\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True,\n",
    "    num_workers=4,  # Adjust based on CPU cores\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODEL, CONFIG CLASSES & HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:58.586277Z",
     "iopub.status.busy": "2025-04-03T04:30:58.585849Z",
     "iopub.status.idle": "2025-04-03T04:30:59.050738Z",
     "shell.execute_reply": "2025-04-03T04:30:59.050063Z",
     "shell.execute_reply.started": "2025-04-03T04:30:58.586257Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing 9 ConvTransformerEncoderLayers\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"ribonanzanet2d-final\")\n",
    "\n",
    "from Network import RibonanzaNet\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Simple Config class that can load from a dict or YAML.\"\"\"\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "        self.entries = entries\n",
    "\n",
    "    def print(self):\n",
    "        print(self.entries)\n",
    "\n",
    "def load_config_from_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "    return Config(**cfg)\n",
    "\n",
    "class FinetunedRibonanzaNet(RibonanzaNet):\n",
    "    \"\"\"\n",
    "    A finetuned version of RibonanzaNet adapted for predicting 3D coordinates.\n",
    "    \"\"\"\n",
    "    def __init__(self, config_obj, pretrained=False, dropout=0.1):\n",
    "        # Modify config dropout before super init, if needed\n",
    "        config_obj.dropout = dropout\n",
    "        super(FinetunedRibonanzaNet, self).__init__(config_obj)\n",
    "\n",
    "        # Load pretrained weights if requested\n",
    "        if pretrained:\n",
    "            self.load_state_dict(\n",
    "                torch.load(config[\"pretrained_weights_path\"], map_location=\"cpu\"), strict = False\n",
    "            )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.xyz_predictor = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"Forward pass to predict 3D XYZ coordinates.\"\"\"\n",
    "        # get_embeddings returns (sequence_features, *some_other_outputs)\n",
    "        sequence_features, _ = self.get_embeddings(\n",
    "            src, torch.ones_like(src).long().to(src.device)\n",
    "        )\n",
    "        xyz_pred = self.xyz_predictor(sequence_features)\n",
    "        return xyz_pred\n",
    "\n",
    "# Instantiate the model\n",
    "model_cfg = load_config_from_yaml(config[\"model_config_path\"])\n",
    "model = FinetunedRibonanzaNet(model_cfg, pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:59.051932Z",
     "iopub.status.busy": "2025-04-03T04:30:59.051729Z",
     "iopub.status.idle": "2025-04-03T04:30:59.062552Z",
     "shell.execute_reply": "2025-04-03T04:30:59.061305Z",
     "shell.execute_reply.started": "2025-04-03T04:30:59.051913Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X, Y, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances between every point in X and every point in Y.\n",
    "    Shape: (len(X), len(Y))\n",
    "    \"\"\"\n",
    "    return ((X[:, None] - Y[None, :])**2 + epsilon).sum(dim=-1).sqrt()\n",
    "\n",
    "def dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=None):\n",
    "    \"\"\"\n",
    "    Distance-based RMSD.\n",
    "    pred_x, pred_y: predicted coordinates (usually the same tensor for X and Y).\n",
    "    gt_x, gt_y: ground truth coordinates.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    if d_clamp is not None:\n",
    "        diff_sq = diff_sq.clamp(max=d_clamp**2)\n",
    "\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def local_dRMSD(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10, d_clamp=30):\n",
    "    \"\"\"\n",
    "    Local distance-based RMSD, ignoring distances above a clamp threshold.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = (~torch.isnan(gt_dm)) & (gt_dm < d_clamp)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff_sq = (pred_dm[mask] - gt_dm[mask])**2 + epsilon\n",
    "    return diff_sq.sqrt().mean() / Z\n",
    "\n",
    "def dRMAE(pred_x, pred_y, gt_x, gt_y, epsilon=1e-4, Z=10):\n",
    "    \"\"\"\n",
    "    Distance-based Mean Absolute Error.\n",
    "    \"\"\"\n",
    "    pred_dm = calculate_distance_matrix(pred_x, pred_y)\n",
    "    gt_dm = calculate_distance_matrix(gt_x, gt_y)\n",
    "\n",
    "    mask = ~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0], device=mask.device).bool()] = False\n",
    "\n",
    "    diff = torch.abs(pred_dm[mask] - gt_dm[mask])\n",
    "    return diff.mean() / Z\n",
    "\n",
    "def align_svd_mae(input_coords, target_coords, Z=10):\n",
    "    \"\"\"\n",
    "    Align input_coords to target_coords via SVD (Kabsch algorithm) and compute MAE.\n",
    "    \"\"\"\n",
    "    assert input_coords.shape == target_coords.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    # Create mask for valid points\n",
    "    mask = ~torch.isnan(target_coords.sum(dim=-1))\n",
    "    input_coords = input_coords[mask]\n",
    "    target_coords = target_coords[mask]\n",
    "    \n",
    "    # Compute centroids\n",
    "    centroid_input = input_coords.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target_coords.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input_coords - centroid_input\n",
    "    target_centered = target_coords - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (determinant R == 1)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt_adj = Vt.clone()   # Clone to avoid in-place modification issues\n",
    "        Vt_adj[-1, :] = -Vt_adj[-1, :]\n",
    "        R = Vt_adj @ U.T\n",
    "\n",
    "    # Rotate input and compute mean absolute error\n",
    "    aligned_input = (input_centered @ R.T) + centroid_target\n",
    "    return torch.abs(aligned_input - target_coords).mean() / Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:59.064109Z",
     "iopub.status.busy": "2025-04-03T04:30:59.063897Z",
     "iopub.status.idle": "2025-04-03T04:30:59.074087Z",
     "shell.execute_reply": "2025-04-03T04:30:59.073395Z",
     "shell.execute_reply.started": "2025-04-03T04:30:59.064090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, val_dl, epochs=50, cos_epoch=35, lr=3e-4, clip=1):\n",
    "    \"\"\"Train the model with a CosineAnnealingLR after `cos_epoch` epochs.\"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.0, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=(epochs - cos_epoch) * len(train_dl),\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_preds = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_pbar = tqdm(train_dl, desc=f\"Training Epoch {epoch+1}/{epochs}\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Add profiling for the first few batches of the first epoch\n",
    "        profiling_enabled = (epoch == 0)\n",
    "\n",
    "        for idx, batch in enumerate(train_pbar):\n",
    "            sequence = batch[\"sequence\"].cuda()\n",
    "            gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "\n",
    "            # Only profile the first 5 batches of the first epoch\n",
    "            if profiling_enabled and idx < 10:\n",
    "                torch.cuda.synchronize()\n",
    "                start_forward = time.time()\n",
    "                \n",
    "                # Remove autocast\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                forward_time = time.time() - start_forward\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                start_loss = time.time()\n",
    "                \n",
    "                # Remove autocast\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "                \n",
    "                torch.cuda.synchronize()\n",
    "                loss_time = time.time() - start_loss\n",
    "                \n",
    "                print(f\"Batch {idx}: Forward pass: {forward_time:.4f}s, Loss computation: {loss_time:.4f}s\")\n",
    "                \n",
    "                # Continue with normal training flow (without scaler)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            else:\n",
    "                # Normal non-profiling training code (without autocast and scaler)\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            if (epoch + 1) > cos_epoch:\n",
    "                scheduler.step()\n",
    "                \n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (idx + 1)\n",
    "            train_pbar.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        with torch.no_grad():\n",
    "            for idx, batch in enumerate(val_dl):\n",
    "                sequence = batch[\"sequence\"].cuda()\n",
    "                gt_xyz = batch[\"xyz\"].squeeze().cuda()\n",
    "\n",
    "                pred_xyz = model(sequence).squeeze()\n",
    "                loss = dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.append((gt_xyz.cpu().numpy(), pred_xyz.cpu().numpy()))\n",
    "\n",
    "            val_loss /= len(val_dl)\n",
    "            print(f\"Validation Loss (Epoch {epoch+1}): {val_loss:.4f}\")\n",
    "\n",
    "            # Check for improvement\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_preds = val_preds\n",
    "                torch.save(model.state_dict(), config[\"save_weights_name\"])\n",
    "                print(f\"  -> New best model saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), config[\"save_weights_final\"])\n",
    "    return best_val_loss, best_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. RUN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:59.075194Z",
     "iopub.status.busy": "2025-04-03T04:30:59.074970Z",
     "iopub.status.idle": "2025-04-03T04:30:59.078648Z",
     "shell.execute_reply": "2025-04-03T04:30:59.077979Z",
     "shell.execute_reply.started": "2025-04-03T04:30:59.075176Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured batch size: 1\n",
      "Train loader batch size: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Configured batch size: {config['batch_size']}\")\n",
    "print(f\"Train loader batch size: {train_loader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T04:30:59.079900Z",
     "iopub.status.busy": "2025-04-03T04:30:59.079723Z",
     "iopub.status.idle": "2025-04-03T04:53:41.666026Z",
     "shell.execute_reply": "2025-04-03T04:53:41.659829Z",
     "shell.execute_reply.started": "2025-04-03T04:30:59.079884Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/50:   0%|          | 0/542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Forward pass: 1.1636s, Loss computation: 1.2005s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.8516:   0%|          | 1/542 [00:03<29:05,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: Forward pass: 0.3940s, Loss computation: 0.0036s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 5.1066:   1%|          | 3/542 [00:05<12:03,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2: Forward pass: 0.0908s, Loss computation: 0.0022s\n",
      "Batch 3: Forward pass: 0.0562s, Loss computation: 0.0022s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 4.1688:   1%|          | 5/542 [00:05<05:38,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4: Forward pass: 0.0515s, Loss computation: 0.0024s\n",
      "Batch 5: Forward pass: 0.0367s, Loss computation: 0.0024s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.5932:   1%|▏         | 7/542 [00:05<03:14,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6: Forward pass: 0.0619s, Loss computation: 0.0022s\n",
      "Batch 7: Forward pass: 0.0319s, Loss computation: 0.0024s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.3709:   1%|▏         | 8/542 [00:05<02:31,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8: Forward pass: 0.0607s, Loss computation: 0.0022s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 3.5264:   2%|▏         | 10/542 [00:06<02:38,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9: Forward pass: 0.0823s, Loss computation: 0.0024s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.7761: 100%|██████████| 542/542 [02:27<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 1): 2.1273\n",
      "  -> New best model saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 1.8230: 100%|██████████| 542/542 [01:56<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 2): 1.8759\n",
      "  -> New best model saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 1.6605: 100%|██████████| 542/542 [01:56<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 3): 1.6122\n",
      "  -> New best model saved at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 1.5213: 100%|██████████| 542/542 [02:19<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 4): 1.5123\n",
      "  -> New best model saved at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 1.3414: 100%|██████████| 542/542 [02:22<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 5): 1.3467\n",
      "  -> New best model saved at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 1.2016: 100%|██████████| 542/542 [02:15<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 6): 1.3890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 1.1433: 100%|██████████| 542/542 [02:04<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 7): 1.2847\n",
      "  -> New best model saved at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 1.1185: 100%|██████████| 542/542 [02:04<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 8): 1.3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 1.0672: 100%|██████████| 542/542 [02:29<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss (Epoch 9): 1.2587\n",
      "  -> New best model saved at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 1.0345:  64%|██████▍   | 347/542 [01:37<00:54,  3.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     best_loss, best_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# or config[\"epochs\"]\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcos_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# or config[\"cos_epoch\"]\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 56\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, val_dl, epochs, cos_epoch, lr, clip)\u001b[0m\n\u001b[1;32m     53\u001b[0m pred_xyz \u001b[38;5;241m=\u001b[39m model(sequence)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m dRMAE(pred_xyz, pred_xyz, gt_xyz, gt_xyz) \u001b[38;5;241m+\u001b[39m align_svd_mae(pred_xyz, gt_xyz)\n\u001b[0;32m---> 56\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[1;32m     58\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_loss, best_predictions = train_model(\n",
    "        model=model,\n",
    "        train_dl=train_loader,\n",
    "        val_dl=val_loader,\n",
    "        epochs=50,         # or config[\"epochs\"]\n",
    "        cos_epoch=35,      # or config[\"cos_epoch\"]\n",
    "        lr=3e-4,\n",
    "        clip=1\n",
    "    )\n",
    "    print(f\"Best Validation Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11403143,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 4299272,
     "sourceId": 7639698,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4459124,
     "sourceId": 8318191,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
